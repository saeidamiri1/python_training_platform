{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Python training platform","text":"<p>A comprehensive Python learning platform prepared for learners at all levels, offering interactive lessons, hands-on coding exercises, and real-world projects to build practical skills. The platform also includes resources to reinforce foundational Python concepts, with a focus on core principles rather than specific libraries or modules. The content is organized into four main sections: Python Basics, Python Projects, Workshops, and Concise Notes.</p>"},{"location":"#book","title":"Book","text":"<p>This section serves as the foundation of the platform, presenting a series of structured chapters that guide users through the process of learning Python. The chapters include:</p> <ul> <li>Chapter 1: Primer</li> <li>Chapter 2: computation</li> <li>Chapter 3: Data analysis</li> <li>Chapter 4: Visualization</li> <li>Chapter 5: Working with files</li> <li>Chapter 6: OS</li> <li>Chapter 7: Decorator</li> <li>Chapter 8: Class</li> <li>Chapter 9: Higher-order functions</li> <li>Chapter 10: Multiprocessing</li> <li>Chapter 11: Regex</li> <li>Chapter 12: Testing and debugging</li> <li>Chapter 13: Package</li> </ul>"},{"location":"#python-projects","title":"Python projects","text":"<p>This section features projects that can be used to learn about Python's applications.</p>"},{"location":"#workshop","title":"Workshop","text":"<p>This workshop offers practical insights and support for those embarking on their data analysis journey with Python.</p>"},{"location":"#concise-notes","title":"Concise notes","text":"<p>Dive into a collection of blogs exploring different aspects of Python programming.</p>"},{"location":"support/","title":"Support","text":""},{"location":"support/#become-a-sponsor","title":"Become a Sponsor","text":"<p>Open source projects take time and money. Help support the project by becoming a sponsor. You can add your support at any tier you feel comfortable with. No amount is too little. We also accept one time contributions via PayPal.</p> <p> GitHub Sponsors  PayPal</p>"},{"location":"book/overview/","title":"Overview","text":"<p>This short book covers fundamental concepts that help users engage in hands-on coding.</p>"},{"location":"book/ch10_multiprocessing/ch10_joblib/","title":"Joblib","text":"<p><code>joblib</code> provides a simple way to write parallel computation,  which can be used to to efficently serialized the large data. </p>"},{"location":"book/ch10_multiprocessing/ch10_joblib/#parallel-processing","title":"Parallel Processing","text":"<p>Here we look how to used joblib to do parallel process: </p> <p><pre><code>#name joblib1.py\nimport os\nimport time\nfrom joblib import Parallel, delayed\n\ndef prod(x):\n    square = 0\n    for i in x:\n        time.sleep(1)\n        square += i * i\n        print(f\"Now Process {os.getpid()}  | is calculating square {i}\")\n    return square\n\nx = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n# Split list into chunks for parallel processing\nchunks = [x[0:5],x[6:8] ]  # split into 4 chunks\n\nimport multiprocessing as mp\nnum_cores = mp.cpu_count()\n\nresults = Parallel(n_jobs=num_cores-1,verbose=1)(delayed(prod)(chunk) for chunk in chunks)\n\nprint(\"Partial results:\", results)\nprint(\"Total sum of squares:\", sum(results))\n</code></pre> <pre><code>[Parallel(n_jobs=11)]: Using backend LokyBackend with 11 concurrent workers.\nNow Process 8249  | is calculating square 1\nNow Process 8254  | is calculating square 7\nNow Process 8249  | is calculating square 2\nNow Process 8254  | is calculating square 8\nNow Process 8249  | is calculating square 3\nNow Process 8249  | is calculating square 4\nNow Process 8249  | is calculating square 5\n[Parallel(n_jobs=11)]: Done   2 out of   2 | elapsed:    5.1s finished\nPartial results: [55, 113]\nTotal sum of squares: 168\n</code></pre> delayed is used to capture the arguments of the target function, in this case, the prod. We run the above code (with num_cores-1) CPUs, if you want to use all of computational power on your machine. You can use all CPUs on your machine by setting n_jobs=-1. If you set it to -2, all CPUs but one are used. Here, we turn on the verbose argument (verbose=1) to output the status messages The function can be done using pool workers</p> <pre><code>with Parallel(n_jobs=num_cores-1) as parallel:\n  results = parallel(n_jobs=num_cores-1,verbose=1)(delayed(prod)(chunk) for chunk in chunks)\n</code></pre> <p>There are multiple backends in joblib, which provides different ways to do the parallel computing. If you set the backend as multiprocessing, it creates a multiprocessing pool that uses separate Python woker processes to execute tasks concurrently on separate CPUs. </p> <pre><code>import os\nimport time\nfrom joblib import Parallel, delayed\nimport multiprocessing\n\ndef prod(x):\n    square = 0\n    for i in x:\n        time.sleep(1)\n        square += i * i\n        print(f\"Now Process {os.getpid()}  | is calculating square {i}\")\n    return square\n\nif __name__ == \"__main__\":\n    x = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n    # Split list into chunks for parallel processing\n    chunks = [x[0:5],x[6:8] ]  # split into 4 chunks\n    import multiprocessing as mp\n    num_cores = mp.cpu_count()\n    results = Parallel(n_jobs=num_cores-1,backend='multiprocessing',verbose=1)(delayed(prod)(chunk) for chunk in chunks)\n    print(\"Partial results:\", results)\n    print(\"Total sum of squares:\", sum(results))\n</code></pre> <p>This function will run each function in isolated process, so the parallel function needs the shared memory semantics of threads, it can be done via require='sharedmem': </p> <pre><code>results = Parallel(n_jobs=num_cores-1, require='sharedmem',verbose=1)(delayed(prod)(chunk) for chunk in chunks)\n</code></pre>"},{"location":"book/ch10_multiprocessing/ch10_joblib/#serializing-object","title":"Serializing object","text":"<p>In this chapter, we review how to use Pickle-like tools to store data. When working with large objects or machine learning models, the joblib library offers an efficient and convenient way to serialize and save them to disk. This is especially useful for storing models after training or for caching intermediate results. Here\u2019s a simple example using joblib:</p> <pre><code>from joblib import dump, load\nx = [1, 2, 3, 4, 5, 6, 7, 8, 9]\ndump(weights, 'x.joblib')  # Save model\nweights = load('x.joblib') # Load model\n</code></pre>"},{"location":"book/ch10_multiprocessing/ch10_joblib/#caching-computations","title":"Caching Computations","text":"<p>One can use  Memory to get rid of repition of computation, </p> <p><pre><code>from joblib import Memory\nmem = Memory(location='cachedir', verbose=0)\n@mem.cache\ndef func_time(x):\n    time.sleep(4)\n    return x ** 2\n\n@mem.cache\ndef prod(x):\n    square = 0\n    start_parallel = time.time()\n    for i in x:\n        time.sleep(1)\n        square += i * i\n        print(f\"Now Process {os.getpid()}  | is calculating square {i}\")\n    end_parallel = time.time()\n    print(f\"Total time:  {end_parallel-start_parallel}\")\n    return square\n\n\nprod(x)\nprod(x)\n</code></pre> <pre><code>#Output: \n&gt;&gt;&gt; prod(x)\nNow Process 79813  | is calculating square 1\nNow Process 79813  | is calculating square 2\nNow Process 79813  | is calculating square 3\nNow Process 79813  | is calculating square 4\nNow Process 79813  | is calculating square 5\nNow Process 79813  | is calculating square 6\nNow Process 79813  | is calculating square 7\nNow Process 79813  | is calculating square 8\nNow Process 79813  | is calculating square 9\nTotal time:  9.02702784538269\n285\n&gt;&gt;&gt; prod(x)\n285\n</code></pre></p>"},{"location":"book/ch10_multiprocessing/ch10_joblib/#share-data","title":"Share data","text":"<p>When working with multiprocessing, it's important to use memory-efficient techniques. By default, when data is passed to child processes, it gets copied\u2014this can lead to high memory usage, especially with large datasets.</p> <p>To avoid this, joblib provides support for shared memory when using NumPy arrays and similar data structures. This allows multiple processes or threads to access the same data without duplication, improving both performance and efficiency.</p> <p>Let\u2019s review how to use joblib with sharedmem to compute row-wise means on a NumPy array: <pre><code>import numpy as np\nfrom joblib import Parallel, delayed\n\n# Create a random dataset\ndata = np.random.rand(100, 1000)\n\n# Function to compute the mean of a specific row\ndef mean_row(i):\n    return np.mean(data[i])\n\n# Use joblib with shared memory to avoid copying large arrays between processes\nresult = Parallel(n_jobs=4, require='sharedmem')(\n    delayed(mean_row)(i) for i in range(data.shape[0])\n)\n\nprint(result)\n</code></pre></p> <p>Note: require='sharedmem' ensures that data is not copied between processes, and instead is shared efficiently. This technique works best when using threads (n_jobs &gt; 1 with require='sharedmem') and is especially helpful with large NumPy arrays. Make sure your function only reads from the shared data (no in-place modifications) to avoid race conditions.</p>"},{"location":"book/ch10_multiprocessing/ch10_multiprocessing/","title":"Multiprocessing","text":"<p>Python has the ability to handle multiple tasks simultaneously or in parallel, allowing it to take full advantage of multiple cores and processors. In this section, we briefly discuss how to perform parallel computation using Python.</p> <p>In general, multiprocessing (or parallel processing) refers to the use of two or more processors by an application to perform tasks in parallel. Each process runs independently and has its own allocated resources. To enable communication between these separate processes, the concept of Inter-Process Communication (IPC) must be used.</p> <p>Multiprocessing is particularly useful when tasks are: CPU-bound, Can be executed independently, Require minimal data sharing between them</p> <p>Python provides two main ways to implement multiprocessing: the Pool class and the Process class. In the following sections, we will first explore the Pool method, and then examine how to use the Process class for parallel execution.</p>"},{"location":"book/ch10_multiprocessing/ch10_multiprocessing/#getting-started","title":"Getting Started","text":"<p>To see how many CPUs are available on your computer,  <pre><code>import multiprocessing\nmultiprocessing.cpu_count()\n</code></pre></p>"},{"location":"book/ch10_multiprocessing/ch10_multiprocessing/#pool-method","title":"Pool method","text":"<p>Pool.map() is the parallel equivalent of Python\u2019s built-in map() function. To run computations in parallel, you first create a pool of worker processes\u2014typically based on the number of available CPU cores. If the number of processes is not specified, Pool will use all available CPU cores by default.</p> <p><pre><code>#name mp1.py\nfrom multiprocessing import Pool\nimport os\nimport time\n\ndef prod(x):\n    print(f\"Now Process {os.getpid()} | is calculating square {x}\")\n    return x * x\n\nif __name__ == \"__main__\":\n    x = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n    with Pool(processes=4) as pool:\n        result = pool.map(prod, x)\n\n    print(f\"Partial results: {result}\")\n    print(f\"Total sum of squares: {sum(result)}\")\n    print('Done')\n</code></pre> Here, os.getpid() prints the process ID, helping you see which worker handled which task. Alternative ways to use Pool.map() You can also create the pool without specifying the number of processes (it defaults to all available CPUs):</p> <pre><code>with Pool() as pool:\n    result = pool.map(defs.sq, x)\n</code></pre> <p>Or by manually managing the pool:</p> <pre><code>pl = Pool(4)\nresult = pl.map(defs.sq, x)\npl.close()\n</code></pre> <p>Limitation of Pool.map(): The Pool.map() function accepts only a single iterable, which means it supports only one argument per target function. To handle functions with multiple arguments, you can use Pool.starmap(), which we'll explore next.</p>"},{"location":"book/ch10_multiprocessing/ch10_multiprocessing/#multiple-arguments","title":"Multiple arguments","text":"<p>If your target function requires multiple arguments, you can use pool.starmap(), which allows unpacking argument tuples for parallel execution. In the below, we use Pool.starmap() with a Function that Takes Two Arguments First, add the following code to a file named mp2.py</p> <p><pre><code>#File: mp2.py\nfrom multiprocessing import Pool\nimport os\nimport time\n\ndef prod(x,y):\n    print(f\"Now Process {os.getpid()} | is calculating  {x} times {y}\")\n    return x * y\n\nif __name__ == \"__main__\":\n    x = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n    y=x[::-1]\n    xy=zip(x,y)\n    with Pool() as pool:\n      result = pool.starmap(prod, xy)\n\n    print(f\"Partial results: {result}\")\n    print(f\"Total sum of squares: {sum(result)}\")\n    print('Done')\n</code></pre> <pre><code># Output \nNow Process 47902 | is calculating  1 times 9\nNow Process 47902 | is calculating  2 times 8\nNow Process 47902 | is calculating  3 times 7\nNow Process 47902 | is calculating  4 times 6\nNow Process 47902 | is calculating  5 times 5\nNow Process 47902 | is calculating  6 times 4\nNow Process 47902 | is calculating  7 times 3\nNow Process 47902 | is calculating  8 times 2\nNow Process 47902 | is calculating  9 times 1\nPartial results: [9, 16, 21, 24, 25, 24, 21, 16, 9]\nTotal sum of squares: 165\nDone\n</code></pre></p> <p>Note on Blocking Behavior: A major limitation of Pool.map() and Pool.starmap() is that they are blocking operations \u2014 the main (master) process is paused until all results are returned. To avoid blocking and run computations asynchronously, you can use map_async() or starmap_async(), which allow concurrent execution without halting the main process.</p> <p><pre><code>xx=zip(x,x)\nxy=zip(x,y)\nwith Pool() as pool:\n    p1 = pool.map_async(prod, xx).get()\n    p2 = pool.map_async(prod, xy).get()\n</code></pre> .get() blocks until the results are ready, but you can omit it or delay it to keep the main process responsive.</p>"},{"location":"book/ch10_multiprocessing/ch10_multiprocessing/#parallel-vs-serial-process","title":"Parallel vs serial process","text":"<p>Let compare the parallel and serial  processing here:  <pre><code>#File: mp3.py\nimport time\nfrom multiprocessing import Pool\n\nimport os\nimport time\n\ndef prod(x):\n    print(f\"Now Process {os.getpid()} | is calculating square {x}\")\n    time.sleep(2)\n    return x * x\n\nif __name__ == \"__main__\":\n    x = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n    with Pool(processes=4) as pool:\n        start_parallel = time.time()\n        result = pool.map(prod, x)\n        end_parallel = time.time()\n# Sequential processing\n    start_sequential = time.time()\n    result_sequential = list(map(prod, x))\n    end_sequential = time.time()\n    print(\"Time for Parallel Processing: {:.4f} seconds\".format(end_parallel - start_parallel))\n    print(\"Time for Sequential Processing: {:.4f} seconds\".format(end_sequential - start_sequential))\n</code></pre> <pre><code>Now Process 58957 | is calculating square 1\nNow Process 58958 | is calculating square 2\nNow Process 58959 | is calculating square 3\nNow Process 58960 | is calculating square 4\nNow Process 58959 | is calculating square 5\nNow Process 58958 | is calculating square 6\nNow Process 58957 | is calculating square 7\nNow Process 58960 | is calculating square 8\nNow Process 58959 | is calculating square 9\nNow Process 58955 | is calculating square 1\nNow Process 58955 | is calculating square 2\nNow Process 58955 | is calculating square 3\nNow Process 58955 | is calculating square 4\nNow Process 58955 | is calculating square 5\nNow Process 58955 | is calculating square 6\nNow Process 58955 | is calculating square 7\nNow Process 58955 | is calculating square 8\nNow Process 58955 | is calculating square 9\nTime for Parallel Processing: 6.0465 seconds\nTime for Sequential Processing: 18.0376 seconds\n</code></pre></p>"},{"location":"book/ch10_multiprocessing/ch10_multiprocessing/#process-method","title":"Process method","text":"<p>Another approach is to use the Process class directly from the multiprocessing module: <pre><code>#File: mp4.py\nimport multiprocessing\nimport os\nimport time\n\ndef prod(x, results, key):\n    square = 0\n    for i in x:\n        time.sleep(1)\n        square += i * i\n        print(f\"Now Process {os.getpid()} | is calculating square {i}\")\n    results[key] = square\n\nif __name__ == \"__main__\":\n    x = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n    y=x[::-1]\n    results = {}\n    p1 = multiprocessing.Process(target=prod, args=(x, results, \"res1\"))\n    p2 = multiprocessing.Process(target=prod, args=(y, results, \"res2\"))\n    # Start task execution\n    p1.start()\n    p2.start()\n    # Wait for process to complete execution\n    p1.join()\n    p2.join()\n    print('Done')\n</code></pre> <pre><code># Output\nNow Process 62187 | is calculating square 1\nNow Process 62188 | is calculating square 9\nNow Process 62187 | is calculating square 2\nNow Process 62188 | is calculating square 8\nNow Process 62188 | is calculating square 7\nNow Process 62187 | is calculating square 3\nNow Process 62187 | is calculating square 4\nNow Process 62188 | is calculating square 6\nNow Process 62188 | is calculating square 5\nNow Process 62187 | is calculating square 5\nNow Process 62188 | is calculating square 4\nNow Process 62187 | is calculating square 6\nNow Process 62188 | is calculating square 3\nNow Process 62187 | is calculating square 7\nNow Process 62188 | is calculating square 2\nNow Process 62187 | is calculating square 8\nNow Process 62188 | is calculating square 1\nNow Process 62187 | is calculating square 9\nDone\n</code></pre> In the example above: We define a function prod() to calculate the sum of squares of numbers in a list. We use a multiprocessing.Manager().dict() to share results between processes. We initiate Process objects with target function and arguments, start them with start(), and wait for completion using join(). Unlike the Pool method, the Process approach provides more granular control over individual processes. However, it does not automatically manage worker allocation or load balancing across CPU cores \u2014 this has to be handled manually. Let me know if you\u2019d like a visual or table-based comparison of Process vs Pool.</p>"},{"location":"book/ch10_multiprocessing/ch10_multiprocessing/#sharing-data","title":"Sharing data","text":"<p>Each process has its own memory and CPU, meaning that data stored in one process\u2019s memory is not directly accessible to others. Therefore, to work with shared data across processes, a communication mechanism is needed \u2014 this is known as Inter-Process Communication (IPC). Sharing objects between processes requires explicitly passing data through such communication channels. The Python multiprocessing module provides several built-in methods for IPC, including Pipes, Queues, Managers, and shared memory. In this section, we will explore how to use these tools to enable efficient communication between processes.</p>"},{"location":"book/ch10_multiprocessing/ch10_multiprocessing/#queues","title":"Queues","text":"<p>To pass data between processes, we can use a Queue from the multiprocessing module. In the following example, if a number is even, it is placed into the queue for further processing or communication.</p> <p><pre><code>#File: mp5.py\nimport multiprocessing\nimport os\nimport time\n\ndef prod(x, q, results, key):\n    square = 0\n    for i in x:\n        time.sleep(1)\n        square += i * i\n        print(f\"Now Process {os.getpid()} | is calculating square {i}\")\n        if i % 2 == 0:\n            q.put(i)\n    results[key] = square\n\nif __name__ == \"__main__\":\n    x = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n    y=x[::-1]\n    results = {}\n    q1 = multiprocessing.Queue()\n    q2 = multiprocessing.Queue()\n    p1 = multiprocessing.Process(target=prod, args=(x, q1, results, \"res1\"))\n    p2 = multiprocessing.Process(target=prod, args=(y, q2, results, \"res2\"))\n    # Start task execution\n    p1.start()\n    p2.start()\n    # Wait for process to complete execution\n    p1.join()\n    p2.join()\n    def printqueue(q):\n        while not q.empty():\n            print(\"Received:\", q.get())\n    printqueue(q1)\n    printqueue(q2)\n    print('Done')\n</code></pre> <pre><code>Now Process 10493 | is calculating square 1\nNow Process 10494 | is calculating square 9\nNow Process 10493 | is calculating square 2\nNow Process 10494 | is calculating square 8\nNow Process 10493 | is calculating square 3\nNow Process 10494 | is calculating square 7\nNow Process 10493 | is calculating square 4\nNow Process 10494 | is calculating square 6\nNow Process 10493 | is calculating square 5\nNow Process 10494 | is calculating square 5\nNow Process 10493 | is calculating square 6\nNow Process 10494 | is calculating square 4\nNow Process 10494 | is calculating square 3\nNow Process 10493 | is calculating square 7\nNow Process 10493 | is calculating square 8\nNow Process 10494 | is calculating square 2\nNow Process 10493 | is calculating square 9\nNow Process 10494 | is calculating square 1\nReceived: 2\nReceived: 4\nReceived: 6\nReceived: 8\nReceived: 8\nReceived: 6\nReceived: 4\nReceived: 2\n</code></pre></p>"},{"location":"book/ch10_multiprocessing/ch10_multiprocessing/#pipes","title":"Pipes","text":"<p>In multiprocessing, Pipes are primarily used for communication between processes. A pipe consists of two connection objects, each with send() and recv() methods for sending and receiving data. Below is an example that demonstrates how to use a pipe:</p> <pre><code>#File: mp6.py\nimport time\nimport os\nfrom multiprocessing import Process, Pipe\n\ndef prod(x, pipe_conn):\n    square = 0\n    even_numbers = []\n\n    for i in x:\n        time.sleep(1)\n        square += i * i\n        print(f\"Process {os.getpid()} is calculating square of {i}\")\n        if i % 2 == 0:\n            even_numbers.append(i)\n\n    # Send both results via pipe: even numbers + square sum\n    pipe_conn.send((even_numbers, square))\n    pipe_conn.close()\n\nif __name__ == '__main__':\n    x = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n    parent_conn, child_conn = Pipe()\n\n    p = Process(target=prod, args=(x, child_conn))\n    p.start()\n\n    # Receive result\n    even_numbers, total_square = parent_conn.recv()\n\n    print(\"\\nEven numbers:\", even_numbers)\n    print(\"Total sum of squares:\", total_square)\n\n    p.join()\n</code></pre> <pre><code>#Output: \nProcess 19746 is calculating square of 1\nProcess 19746 is calculating square of 2\nProcess 19746 is calculating square of 3\nProcess 19746 is calculating square of 4\nProcess 19746 is calculating square of 5\nProcess 19746 is calculating square of 6\n\nEven numbers: [2, 4, 6]\nTotal sum of squares: 91\n</code></pre>"},{"location":"book/ch10_multiprocessing/ch10_multiprocessing/#manager","title":"Manager","text":"<p>The multiprocessing.Manager provides a safe way to share different types of objects\u2014such as dictionaries, lists, and more\u2014between processes. It works by running a separate server process that holds the shared objects and allows other processes to access and modify them through proxies.</p> <p><pre><code>#File: mp7.py\nimport time\nimport os\nfrom multiprocessing import Process, Manager\ndef prod(x, results, key):\n    square = 0\n    for i in x:\n        time.sleep(1)\n        square += i * i\n        print(f\"Process {os.getpid()} is calculating square of {i}\")\n    results[key] = square  # Shared dictionary gets updated\nif __name__ == '__main__':\n    x = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n    manager = Manager()\n    results = manager.dict()  # Shared dictionary\n    p = Process(target=prod, args=(x, results, 'square_sum'))\n    p.start()\n    p.join()\n\n    print(\"Total sum of squares:\", results['square_sum'])\n</code></pre> <pre><code># Output\nProcess 25894 is calculating square of 1\nProcess 25894 is calculating square of 2\nProcess 25894 is calculating square of 3\nProcess 25894 is calculating square of 4\nProcess 25894 is calculating square of 5\nProcess 25894 is calculating square of 6\nProcess 25894 is calculating square of 7\nProcess 25894 is calculating square of 8\nProcess 25894 is calculating square of 9\nTotal sum of squares: 285\n</code></pre></p>"},{"location":"book/ch10_multiprocessing/ch10_multiprocessing/#shared_memory","title":"shared_memory","text":"<p>Since Python 3.8, the multiprocessing.shared_memory module has been introduced, allowing data to be shared efficiently between processes\u2014especially useful for large data structures like NumPy arrays. In the example below, we demonstrate how to define and use a shared array.</p> <p><pre><code>#File: mp8.py\nimport numpy as np\nimport multiprocessing\nfrom multiprocessing import shared_memory\n\ndef read_data(shm_name):\n    shm = shared_memory.SharedMemory(name=shm_name)\n    data = np.ndarray((4,), dtype=np.float64, buffer=shm.buf)\n    print(\"Data imported:\", data[:])\n    shm.close()\n\nif __name__ == \"__main__\":\n    shm = shared_memory.SharedMemory(create=True, size=4 * np.float64().nbytes)\n    arr = np.ndarray((4,), dtype=np.float64, buffer=shm.buf)\n    arr[:] = [1.1, 2.2, 3.3, 4.4]\n\n    p = multiprocessing.Process(target=read_data, args=(shm.name,))\n    p.start()\n    p.join()\n\n    shm.close()\n    shm.unlink()\n</code></pre> <pre><code>#Output\nData imported: [1.1 2.2 3.3 4.4]\n</code></pre></p> <p>Now let's define a more advanced function that saves the final result in shared memory.</p> <p><pre><code>#File: mp9.py\nimport os\nimport time\nimport numpy as np\nimport multiprocessing\nfrom multiprocessing import shared_memory\n\ndef prod(x, shm_name, index):\n    # Connect to the shared memory block\n    shm = shared_memory.SharedMemory(name=shm_name)\n    results = np.ndarray((10,), dtype=np.int64, buffer=shm.buf)  # shape must match main array\n    # Compute sum of squares\n    square = 0\n    for i in x:\n        time.sleep(1)\n        square += i * i\n        print(f\"Process {os.getpid()} is calculating square of {i}\")\n    # Write result to shared memory at given index\n    results[index] = square\n    shm.close()\n\nif __name__ == \"__main__\":\n    # Create shared array with 10 slots (adjust as needed)\n    shm = shared_memory.SharedMemory(create=True, size=10 * np.int64().nbytes)\n    results = np.ndarray((1,), dtype=np.int64, buffer=shm.buf)\n    results[:] = 0  # Initialize\n    x = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n    p = multiprocessing.Process(target=prod, args=(x, shm.name, 0))\n    p.start()\n    p.join()\n    print(\"Final shared memory results:\", results[:])\n    shm.close()\n    shm.unlink()  # Clean up shared memory\n</code></pre> <pre><code>#Output\nProcess 46286 is calculating square of 1\nProcess 46286 is calculating square of 2\nProcess 46286 is calculating square of 3\nProcess 46286 is calculating square of 4\nProcess 46286 is calculating square of 5\nProcess 46286 is calculating square of 6\nProcess 46286 is calculating square of 7\nProcess 46286 is calculating square of 8\nProcess 46286 is calculating square of 9\nFinal shared memory results: [285]\n</code></pre></p>"},{"location":"book/ch10_multiprocessing/ch10_overview/","title":"overview","text":"<p>Most modern CPUs have multiple cores, which enable parallel computing in Python. Parallel computing involves performing multiple tasks simultaneously to reduce the overall runtime of a program. In Python, a process is an instance of a program created by the operating system, with its own dedicated memory space. A thread, on the other hand, is a smaller unit of execution within a process. Each process can contain multiple threads, and these threads share the same memory space within the process. Because of this shared memory, if one thread modifies a variable, the change is visible to all other threads in that process. In contrast, separate processes do not share memory\u2014modifying a variable in one process does not affect variables in another process. While threads within a process share memory, they maintain separate stack traces and CPU registers. Multithreading allows multiple threads to run concurrently within a single process, enabling simultaneous execution of smaller tasks. This is one of the ways to achieve parallelism, particularly when tasks are I/O-bound or when you want to optimize resource sharing within a program. The following figure shows difference between multithread proceess, and multiprocessing </p> Multi Threaded &amp; MultiProcessing Env. <p>Python has a feature called the Global Interpreter Lock (GIL), which allows only one native thread to execute Python bytecode at a time. As a result, it prevents multiple threads from running Python code simultaneously within the same process. This limitation exists because Python was originally designed before multi-core processors became common in personal computers.</p> <p>In this section, we review the concepts of multiprocessing and multithreading, which are key to achieving parallelism and concurrency in Python:</p> <ul> <li>Multiprocessing An overview of the multiprocessing module, which enables parallel execution using separate processes that bypass the GIL.</li> <li>Joblib A review of Joblib, a high-level library that simplifies parallel computing, particularly for tasks involving loops and data processing. </li> <li>Multithreading A discussion of the threading module and how multithreading can be used for I/O-bound tasks, despite the GIL.</li> </ul>"},{"location":"book/ch10_multiprocessing/ch10_threading/","title":"Multithreading","text":"<p>Unlike multiprocessing, multithreading executes multiple threads concurrently within the same process. These threads share the same memory space, allowing for efficient communication and data sharing. Multithreading is especially useful for I/O-bound tasks, such as reading files from a network or querying a database, as it allows multiple threads to handle I/O operations simultaneously without blocking each other. In contrast, multiprocessing is more suitable for CPU-bound tasks, as it leverages multiple processors to perform parallel computations\u2014similar to how multicore systems outperform single-core systems for intensive computations.</p>"},{"location":"book/ch10_multiprocessing/ch10_threading/#threading","title":"threading","text":"<p>Python has a built-in module called threading that is used to implement multithreading. The following example demonstrates how to use the threading module to run code concurrently.</p> <pre><code>#name thr1.py\nimport threading\nimport os\nimport time\n\ndef prod(x, results, key):\n    square = 0\n    for i in x:\n        time.sleep(1)\n        square += i * i\n        print(f\"Now Process {os.getpid()} | Thread Name {threading.current_thread().name} | is calculating square {i}\")\n    results[key] = square\n\nif __name__ == \"__main__\":\n    x = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n    x1 = x[0:5]  \n    x2 = x[5:9]  \n    results = {}\n    p1 = threading.Thread(target=prod, name=\"p1\", args=(x1, results, \"res1\"))\n    p2 = threading.Thread(target=prod, name=\"p2\", args=(x2, results, \"res2\"))\n\n    # Start task execution\n    p1.start()\n    p2.start()\n\n    # Wait for threads to complete\n    p1.join()\n    p2.join()\n\n    total = results[\"res1\"] + results[\"res2\"]\n    print(f\"Partial results: {results}\")\n    print(f\"Total sum of squares: {total}\")\n    print('Done')\n\n\n# result 1:  running python3 thr1.py\nNow Process 14075 | Thread Name p1 | is calculating square 1\nNow Process 14075 | Thread Name p2 | is calculating square 6\nNow Process 14075 | Thread Name p1 | is calculating square 2\nNow Process 14075 | Thread Name p2 | is calculating square 7\nNow Process 14075 | Thread Name p1 | is calculating square 3\nNow Process 14075 | Thread Name p2 | is calculating square 8\nNow Process 14075 | Thread Name p1 | is calculating square 4\nNow Process 14075 | Thread Name p2 | is calculating square 9\nNow Process 14075 | Thread Name p1 | is calculating square 5\nPartial results: {'res2': 230, 'res1': 55}\nTotal sum of squares: 285\nDone\n\n# result 2: running python3 thr1.py\nNow Process 13794 | Thread Name p1 | is calculating square 1\nNow Process 13794 | Thread Name p2 | is calculating square 6\nNow Process 13794 | Thread Name p2 | is calculating square 7\nNow Process 13794 | Thread Name p1 | is calculating square 2\nNow Process 13794 | Thread Name p2 | is calculating square 8\nNow Process 13794 | Thread Name p1 | is calculating square 3\nNow Process 13794 | Thread Name p1 | is calculating square 4\nNow Process 13794 | Thread Name p2 | is calculating square 9\nNow Process 13794 | Thread Name p1 | is calculating square 5\nPartial results: {'res2': 230, 'res1': 55}\nTotal sum of squares: 285\nDone\n</code></pre> <p>You can see that both threads share the same process ID, which confirms that they are part of the same process. Additionally, the output is not generated in a strict sequential order. For example, the first line might be produced by thread1, while the second and third lines are from thread2, followed again by output from thread1, and so on.</p> <p>In Result 2, a rerun of the code shows that the order of thread execution has changed, highlighting the non-deterministic nature of thread scheduling.</p> <p>It's important to note that concurrency does not necessarily mean parallel execution. In the case of multithreading in Python (especially due to the Global Interpreter Lock, or GIL), only one thread runs at a time. As a result, it doesn\u2019t actually reduce the total execution time compared to sequential execution. Instead, the CPU switches between threads\u2014pausing one, starting another, and later returning to resume the previous thread from where it left off. This thread switching is what gives the appearance of concurrency but does not achieve true parallelism.</p>"},{"location":"book/ch10_multiprocessing/ch10_threading/#daemon-threads","title":"Daemon Threads","text":"<p>A daemon thread is a background thread that runs alongside the main thread but does not block the main thread\u2019s execution. It runs continuously in the background and is automatically terminated when the main thread finishes, even if the daemon thread is still running or hasn't completed its task.</p> <p>In Python, daemon threads are often used for background tasks such as garbage collection or housekeeping operations that should not prevent the program from exiting. When the main thread ends, all daemon threads are stopped abruptly.</p> <p>To create a daemon thread in Python, you can set the daemon property to True, either using p1.setDaemon(True) (for backward compatibility) or more commonly:</p> <pre><code>#name thr1.py\nimport threading\nimport os\nimport time\n\ndef prod(x, results, key):\n    square = 0\n    for i in x:\n        time.sleep(1)\n        square += i * i\n        print(f\"Now Process {os.getpid()} | Thread Name {threading.current_thread().name} | is calculating square {i}\")\n    results[key] = square\n\n\n\nif __name__ == \"__main__\":\n    x = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n    x1 = x[0:5]  \n    x2 = x[5:9]  \n    results = {}\n    p1 = threading.Thread(target=prod, name=\"p1\", args=(x1, results, \"res1\"))\n    p1.daemon = True  # Set as daemon thread\n    # Start task execution\n    p1.start()\n\n# result :  running python3 thr2.py\nMain thread will sleep for 3 seconds.\nNow Process 20890 | Thread Name p1 | is calculating square 1\nDaemon thread is running...\nNow Process 20890 | Thread Name p1 | is calculating square 2\nDaemon thread is running...\nMain thread exiting... Daemon thread will be killed.\n</code></pre>"},{"location":"book/ch10_multiprocessing/ch10_threading/#threading-in-joblib","title":"Threading in joblib","text":"<p>Let\u2019s use threading with joblib.</p> <pre><code>#name thr2.py\nimport threading\nimport os\nimport time\nfrom joblib import Parallel, delayed\n\ndef prod(x):\n    square = 0\n    for i in x:\n        time.sleep(1)\n        square += i * i\n        print(f\"Now Process {os.getpid()} | Thread Name {threading.current_thread().name} | is calculating square {i}\")\n    return square\n\nx = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n# Split list into chunks for parallel processing\nchunks = [x[0:5],x[6:8] ]  # split into 4 chunks\n\nresults = Parallel(n_jobs=4, backend='threading')(delayed(prod)(chunk) for chunk in chunks)\n\nprint(\"Partial results:\", results)\nprint(\"Total sum of squares:\", sum(results))\n\n# result : running python3 thr2.py\nNow Process 10956 | Thread Name Thread-2 (worker) | is calculating square 7\nNow Process 10956 | Thread Name Thread-1 (worker) | is calculating square 1\nNow Process 10956 | Thread Name Thread-2 (worker) | is calculating square 8\nNow Process 10956 | Thread Name Thread-1 (worker) | is calculating square 2\nNow Process 10956 | Thread Name Thread-1 (worker) | is calculating square 3\nNow Process 10956 | Thread Name Thread-1 (worker) | is calculating square 4\nNow Process 10956 | Thread Name Thread-1 (worker) | is calculating square 5\n</code></pre> <p>Now, let's consider the multiprocessing case\u2014you'll notice that the process IDs have changed.</p> <pre><code>results = Parallel(n_jobs=4)(delayed(prod)(chunk) for chunk in chunks)\n# result :\nNow Process 15654 | Thread Name MainThread | is calculating square 1\nNow Process 15657 | Thread Name MainThread | is calculating square 7\nNow Process 15654 | Thread Name MainThread | is calculating square 2\nNow Process 15657 | Thread Name MainThread | is calculating square 8\nNow Process 15654 | Thread Name MainThread | is calculating square 3\nNow Process 15654 | Thread Name MainThread | is calculating square 4\nNow Process 15654 | Thread Name MainThread | is calculating square 5\n</code></pre>"},{"location":"book/ch11_regex/ch11_challenges/","title":"Challenge","text":"<p>Consider \"the quick brown fox jumps over the lazy dog\" as text,  a) Search for <code>o</code> and show adjacent characters: b) Search for three-letter words enclosed by whitespace: c) Substitute any of <code>dflj</code> by a <code>w</code>:</p> <pre><code>import re\ntext = \"the quick brown fox jumps over the lazy dog\"\nprint(re.findall(\".o.\", text))\nprint(re.findall(\"\\s(\\wo\\w)\\s*\", text))\nprint(re.sub(\"[dflj]\", \"w\", text))\nprint(re.search('jumps|swims', text))\n</code></pre> <p>Recognize phone numbers in Germany <pre><code>import re\npattern = re.compile(\"(00|0 0|\\+)\\s*4\\s*9[0-9 ]+\")\ntext = [\n\"0049 190 34 57 90\",\n\"+49 190 34 57 90\",\n\"00 00 00 49 190 34 57 90 33\",\n\"00 49 190 34 57 90\",\n\"0049190345790\",\n\"+48 60 60 606 9\",\n\"+41 55 55 55 55\"\n]\nfor e in text:\n    if pattern.match(e):\n        print(e, \"is a German phone number\")\n    else:\n        print(e, \"is some other number\")\n</code></pre></p> <p>checking if a string starts with '&gt;' <pre><code>import re;\np = re.compile( '^&gt;' )\nm = p.match( '&gt;hello' )\nif m:\n    print 'Match found: ', m.group()\nelse:\n    print 'No match'\n</code></pre></p> <p>matchin more than one pattern on the same string <pre><code>m=re.search(\"^&gt;|^#\",line)\nif m:\n    print 'Match found: ', m.group()\n</code></pre></p> <p>Consider a text \"All digits are 0 12 245 6789\" a) pattern to find three consecutive digits b) compile string pattern to re.Pattern object c) print the type of compiled pattern</p> <p>import re str = \"All digits are 0 12 245 6789\" string_pattern = r\"\\d{3}\" regex_pattern = re.compile(string_pattern) print(type(regex_pattern)) result = regex_pattern.findall(str) print(result)</p>"},{"location":"book/ch11_regex/ch11_overview/","title":"Overview","text":"<p>This chapter provides a brief overview of regular expression.</p> <ul> <li>Regular expression</li> <li>Challenges</li> </ul>"},{"location":"book/ch11_regex/ch11_regex/","title":"Regular Expression","text":"<p>Regular Expression (RegEx) is a useful way in  extracting and searching a pattern. In Python, <code>re</code> module  is the standard library that work with RegEx. To specify a pattern one can use metacharacters <code>[].^$*+?{}()\\|</code>, Square brackets (<code>[]</code>) specify  a set of chracters you wish to match, i.e., <code>[abcd]</code> will match if the string you are trying to match contains any of the <code>a</code>, <code>b</code>, <code>c</code>, or <code>d</code>. To specify a range, you can use <code>-</code>,, i,e '[a-d]' is the same as <code>[abcd]</code>. <code>[1-4]</code> is the same as <code>[1234]</code>. If you use the caret in a  square-bracket, it means the complements: <code>[^abcd]</code> means any character except <code>a</code> or <code>b</code>, <code>c</code>, or <code>d</code>.  <code>[^0-9]</code> means any non-digit character. A period matches any single character: <code>..</code> means any string of length two. The caret means start: <code>^ab</code> means any string that start with <code>ab</code>. The dollar symbol is used to check if a string ends with a certain character. <code>x$</code> any patter end to x. <code>*</code>  The following table includes the characters that can be used in  RegEx. </p> -- -- <code>\\d</code> matches any decimal digit, <code>[0-9]</code> <code>\\D</code> matches any non-digit character <code>[^0-9]</code> <code>\\n</code> matches any newline <code>\\t</code> matches any any tab <code>\\0</code> matches null character <code>\\s</code> matches any whitespace character <code>[ \\t\\n\\r\\f\\v]</code> <code>\\S</code> matches any non-whitespace character <code>[^ \\t\\n\\r\\f\\v]</code> <code>\\w</code> matches any alphanumeric character <code>[a-zA-Z0-9_]</code> <code>\\W</code> matches any non-alphanumeric character <code>[^a-zA-Z0-9_]</code> <code>[ABC]</code> one of characters A,B,C <code>.</code> any character except new line. <code>^A</code> not A <code>+</code> one or more of the preceding pattern <code>*</code> zero or more of preceding pattern <code>?</code> matches zero or one occurrence <code>a|b</code> either a or b matches <code>(a|c)yz</code> Parentheses () is used to group sub-patterns <code>{n,m}</code> least n, and at most m repetitions of the pattern left to it <code>\\A</code> Matches if the specified characters are at the start of a string \\Athe <code>\\b</code> Matches if the specified characters are at the beginning or end of a word \\bmon and mon\\b. `\\B`` Opposite of \\b. Matches if the specified characters are not at the beginning or end of a word . \\Bmon and mon\\B <p>To specify a regular expression in Python, we precede it with r to create raw strings. The following show what trying with and without <code>r</code>. </p> <pre><code>pattern = '\\t'\nprint(pattern)\npattern = r'\\t'\nprint(pattern)\n</code></pre>"},{"location":"book/ch11_regex/ch11_regex/#match","title":"match","text":"<p>The <code>re.match</code> search for the given pattern, if it occurr, it the span of match object, otherwise it returns None.</p> <pre><code>import re\n\npattern = 'beer'\ntext= 'beer is cool'\nresult = re.match(pattern, text)\n\nif result:\n  print(\"Search successful.\")\nelse:\n  print(\"Search unsuccessful.\") \n</code></pre>"},{"location":"book/ch11_regex/ch11_regex/#search","title":"search","text":"<p><code>search()</code> scan through a string, looking for any location where this RE matches</p> <pre><code>pattern = r'beer'\ntext= 'the beer is cold, beer'\nresult = re.search(pattern, text)\nresult\n</code></pre>"},{"location":"book/ch11_regex/ch11_regex/#findall","title":"findall","text":"<p><code>findall()</code> find all substrings where the RE matches, and returns them as a list</p> <pre><code>re.findall('1', '123411')\n</code></pre>"},{"location":"book/ch11_regex/ch11_regex/#finditer","title":"finditer","text":"<p><code>finditer()</code> find all substrings where the RE matches, and return them as an iterator</p> <pre><code>pattern = r'beer'\ntext= 'beer is cheap, bear'\nresult = re.finditer(pattern, text)\nresult\n</code></pre> <p>since it is a iterator, you can put it in a loop </p> <pre><code>for m in re.finditer(pattern, text):\n    print('%02d-%02d: %s' % (m.start(), m.end(), m.group(0)))\n</code></pre>"},{"location":"book/ch11_regex/ch11_regex/#sub","title":"sub","text":"<p>The general syntax of <code>sub</code> is <code>re.sub(pattern, replace, string, count)</code>. The default <code>count</code> is zero and replace the first one, <code>count=1</code> will replace all occurrences.</p> <p><pre><code>text= 'beer is cheap, 10$'\nre.sub('e','E',text)\nurl = 'company.com'\nre.sub('\\.com$', '.ai', url)\n</code></pre> To count the number of replace, you can use <code>subn</code></p>"},{"location":"book/ch11_regex/ch11_regex/#split","title":"split","text":"<p>The function <code>splits</code> drop the string where there is a match and returns a list of strings where the splits have occurred.</p> <pre><code>text= 'beer is cheap, 10$'\nre.split('is',text)\n</code></pre> <p>Flag  <code>maxsplit=1</code> will replace all occurrences.</p>"},{"location":"book/ch11_regex/ch11_regex/#repetition","title":"Repetition","text":"<p>In the case you need a repetition, write a bracket infront it and specify the number of times a pattern should repetited, for example <code>\\d{3}</code> is equvalent to <code>\\d\\d\\d</code>. You can specify a range for repitition for example <code>\\d{2,4}</code> means mathc to ditigal of length, 2, 3, and 4, e.g., 10, 101 and 1010. Using this notation you can state <code>*</code> and <code>+</code> are  equivalent to {0,} and <code>{1,}</code>, e.g., <code>\\d+</code> find numbers of any arbitrary length. </p>"},{"location":"book/ch11_regex/ch11_regex/#compile","title":"compile","text":"<p>You can compile a regular expression pattern provided as a string into a regex pattern object and you can use the pattern object to search for a match inside different target strings using regex methods such as a re.match() or re.search(). It is useful that you want to use the same pattern over and over again. </p> <pre><code>pattern = r\"\\d{3}\"\nregex = re.compile(pattern)\nprint(type(regex))\nstr = \"the numbers are 1 23 456 7890\"\nresult = regex.findall(str1)\nprint(result)\n</code></pre>"},{"location":"book/ch12_debugging/ch12_challenges/","title":"Challenge","text":""},{"location":"book/ch12_debugging/ch12_challenges/#challenge-1","title":"Challenge 1","text":"<p>Write a class that takes a salary as input, and raises an error if the salary is not within the range of 5000 to 15000.</p> Respond: <pre><code>class SalaryNotInRangeError(Exception):\n    \"\"\"Exception raised for errors in the input salary.\n    Attributes:\n        salary -- input salary which caused the error\n        message -- explanation of the error\n    \"\"\"\n    def __init__(self, salary, message=\"Salary is not in (5000, 15000) range\"):\n        self.salary = salary\n        self.message = message\n        super().__init__(self.message)\n    def __str__(self):\n        return f'{self.salary} -&gt; {self.message}'\n\n\nsalary = int(input(\"Enter salary amount: \"))\nif not 5000 &lt; salary &lt; 15000:\n    raise SalaryNotInRangeError(salary)\n</code></pre>"},{"location":"book/ch12_debugging/ch12_debugging/","title":"-- Debugging","text":""},{"location":"book/ch12_debugging/ch12_debugging/#title-debugging","title":"title: Debugging","text":""},{"location":"book/ch12_debugging/ch12_debugging/#reading-traceback","title":"Reading Traceback","text":"<p>The following demonstrates how to use the <code>sys</code> function to determine what error occurred. Let's try a simple mathematical operation and see which error might arise.</p> <pre><code>list_n = [2,1,0]\nfor entry in list_n:\n        entry=entry*2\n        print(\"The entry is\", entry)\n        print('DEBUG:', repr(entry))\n        r = 1/int(entry)\nprint('End of code')\n</code></pre> <pre><code>python3 temp.py\n\nThe entry is 2\nThe entry is 1\nThe entry is 0\nTraceback (most recent call last):\n  File \"./temp.py\", line 4, in &lt;module&gt;\n    r = 1/int(entry)\n        ~^~~~~~~~~~~\nZeroDivisionError: division by zero\n(venv) samamiri@Sams-MacBook-Pro python-practice0 % \n</code></pre> <p>It shows that the program crashed on the last line. Of course, this isn't always easy to diagnose, so you can copy the error message and paste it into Google for more help.</p>"},{"location":"book/ch12_debugging/ch12_debugging/#interactively","title":"Interactively","text":"<p>To run interactively or in a REPL (Read-Eval-Print Loop), use the <code>-i</code> option to keep Python running.</p> <pre><code>python3 -i temp.py\n</code></pre> <p>When an error occurs, the Python environment pops up, allowing you to interactively work within Python to troubleshoot the error.</p>"},{"location":"book/ch12_debugging/ch12_debugging/#warning","title":"Warning","text":"<p>If you need to keep track of warnings, use the warnings module. The warning messages will be stored in <code>sys.stderr</code>.</p> <pre><code>import warnings\nlist_n = [2,1,0]\nfor entry in list_n:\n    print(\"The entry is\", entry)\n    if entry == 0:\n            warnings.warn(\"This is a warning note\")\n    r = 1/int(entry)\nprint('End of code')\n</code></pre> <p>If you want the program to stop execution as soon as a warning occurs, use the <code>-W error</code> option when running the script.</p> <p><pre><code>python -W error temp.py\n</code></pre> To mute all warning use <code>-W ignore</code></p> <pre><code>python -W ignore temp.py\n</code></pre>"},{"location":"book/ch12_debugging/ch12_debugging/#run-under-debugger","title":"Run under debugger","text":"<p>You can manually add a debugger into your code using <code>breakpoint()</code>, which calls the <code>sys.breakpointhook()</code> function\u2014by default, this invokes pdb.set_trace() from the pdb module. Alternatively, you can run an entire program under the debugger by inserting <code>pdb.set_trace()</code> directly.</p> <pre><code>list_n = [2,1,0]\nfor entry in list_n:\n    print(\"The entry is\", entry)\n    breakpoint()\n    r = 1/int(entry)\nprint('End of code')\n</code></pre> <pre><code>python3 -m pdb temp.py\nThe entry is 2\n&gt; ./temp.py(6)&lt;module&gt;()\n-&gt; r = 1/int(entry)\n(Pdb) \n</code></pre> <p>Then you can use debugger commands to step through the code. Type <code>c</code> to continue execution. Use !statement to execute a Python statement, and <code>!entry</code> to view the current value of the variable <code>entry</code>.</p> <pre><code>(Pdb) !entry\n2\n</code></pre> <p>You can use the following code to help debug your program.</p> Command Syntax Description help Get help w where Print stack trace d down Move down one stack level u up Move up one stack level b loc break loc Set a breakpoint s step Execute one instruction c continue Continue execution l list List source code a arg Print args of current function !statement Execute statement"},{"location":"book/ch12_debugging/ch12_error_handling/","title":"Error Handling","text":"<p>The <code>try.. except</code> statement allows your program to catch and handle errors instead of terminating unexpectedly.  To manage errors gracefully, you can use <code>try ... except</code>, its basic structure is as follows:</p>"},{"location":"book/ch12_debugging/ch12_error_handling/#simple-exception","title":"simple Exception","text":"<pre><code>try:\n   operations;\nexcept ExceptionI:\n   If there is ExceptionI, then execute this block.\nexcept ExceptionII:\n   If there is ExceptionII, then execute this block.\n   ...\nelse:\n   If there is no exception then execute this block. this part arbitary and can be dropt.  \nfinally: \n   This block always runs.\n</code></pre> <p>The following show how to use <code>sys</code> function to find out what error happen, let try a simple mathemtic operation and see what error might happen.    </p> <pre><code>import sys\nlist_n = ['a',0, 3]\nfor entry in list_n:\n    try:\n        print(\"The entry is\", entry)\n        r = 1/int(entry)\n    except:\n        print(\"Oops!\", sys.exc_info()[0], \"occurred.\")\n        print(\"Next entry.\")\n</code></pre> <p>You see two error  'ValueError' and 'ZeroDivisionError'....</p>"},{"location":"book/ch12_debugging/ch12_error_handling/#assert","title":"assert","text":"<p>The assert statement is useful for debugging, as it tests a condition in your code.  If the condition is not True, the program raises an AssertionError.</p> <pre><code>while True:\n        num = int(input(\"Enter a number: \"))\n        assert num % 2 == 0 , \"Not an Even number\" \n        reciprocal = 1/num\n        print(reciprocal)\n</code></pre> <pre><code>while True:\n    try:\n        num = int(input(\"Enter a number: \"))\n        assert num % 2 == 0 , \"An even number\"\n    except:\n        print(\"Not an even number!\")\n        break\n    else:\n        reciprocal = 1/num\n        print(reciprocal)\n</code></pre>"},{"location":"book/ch12_debugging/ch12_error_handling/#exception-configuration","title":"Exception configuration","text":"<p>User can set up and control how exceptions determining what happens when an error occurs, how it is reported. </p>"},{"location":"book/ch12_debugging/ch12_error_handling/#exception-class","title":"Exception class","text":"<p>We can detect error withous using <code>sys</code>. Since every exception in Python inherits from the base Exception class, we can achieve the same result using the following approach:</p> <pre><code>import sys\nlist_n = ['a',0, 3]\nfor entry in list_n:\n    try:\n        print(\"The entry is\", entry)\n        r = 1/int(entry)\n    except Exception as e:\n        print(\"Oops!\", e.__class__, \"occurred.\")\n        print(\"Next entry.\")\n</code></pre> <p>Try the following which show you can handle the error inside the <code>try</code>. Run the following code with -1, 1, 'a'. </p> <pre><code>try:\n     a = int(input(\"Enter a positive integer: \"))\n     if a &lt;= 0:\n         raise ValueError(\"That is not a positive number!\")\nexcept Exception as ve:\n     print(ve)\n</code></pre>"},{"location":"book/ch12_debugging/ch12_error_handling/#indexerror","title":"IndexError","text":"<p>This error occurs when you try to assign a value to an index that is beyond the valid range of indices in the list.</p> <pre><code>tournaments = [\"NAGA\", \"IBJJF\", \"EBI\"]\nwhile True:\n    try:\n        tournament = tournaments.pop()\n        print(f\"I would like to compete in the {tournament} tournament.\")\n    except IndexError:\n        print(\"There are no more tournaments\")\n        break\n</code></pre>"},{"location":"book/ch12_debugging/ch12_error_handling/#raise","title":"Raise","text":"<p>You can define your own types of Exception types:</p> <pre><code>i_num = int(input(\"Enter a number: \"))\nif i_num &lt; number:\n    raise RuntimeError(f'{i_num} is small')\n</code></pre> <p>You can use raise with try to handle exceptions. Let's consider defining a function that raises an error if the input number is less than or greater than zero. First, define the base class to propagate the error:</p> <pre><code>class Error(Exception):\n    \"\"\"Base class for other exceptions\"\"\"\n    pass\n</code></pre> <p>Then, specify the errors and pass the exception to them.</p> <pre><code>class ErrorTooSmall(Error):\n    \"\"\"Raised when the input value is too small\"\"\"\n    pass\n\nclass ErrorTooLarge(Error):\n    \"\"\"Raised when the input value is too large\"\"\"\n    pass\n</code></pre> <p>Now, run the following to </p> <pre><code>number = 10\n\nwhile True:\n    try:\n        i_num = int(input(\"Enter a number: \"))\n        if i_num &lt; number:\n            raise ErrorTooSmall\n        elif i_num &gt; number:\n            raise ErrorTooLarge\n        print(\"Congratulations! You guessed it correctly.\")\n        break\n    except ErrorTooSmall:\n        print(\"This value is too small, try again!\")\n        print()\n    except ErrorTooLarge:\n        print(\"This value is too large, try again!\")\n        print()\n</code></pre>"},{"location":"book/ch12_debugging/ch12_error_handling/#catching-multiple-errors","title":"Catching Multiple Errors","text":"<p>You can catch different types of exceptions by using multiple <code>except</code> blocks.</p> <pre><code>try:\n  ...\nexcept LookupError as e:\n  ...\nexcept RuntimeError as e:\n  ...\nexcept IOError as e:\n  ...\nexcept KeyboardInterrupt as e:\n  ...\n</code></pre> <p>Alternatively, if the handling statements are the same, you can group the exceptions together:</p> <pre><code>try:\n  ...\nexcept (IOError,LookupError,RuntimeError) as e:\n  ...\n</code></pre>"},{"location":"book/ch12_debugging/ch12_error_handling/#catching-all-errors","title":"Catching All Errors","text":"<p>To catch any exception, use <code>Exception</code> like this:</p> <pre><code>try:\n    ...\nexcept Exception:       # DANGER. See below\n    print('An error occurred')\n</code></pre>"},{"location":"book/ch12_debugging/ch12_error_handling/#ioerror","title":"IOError","text":"<p>The following code shows how to handle the recognized IOError in your code.</p> <pre><code>#!/usr/bin/python\n\ntry:\n   fh = open(\"testfile\", \"w\")\n   fh.write(\"This is my test file for exception handling!!\")\nexcept IOError:\n   print \"Error: can\\'t find file or read data\"\nelse:\n   print \"Written content in the file successfully\"\n   fh.close()\n</code></pre>"},{"location":"book/ch12_debugging/ch12_logging/","title":"Logging","text":"<p>To debug the code, you need to collect information and analyze it after execution. This section briefly introduces the logging module. The <code>logging</code> module is a standard Python module used to record diagnostic messages in a log file.</p>"},{"location":"book/ch12_debugging/ch12_logging/#simple-configurarion","title":"Simple configurarion","text":"<p>The following is a simple code example that shows how to use the logging module.</p> <pre><code>import logging\nlogging.basicConfig(\n    filename  = 'debug.log',      # Log output file\n    level     = logging.INFO,   # Output level\n)\n\nlist_n = ['a',0, 1, 2, 'b']\nfor entry in list_n:\n        print(\"The entry is\", entry)\n        logging.info(f' computation for {entry} started')\n        r = 1/int(entry)\n        logging.debug(f' computation is done for {entry}')\nlogger.info(f'Process id Done')\n</code></pre> <p>logging.basicConfig is a one-time configuration at the beginning. Later, we'll show how you can change the configuration. There are different logging levels: <code>DEBUG</code>, <code>ERROR</code>, <code>WARNING</code>, <code>INFO</code>, and <code>CRITICAL</code>. By choosing a level, you can filter messages, such as sending INFO and WARNING to sys.stdout, INFO, WARNING, and ERROR (and above) to sys.stderr, and the rest to a file named app.log.</p>"},{"location":"book/ch12_debugging/ch12_logging/#logging-configuration","title":"Logging Configuration","text":"<p>Let use <code>try-except</code> statement</p> <pre><code>import sys\nimport logging\n# create a logger with 'test_application'\nlogger = logging.getLogger('test_application')\nlogger.setLevel(logging.DEBUG)\n# create file handler which logs even debug messages\nfh = logging.FileHandler('file.log')\nfh.setLevel(logging.DEBUG)\n# create console handler with a higher log level\nch = logging.StreamHandler()\nch.setLevel(logging.ERROR)\nfh.setLevel(logging.DEBUG)\n# create formatter and add it to the handlers\nformatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\nfh.setFormatter(formatter)\nch.setFormatter(formatter)\n# add the handlers to the logger\nlogger.addHandler(fh)\nlogger.addHandler(ch)\n\nlist_n = ['a',0, 1, 2, 'b']\nfor entry in list_n:\n    try:\n        print(\"The entry is\", entry)\n        r = 1/int(entry)\n        logger.info(f' computation is done for {entry}')\n    except Exception as e:\n        print(f'Reason: Oops!, {e.__class__} occurred.')\n        logger.warning(f' Could not compute for {entry}')\n        logger.debug(f'Reason: Oops!, {e.__class__} occurred.')\n    finally: \n        logger.info(f'Next entry')\nlogger.info(f'Process id Done')\n</code></pre> <p>Most programs use <code>logging.getLogger(__name__)</code> instead of specifying a name directly. We can rewrite the function as follows:</p> <pre><code># main.py\nimport sys\nimport logging\n\nlist_n = ['a',0, 1, 2, 'b']\n\ndef reciptocal(list_n):\n    for entry in list_n:\n        try:\n            print(\"The entry is\", entry)\n            r = 1/int(entry)\n            logger.info(f' computation is done for {entry}')\n        except Exception as e:\n            print(f'Reason: Oops!, {e.__class__} occurred.')\n            logger.warning(f' Could not compute for {entry}')\n            logger.debug(f'Reason: Oops!, {e.__class__} occurred.')\n        finally: \n            logger.info(f'Next entry')\n    logger.info(f'Process id Done')\n\n\nif __name__ == '__main__':\n    # create a logger with 'test_application'\n    logger = logging.getLogger(__name__)\n    logger.setLevel(logging.DEBUG)\n    # create file handler which logs even debug messages\n    fh = logging.FileHandler('file.log')\n    fh.setLevel(logging.DEBUG)\n    # create console handler with a higher log level\n    ch = logging.StreamHandler()\n    ch.setLevel(logging.ERROR)\n    fh.setLevel(logging.DEBUG)\n    # create formatter and add it to the handlers\n    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n    fh.setFormatter(formatter)\n    ch.setFormatter(formatter)\n    # add the handlers to the logger\n    logger.addHandler(fh)\n    logger.addHandler(ch)\n    reciptocal(list_n)\n</code></pre>"},{"location":"book/ch12_debugging/ch12_overview/","title":"Overview","text":"<p>This section covers fundamental topics related to testing, logging, and debugging. These topics are essential because the standard does not include a compiler to catch bugs automatically. Therefore, the only way to ensure your code works correctly is to run it and thoroughly test all of its features.</p> <ul> <li>Error handling This section explain how to handle error handling, detecting, and responding to errors that occur during the execution of a program.</li> <li>Logging This section discusses the logging module, which provides a flexible framework for generating log messages. It allows you to track events that occur during your program's execution, which is essential for debugging, monitoring, and maintaining your code.</li> <li>Debugging Here, we explain the process of identifying, analyzing, and fixing bugs in Python code.</li> <li>Challenges</li> </ul>"},{"location":"book/ch13_package/ch13_distribution/","title":"Distribution","text":"<p>Here we present the most basic technique to share, for more information look  at Python Packaging User Guide.</p>"},{"location":"book/ch13_package/ch13_distribution/#setuppy-file","title":"setup.py file","text":"<p>In the first step, create <code>setup.py</code> file to the top-level of your project: </p> <pre><code># setup.py\nimport setuptools\n\nsetuptools.setup(\n    name=\"mypachage\",\n    version=\"0.0.1\",\n    author=\"Saeid Amiri\",\n    author_email=\"saeid.amiri1@gmail.com\",\n    description=\"Training course on python\",\n    packages=setuptools.find_packages(),\n)\n</code></pre> <p>Create <code>requirements.txt</code> and put the necessary package there. Now you can install the package</p> <pre><code>python3.10 -m pip install ./docs/comp/mypachage\n</code></pre> <p>If you want to share the source as a ZIP archive, run the command below. It will create a <code>dist/</code> directory and store a <code>.tar.gz</code> file there. <pre><code>cd ./docs/comp/mypachage\npython3.10 setup.py sdist\n</code></pre></p> <p>You can use it to install the package.</p> <pre><code>python3.10 -m pip install mypachage-0.0.1.tar.gz\n</code></pre>"},{"location":"book/ch13_package/ch13_distribution/#github","title":"Github","text":"<p>You can share the source on GitHub and share it with others. To install from GitHub, you only need the repository's path.</p> <pre><code>pip install 'git+https://github.com/saeidamiri1/mypachage'\n</code></pre> <p>If you want to import a module instead of the entire package, you can do so by.</p> <pre><code>import urllib.request\nurl = 'https://raw.githubusercontent.com/saeidamiri1/ESLR/master/PythonCode/ESRL.py'\ncontents = urllib.request.urlopen(url).read()\nexec(contents)\n</code></pre>"},{"location":"book/ch13_package/ch13_overview/","title":"overview","text":"<p>This section covers the structure of Python packages and discusses how to organize your code for sharing with others or reusing it in different projects. Here, we describe the basic steps for creating a minimal Python package.</p> <ul> <li>Package Here, we briefly explain how to organize and structure related Python modules (files containing Python code) into directories.</li> <li>Distribution We explain how to package a Python library so it can be easily shared, installed, and reused. </li> </ul>"},{"location":"book/ch13_package/ch13_package/","title":"Package","text":"<p>As we discussed in module,  any python source called module. Here we discussed packages which is actually a collection of modules.</p> <p>The companion to [chapter13] includes an example of a simple package, which you can refer to for guidance.</p> <pre><code># To this\npachage_temp/\n    __init__.py\n    main.py\n    sub1/\n        __init__.py\n        sub1_mod1.py\n    sub2/\n        __init__.py\n        sub2_mod2.py\n</code></pre> <p>For any folder you need to have  <code>__init__.py</code> which may be empty, it makes Python treat directories containing it as modules. The code inside <code>__init__.py</code> runs automatically when we import the package, so it executes initialization code for the package. A package serves as namespace for space which can be multilevel imports. Now can run the code as below </p> <pre><code>cd ./mypachage\nimport mypachage.main as  mym\nmym.func1()\n\nfrom mypachage.main import func1\nfunc1()\n\nimport mypachage.sub1.mod1 as mys\nmys.func2()\n</code></pre> <p>After running, python create the file <code>__pycache__</code> that's sitting in your directory. This contains pre-compiled Python modules from before. You can remove it.</p>"},{"location":"book/ch13_package/ch13_package/#initpy","title":"init.py","text":"<p>As you notice, to call function we need to call function via module, to extract function, one can add module\\submodules in <code>__init__</code> which imported when it run: </p> <pre><code># in __init__.py\nprint(\"Initializing __init__ from mypachage\")\nfrom .main import *\n</code></pre> <p>Now one can import the function directly.  <pre><code>from mypachage1 import func1\n</code></pre></p>"},{"location":"book/ch13_package/ch13_package/#name-main","title":"name == 'main':","text":"<p>At the end of module, we add   <code>if __name__ == '__main__':</code> the code after it executes only when you run entire code, hence it does not execute execute when you import function from it</p> <pre><code>python3 ./mypachage1/main.py\n</code></pre>"},{"location":"book/ch13_package/ch13_package/#all","title":"all","text":"<p>As you may know, when you run: <code>from mymodule import *</code>. Python imports all names defined in the module except those that start with an underscore (). However, you can control which functions or classes get imported using the special variable __all_.</p> <pre><code># mymodule.py\n\n__all__ = ['func1', 'class1']\n\ndef func1():\n    print(\"func1 is loaded\")\n\ndef func2():\n    print(\"func2 is loaded\")\n\nclass class1:\n    pass\n\nclass class2:\n    pass\n</code></pre> <p>Now, if you do:</p> <pre><code>from mymodule import *\nfunc1()        # \u2705 works\nfunc2()        # \u274c NNameError: name 'func2' is not defined.\nclass1()      # \u2705 works\nclass2()        # \u274c NameError: name 'class2' is not defined\n</code></pre> <p>If all is not defined, from mymodule import * will import all names that do not start with an underscore (_).</p> <p>In a package, you can also define all in the init.py file to control what gets imported when using a wildcard import from the package.</p>"},{"location":"book/ch14_misc/ch14_json/","title":"Convert a dictionary to a JSON-formatted string:","text":"<p>import json</p> <p>data = {'first': 1, 'second': 'two', 'third': [3,4,5]} jj = json.dumps(data) print(jj)</p>"},{"location":"book/ch14_misc/ch14_json/#convert-json-string-back-to-a-python-dictionary","title":"Convert JSON string back to a Python dictionary:","text":"<p>d = json.loads(jj) print(d)</p>"},{"location":"book/ch14_misc/ch14_json/#save-as-json","title":"Save as json","text":"<p>with open('data.json', 'w') as outfile:     json.dump(data, outfile)</p> <p>read jason  with open('data.json', 'rb') as outfile:     res2 = json.load(outfile)</p> <p>print(res2) </p>"},{"location":"book/ch14_misc/ch14_overview/","title":"Overview","text":"<p>Under Construction</p>"},{"location":"book/ch1_primer/ch1.gitignore/","title":"Ch1.gitignore","text":"In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! <pre>In the following Video, I present how I use vscode to do programming.\n</pre> In the following Video, I present how I use vscode to do programming.  In\u00a0[\u00a0]: Copied! <pre>&lt;iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/3xHFCpglNxA?si=2S6G0IptvNDfYBzj\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen&gt;&lt;/iframe&gt;\n</pre> <p>########################</p>"},{"location":"book/ch1_primer/ch1_challenges/","title":"Challenge","text":""},{"location":"book/ch1_primer/ch1_challenges/#challenge-1","title":"Challenge 1","text":"<p>Write a function to count the number of non-vowel in a string?  </p> Respond: <pre><code>def repit(x):\n    num_nvow=num_vow=num_nodig=0\n    for char in x: \n            if char in \"aeiou\":\n                num_vow += 1\n            elif char.isdigit():\n                num_nodig += 1\n            else:\n                num_nvow +=1\n    return(num_nvow,num_vow,num_nodig)\n</code></pre>"},{"location":"book/ch1_primer/ch1_challenges/#challenge-2","title":"Challenge 2","text":"<p>pi can be estimated using using infinite series. Write a function to estimate it for a given en error.</p>"},{"location":"book/ch1_primer/ch1_challenges/#challenge-3","title":"Challenge 3","text":"<p>Write a function to calculate the Euclidean distance</p> Respond: <pre><code>Exercise:  distance between two rows\ndef dis_col(ma,j1,j2):\n n=mat.shape\n d=0\n for i in range(n[0]):\n   d+=(mat[i,j1]-mat[i,j2])**2\n return d**.5\n\ndef dis_euc(mat):\n n=mat.shape\n di=np.empty((n[1],n[1]))\n for i in range(n[1]):\n   for j in range(n[1]):\n    if i==j:\n     di[i,j]=0\n    elif i&lt;j:\n      di[i,j]=dis_col(mat,i,j)\n    else:\n      di[i,j]=di[j,i]      \n return di  \n\ndis_euc(mat)\n</code></pre>"},{"location":"book/ch1_primer/ch1_challenges/#challenge-4","title":"Challenge 4","text":"<p>Write a function select a random number between 0 and 100, then you give you hints to find it.</p>"},{"location":"book/ch1_primer/ch1_challenges/#challenge-5","title":"Challenge 5","text":"<p>Write an iterate function on dictionary.</p> Respond: <pre><code># A generator expression\nd={'Ryan':4,'Leila':65, 'Saeid':90 }\nfor i,j in d.items():\n print(i,'weight is',j)\n</code></pre>"},{"location":"book/ch1_primer/ch1_challenges/#challenge-6","title":"Challenge 6","text":"<p>Write a script to find the number of duplication of items. </p> Respond: <pre><code>x=(1,2,3,2,3,1,3,3)\nrep={}\nfor i in range(1,len(x),1):\n  if x[i] not in rep:\n        rep[x[i]]=x.count(x[i])\n</code></pre>"},{"location":"book/ch1_primer/ch1_challenges/#challenge-7","title":"Challenge 7","text":"<p>Write factorial function </p> Respond: <pre><code>def factorial(n):\n if n==1:\n    return 1\n if n&lt;0:\n     print(\" your number is negative value\")\n elif abs(int(n)-n)&gt;0:\n # you can use not(isinstance(n,int))\n    print(\"Not define\")\n else:\n    return n*factorial(n-1)\n</code></pre>"},{"location":"book/ch1_primer/ch1_challenges/#challenge-8","title":"Challenge 8","text":"<p>Write a function return the Fibonacci number</p> Respond: <pre><code>def fib(n):\n    if n==1:\n      return  1\n    elif n==2:\n      return  1 \n    else:\n      return fib(n-1)+fib(n-2)\n\nfib(4)\n\ndef fib1(n):\n    if n==0 or n==1: \n    % if n in [0,1]: \n        return 1\n    else:\n        return fib1(n-1)+fib1(n-2)\n\nprint([fib1(i) for i in range(10)])\n\ndef fib2(i):\n    a, b=0, 1\n    for n in range(1,i+1):\n        a,b=b, a+b\n        return b\n\nprint([fib2(n) for n in range(10)])\n\ndef fib_helper(n):\n    if n &lt; 2:\n        return n\n    return fib_helper(n - 1) + fib_helper(n - 2)\n\n\ndef fib(n):\n    return fib_helper(n)\n</code></pre>"},{"location":"book/ch1_primer/ch1_challenges/#challenge-9","title":"Challenge 9","text":"<p>Write a function get a string and a letter, and find the position of letter </p> Respond: <pre><code>def find(word, letter):\n    index=0\n    while index &lt;len(word):\n        if word[index]==letter:\n            print(index+1)\n        index=index+1\n\nword='a'\nletter='saeid'\nfind('saeid','s')\n</code></pre>"},{"location":"book/ch1_primer/ch1_challenges/#challenge-10","title":"Challenge 10","text":"<p>The following is a list generated using for, rewrite it using a list comprehension</p> Respond: <pre><code>x = []\nfor i in range(3):\n    for j in range(2):\n        x.append((i, j))\nprint(x)\n</code></pre> <pre><code>x=[(i, j) for i in range(3) for j in range(2)]\n</code></pre>"},{"location":"book/ch1_primer/ch1_challenges/#challenge-11","title":"Challenge 11","text":"<p>Write a code to display the indices of elements in a list that satisfy a given criterion.</p> Respond: <pre><code>x = [7,2,6,1,4,5,7,8,4]\nlow=3\nup=8\n\n[i for i in range(len(x)) if ((x[i]&gt;low) &amp; (x[i]&lt;up))]\n</code></pre>"},{"location":"book/ch1_primer/ch1_challenges/#challenge-12","title":"Challenge 12","text":"<p>Explain what the following code does, then simplifies as a list comprehension.</p> Respond: <pre><code>x_even = map(lambda x: x*x, filter(lambda x: x%2 == 0, range(10)))\nprint(list(x_even))\n</code></pre> <pre><code>[x**2 for x in range(5) if x%2 == 0 ]\n</code></pre>"},{"location":"book/ch1_primer/ch1_challenges/#challenge-13","title":"Challenge 13","text":"<p>Write a comprehension, get a list and drop 1<sup>st</sup>, and 3th obs.</p> Respond: <pre><code>obs=range(1,10)\n[x for (i,x) in enumerate(obs) if i not in (0,2)]\n</code></pre>"},{"location":"book/ch1_primer/ch1_challenges/#challenge-14","title":"Challenge 14","text":"<p>Write a comprehension that select number that are divisible by 3 and 5 between 1 and 100</p> Respond: <pre><code>obs=range(1,101)\n[x for x in obs if x%3==0 and x%5==0]\n</code></pre>"},{"location":"book/ch1_primer/ch1_challenges/#challenge-15","title":"Challenge 15","text":"<p>Write a function find unique number. Hint: first sort it, then compare pairwisely and drop the duplicate.</p> Respond: <pre><code>def sort0(x):\n  x1=sorted(x)\n  x_sorted=[x1[0]]\n  for i in x1[1:]:\n   if i!=x_sorted[-1]:\n    x_sorted.append(i)\n  return print(\"unique of \",x, \"is\", x_sorted)\n\nobs=[1,4,1,4,2,2,1,4,2,5]\nsort0(obs)\n</code></pre>"},{"location":"book/ch1_primer/ch1_challenges/#challenge-16","title":"Challenge 16","text":"<p>Using map and filter, write a function find cube of odd number between 1 and 20.</p> Respond: <pre><code>x0=list(range(20))\nlist(map(lambda x: x**3,filter(lambda x: x/2!=0,x0)))\n</code></pre>"},{"location":"book/ch1_primer/ch1_challenges/#challenge-17","title":"Challenge 17","text":"<p>Drop the duplication from a list With a given list without changing the original order.</p> Respond: <pre><code>def remove_dub(x):\n    clean0=[]\n    seen0=set()    \n    for i in x:\n        if i in seen0: \n            next\n        else :\n            seen0.add(i); clean0.append(i)\n    return (clean0)\n</code></pre>"},{"location":"book/ch1_primer/ch1_editor/","title":"Editor","text":"<p>We often use the command line, but users can utilize an interactive Python command line called IPython, which offers more functionality. IPython is a module that can be installed via <code>pip install ipython</code>. For instance, by using <code>!</code>, system shell commands can be passed directly to Python. Additionally, you can measure the running time of a function using the <code>%timeit</code> magic command.</p> <pre><code>(venv) samamiri@Sams-MacBook-Pro ~ % ipython\nPython 3.11.10 (main, Sep  7 2024, 01:03:31) [Clang 15.0.0 (clang-1500.3.9.4)]\nType 'copyright', 'credits' or 'license' for more information\nIPython 8.26.0 -- An enhanced Interactive Python. Type '?' for help.\n\nIn [1]: var=!ls\n\nIn [2]: print(var)\n['Applications', 'Desktop', 'Documents', 'Downloads', 'Google Drive', 'Library', 'Movies', 'Music', 'Pictures', 'Public', 'aa.htlm', 'bin', 'quiztudy.com', 'temp', 'venv']\n\nIn [3]: %timeit 2+2\n4.82 ns \u00b1 0.00562 ns per loop (mean \u00b1 std. dev. of 7 runs, 100,000,000 loops each)\n</code></pre> <p>More details can be found in ipython documetation. </p> <p>Instead of using the command line, you can choose from several useful editors for Python, such as VS Code, PyCharm, IPython, Jupyter, Spyder</p>"},{"location":"book/ch1_primer/ch1_editor/#jupyter","title":"Jupyter","text":"<p>The Jupyter Notebook is a web-based interactive computational environment for programming, used to create and share documents containing live code, equations, visualizations, and narrative text. JupyterLab, the next-generation interface for Project Jupyter, offers a more flexible and powerful user experience. Jupyter saves files with the <code>.ipynb</code> extension, which stores the notebook's content. Some editors, such as VS Code (described below), support <code>.ipynb</code> files.</p>"},{"location":"book/ch1_primer/ch1_editor/#vs-code","title":"VS Code","text":"<p>VS Code is a free, modern, and powerful integrated development environment (IDE) developed by Microsoft. It is available for Windows, Linux, macOS, and even web browsers. VS Code is widely used for coding, debugging, and managing projects in various programming languages, including Python, Bash, and more.</p> <p>After spending a significant amount of time coding and editing with VS Code, I would like to share my setup and recommendations. Once you install it, follow these steps to optimize your experience:</p> <ul> <li>Connect VSCode to GitHub for seamless version control.</li> <li>Choose the right theme to enhance readability and comfort.</li> <li>Install essential Python extensions, including: Python, Python Debugger, Python Indent</li> <li>Install Python Snippets to speed up coding.</li> <li>Install the Jupyter extension for interactive coding with Jupyter notebooks.</li> </ul> <p>By following these steps, you can make the most out of VS Code for your development needs!</p>"},{"location":"book/ch1_primer/ch1_module/","title":"Module","text":"<p>Any Python source file with the <code>.py</code> extension can be imported into Python's environment. Therefore, it is common practice to organize code by creating a separate file and importing it when needed. For instance, you can create a file named <code>primer.py</code>.</p> <pre><code>#primer.py\nimport os\nprint(os.getcwd())\n\ndef letterGrade(score):\n    if score &gt;= 90:\n        letter = 'A'\n    elif score &gt;= 80:\n        letter = 'B'\n    elif score &gt;= 70:\n        letter = 'C'\n    elif score &gt;= 60:\n        letter = 'D'\n    else:\n        letter = 'F'\n    return letter\n\nnames = ['Sam Amiri', 'Leila Alimehr','Ryan Amiri']   \n</code></pre> <p>Now import the created module, </p> <pre><code>import primer\nprimer.letterGrade(88)\nprint(primer.names)\n</code></pre> <p>If the file containing the functions is not in the current working directory, you can use the sys module to add its directory to the system path. Here's an example:</p> <pre><code>import sys\nsys.path.append('/path_to_file/')\n\nimport primer\n</code></pre> <p>You can refer to the package section) section to learn more about organizing and packaging functions.</p>"},{"location":"book/ch1_primer/ch1_overview/","title":"Overview","text":"<p>In this chapter, we cover the basics of Python, introduce modules, delve into the concepts of scope and namespaces, and discuss choosing the right editor for your needs.</p> <ul> <li>Primer</li> <li>Module</li> <li>scope_and_namespace</li> <li>Editor</li> <li>Challenges</li> </ul>"},{"location":"book/ch1_primer/ch1_primer/","title":"Python primer","text":""},{"location":"book/ch1_primer/ch1_primer/#getting-started","title":"Getting Started","text":""},{"location":"book/ch1_primer/ch1_primer/#librarymodule","title":"Library\\module","text":"<p>A library or module is a collection of data, functions, and tools packaged for performing specific tasks. Python includes standard library modules, such as <code>re</code>, which are available by default when Python is installed. Since these libraries are pre-installed, their functions can be easily accessed in Python by importing the corresponding module.</p> <pre><code>&gt;&gt;&gt; import re\n&gt;&gt;&gt; re\n&lt;module 're' from '/opt/homebrew/Cellar/python@3.11/3.11.9/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py'&gt;\n&gt;&gt;&gt; \n</code></pre> <p>Other modules come from third-party libraries, which can be installed using <code>pip</code>, Python's package management system. To install a library, simply type its name in the terminal following the pip install command, like this: <code>pip install library_name</code>.</p> <p><pre><code>pip install numpy\nimport numpy\nnumpy\n</code></pre> Third-party modules are typically stored in a dedicated <code>site-packages</code> directory. If the module is hosted on GitHub, you can easily install it by using <code>pip</code> with the module's repository URL.</p> <pre><code>pip install git+https://github.com/mwaskom/seaborn.git\n</code></pre>"},{"location":"book/ch1_primer/ch1_primer/#comments","title":"comments","text":"<p>By putting <code>#</code> infront a line, Python ignores running them, or put <code>`'''</code> a line befor and after text. </p> <p>By placing a <code>#</code> at the beginning of a line, Python treats it as a comment and ignores it during execution. Alternatively, you can use triple quotes (<code>'''</code> or <code>\"\"\"</code>) before and after a block of text to create multi-line comments or docstrings. <pre><code>'''\nIt does not run\n'''\n</code></pre></p>"},{"location":"book/ch1_primer/ch1_primer/#working-directory","title":"Working directory","text":"<p>The working directory is the folder that Python actively accesses to read or save files and interact with objects. This directory is referred to as the \"working directory.\"</p> <pre><code>import os\nos.getcwd()\n</code></pre> <p>To change the current working directory, use <code>os.chdir(path)</code>. To retrieve all files in the current directory as a list, use <code>os.listdir(os.getcwd())</code>.</p>"},{"location":"book/ch1_primer/ch1_primer/#scalar","title":"scalar","text":"<p>A single value is called a scalar. To store this value, you assign it a meaningful name, referred to as a variable. This is done using an assignment statement with the <code>=</code> operator. The following example assigns a numerical value and a string to two different variables:</p> <pre><code>pi0=3.14\npi1='approximate with two digits'\n</code></pre> <p>The assignment can be done in a flexible manner,</p> <pre><code>p=(4,3)\nx, y=p\n\ndat=[2,4, 4, (3,2,4)]\nda1, dat2, dat3,d4=dat\nd4\nx=1\nx+=2 # x=x+2\nx*=2 # x=x*1\nx**=2 # x=x**2\n</code></pre> <p>A variable name can contain both letters and numbers, but it must not begin with a number. It's important to use meaningful names for your variables. The value assigned to a variable can be of various basic built-in types, such as integer, float, string, and boolean. A boolean represents a logical value, typically either <code>True</code> or <code>False</code>.</p> <pre><code>&gt;&gt;&gt; x1=1\n&gt;&gt;&gt; x2=2.0\n&gt;&gt;&gt; x3='3'\n&gt;&gt;&gt; x4=True\n&gt;&gt;&gt; type(x1)\n&lt;class 'int'&gt;\n&gt;&gt;&gt; type(x2)\n&lt;class 'float'&gt;\n&gt;&gt;&gt; type(x3)\n&lt;class 'str'&gt;\n&gt;&gt;&gt; type(x4)\n&lt;class 'bool'&gt;\n</code></pre>"},{"location":"book/ch1_primer/ch1_primer/#data-structures","title":"Data Structures","text":"<p>Python provides a variety of useful data structures, such as lists, sets, and dictionaries. Additionally, Python allows programmers to define custom data structures using a feature called classes.</p>"},{"location":"book/ch1_primer/ch1_primer/#list","title":"list","text":"<p>A list is a sequence of values assigned to a variable. The individual values within a list are called elements or items. You can access the elements of a list using square brackets.</p> <pre><code>weights=[20,15,19,21,16] \ntype(weights)\ncolors=['red','blue','green','black','white']\ncolors\na,*b,c=[1,2,3,4]\n</code></pre> <p>To join the element use <code>\"\".join()</code></p> <pre><code>\",\".join(colors)\n</code></pre> <p>Use square brackets, <code>[]</code>, to index a list and access its elements.</p> <pre><code>colors[1:3]\ncolors[:3]\ncolors[3:]\ncolors[-1]\ncolors[1]\ncolors[:-1]\ncolors[::-1]\ncolors[::2] # even indexes\n</code></pre> <p>The following script demonstrates how to reverse, add new objects, and sort the elements of a list.</p> <pre><code>colors.reverse()\ncolors\n\ncolors.extend('blue')\ncolors\n\ncolors.extend(['blue'])\ncolors\n\nsorted(colors)\ncolors.sort()\ncolors.sort(key=len)\ncolors\n</code></pre> <p>Finding the index of elements and counting their occurrences is very simple. See the example below.</p> <pre><code>colors.index('blue')\ncolors.count('blue')\n</code></pre> <p>To change the element of list use <code>replace</code>:</p> <pre><code>a = 'hello, world!'\na[2]='z'\na.replace('l', 'z', 1)\na.replace('l', 'z')\n</code></pre>"},{"location":"book/ch1_primer/ch1_primer/#tuple","title":"Tuple","text":"<p>A tuple is a sequence of objects, similar to a list, but it is immutable. To define a tuple, Python uses parentheses:</p> <pre><code>&gt;&gt;&gt; colors=('red','blue','green','black','white')\n&gt;&gt;&gt; type(colors)\n&lt;class 'tuple'&gt;\n&gt;&gt;&gt; colors[1:3]\n('blue', 'green')\n</code></pre> <p>To access the contents of a tuple, use square brackets, just like a list. While lists and tuples may look similar, the key difference is that the elements of a tuple are immutable, meaning once a tuple is created, its contents cannot be modified.</p> <p><pre><code>&gt;&gt;&gt; colors[1]\n'blue'\n&gt;&gt;&gt; colors[1]='yellow'\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nTypeError: 'tuple' object does not support item assignment\n</code></pre> A brief comparison of mutable and immutable types, along with their applications, can be found below: here.</p>"},{"location":"book/ch1_primer/ch1_primer/#set","title":"Set","text":"<p>Set is a collection of elements without order and index, the same as defined in Algebra. Duplication of elements in set does not make sense, so Python drops the duplication automatically. Use the curly bracket ({) to create the set:</p> <pre><code>colors={'red','blue','green','black','white'}\ntype(colors)\n</code></pre> <p>You can add a new object to a set using <code>add</code>, and to add multiple objects, use <code>update</code>. To remove elements, use <code>remove</code> or <code>discard</code>. Both methods remove elements, but <code>discard</code> does not raise an error if the element does not exist in the set, whereas remove will.</p> <pre><code>colors.add('pink')\ncolors.update(['purple','orange'])\ncolors.remove('pink')\ncolors.remove('pink')\ncolors.discard('pink')\n</code></pre> <p>To delete elements from a set, use <code>clear</code>, and to remove the set completely, use <code>del</code>. To check if an element exists in a set, use the <code>in</code> keyword. The functions <code>len</code> and sorted can also be applied to sets:</p> <pre><code>'blue' in colors\nlen(colors)\nsorted(colors)\n</code></pre> <p>The functions <code>intersection</code>, <code>union</code>, <code>difference</code>, <code>issubset</code>, and <code>issuperset</code> can be applied on sets:  </p> <pre><code>'blue' in colors\nlen(colors)\nsorted(colors)\n{'red','blue'}.intersection({'red','white'})\n{'red','blue'}.union({'red','white'})\n{'red','blue'}.difference({'red','white'})\n{'red'}.issubset({'red','white'})\n{'red'}.issuperset({'red','white'})\n</code></pre> <p>To create a frozen set, use <code>frozenset</code>. A frozen set is immutable, meaning its elements cannot be changed. It can be used as an element in another set or as a key in a dictionary.</p>"},{"location":"book/ch1_primer/ch1_primer/#dictionary","title":"Dictionary","text":"<p>A dictionary is a generalized form of a list, but unlike a list, its indices (keys) can be of any data type. A dictionary maps a set of keys to a corresponding set of values. A dictionary consists of keys and values, where the key acts as the index, and the value is the associated item. In Python, a dictionary is a collection of unique key-value pairs. You construct a dictionary using curly brackets {}, separating keys and values with colons : and each key-value pair with commas ,. Keys must be quoted. You can print the dictionary by referencing it in a print statement.</p> <pre><code>prices = {\n   'BMW': 50,\n   'BENZ': 55,\n   'Ford': 25,\n   'Chevy': 30,  \n   'GM': 28\n}\n\nprices.values()\nprices.keys()\nprices.items()\n</code></pre> <p>The dictionary is very simple to manipulate,  </p> <pre><code>student={'A':10, 'B':20, 'AB':100 }\nstudent.values()\nstudent.keys()\nstudent['C']=45\nstudent[45]=34\ndel student['C']\n</code></pre> <p>Note that dictionaries are unordered, meaning the order in which keys are added does not necessarily reflect the order in which they will be retrieved or displayed.</p> <pre><code>dic1={\n'x1' : 1,\n'x2' : 2,\n'x3' : 3 }\n\ndic2={\n'y1' : 10,\n'x1' : 11,\n'x2' : 2 }\n\ndic1.keys() &amp; dic2.keys()\ndic1.keys() - dic2.keys()\ndic1.items() &amp; dic2.items()\n</code></pre> <p>To get the value for a specific key if it exists, and assign a default value if it doesn't, use the <code>get()</code> method.</p> <pre><code>dic1.get('x1') \ndic1.get('x4',0) \n</code></pre> <p>Example: Create a list where each element is a dictionary.</p> <pre><code>team = [\n    {\n        'name': 'Saeid',\n        'city': 'Toronto',\n    },\n    {\n        'name': 'Leila',\n        'city': 'Torronto',\n    },\n    {\n        'name': 'Ryan',\n        'city': 'Montreal',\n    },\n</code></pre>"},{"location":"book/ch1_primer/ch1_primer/#other","title":"Other","text":"<p>One of the most practical data structures is the array, which is an extension of the list and is implemented in NumPy. For more details, see  chapter2. Additionally, you can define your own custom data structure using classes to suit your specific needs.</p>"},{"location":"book/ch1_primer/ch1_primer/#conditionals","title":"Conditionals","text":""},{"location":"book/ch1_primer/ch1_primer/#boolean-value","title":"Boolean value","text":"<p>The values True (T) and False (F) are referred to as logical values in Python, with corresponding integer values of 1 and 0, respectively. Run the following code and explain what it does.</p> <pre><code>&gt;&gt;&gt; 8&lt;9\nTrue\n&gt;&gt;&gt; 9&lt;8\nFalse\n&gt;&gt;&gt; x=3\n&gt;&gt;&gt; y=9\n&gt;&gt;&gt; x&lt;y\nTrue\n&gt;&gt;&gt; x&gt;y\nFalse\n&gt;&gt;&gt;\n&gt;&gt;&gt; X=range(-3,3)\n&gt;&gt;&gt; [X[i]&lt;2 for i in range(6)]\n[True, True, True, True, True, False]\n&gt;&gt;&gt; sum([X[i]&lt;2 for i in range(6)])\n5\n&gt;&gt;&gt; sum(X)\n-3\n</code></pre> <p>One of the main applications of logical operators is to extract specific elements. See the following code examples:</p> <pre><code>&gt;&gt;&gt; weight=[58,89,68,74,62,77,65,65]\n&gt;&gt;&gt; [weight[i]&lt;74 for i in range(len(weight))]\n[True, False, True, False, True, False, True, True]\n&gt;&gt;&gt; weight&lt;74\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nTypeError: '&lt;' not supported between instances of 'list' and 'int'\n</code></pre> <p>Clearly, <code>weight&lt;74</code> does not work with a list. chapter2  discusses the array functionality provided by NumPy, which allows for such operations.</p> <pre><code>&gt;&gt;&gt; weight=numpy.array(weight)\n&gt;&gt;&gt; weight&lt;74\narray([ True, False,  True, False,  True, False,  True,True], dtype=bool)\n&gt;&gt;&gt; (weight&lt;74) &amp; (weight==89)\narray([False, False, False, False, False, False, False, False], dtype=bool)\n&gt;&gt;&gt; weight[(weight&lt;74) &amp; (weight==89)]\narray([], dtype=int64)\n&gt;&gt;&gt; weight[(weight&lt;74) &amp; (weight==62)]\narray([62])\n&gt;&gt;&gt; weight[(weight&lt;74) | (weight==62)]\narray([58, 68, 62, 65, 65])\n&gt;&gt;&gt; weight[~(weight&lt;74) &amp; (weight==62)]\narray([], dtype=int64)\n&gt;&gt;&gt; weight[~((weight&lt;74) | (weight==62))]\narray([89, 74, 77])\n</code></pre>"},{"location":"book/ch1_primer/ch1_primer/#control-structure","title":"Control Structure","text":"<p>Commands with control structures often include conditional statements that use comparison operators (&gt;, &lt;, =&gt;, &lt;=, ==, !=, ~, is). </p> <pre><code>&gt;&gt;&gt; 3&lt;4\nTrue\n&gt;&gt;&gt; 3!=4\nTrue\n&gt;&gt;&gt; 3==4\nFalse\n&gt;&gt;&gt; 3 is 4\nFalse\n&gt;&gt;&gt; 'hi' == 'h' + 'i'\nTrue\n&gt;&gt;&gt; 'HI' != 'hi'\nTrue\n&gt;&gt;&gt; [1, 2] != [2, 1]\nTrue\n&gt;&gt;&gt; ~True\n-2\n&gt;&gt;&gt; ~False\n-1\n</code></pre> <p>The structure of the <code>if</code> statement is as follows: If the condition (<code>cond</code>) is satisfied, the corresponding expression (<code>cons.expr</code>) is executed; otherwise, the alternative expression (<code>alt.expr</code>) is executed.</p> <pre><code>if(cond)\n cons.expr \nelif (condition) \n alt.expr \nelse \nalt.expr\n</code></pre> <pre><code>x=4\ny=4\n\nif x&lt;y: \n  print('x is less than y')\nelif x&gt;y:\n print('x greater than y')\nelse: \n print('x and y are equal')\n</code></pre> <p>To insert a value inside a string, use the f-string format.</p> <pre><code>if x&lt;y: \n  print( f'{x} is less than {y}')\nelif x&gt;y:\n print(f'{x}greater than {y}')\nelse: \n print(f'x={x} and y={y} are equal')\n</code></pre> <p>Variables can be combined using the logical operators <code>or</code>, <code>and</code>, and <code>not</code>. <pre><code>a or b\na and b\nnot a\n(a or b) and not (c or d)\n</code></pre></p> <p>The <code>in</code> operator can also be used with lists and strings. <pre><code>'a' in ['a', 'b']\n'a' in ['c', 'b']\n</code></pre></p> <p>See chapter2 for more information about logical values.</p>"},{"location":"book/ch1_primer/ch1_primer/#try-except","title":"Try except","text":"<p>When there is a possibility of an error, it is better to use <code>try</code> and <code>except</code>. The try block tests the code for errors, and if an error occurs, the program moves to the except block. If no error occurs, it proceeds to the else block. Its structure is very simple as below</p> <pre><code>try:\n    code in this block if things go well\nexcept:\n    code in this block run if things go wrong\n</code></pre> <pre><code>x='Just test'\ntry:\n  print(x)\nexcept:\n  print(\"Something went wrong\")\nelse:\n  print(\"Nothing went wrong\")\n\ntry:\n  print(y)\nexcept:\n  print(\"Something went wrong\")\nelse:\n  print(\"Nothing went wrong\")\n</code></pre> <p>You can catch specific error types, but here we present a generic except block. We discuss handling specific errors in Chapter 13, which makes debugging the code easier.</p>"},{"location":"book/ch1_primer/ch1_primer/#function","title":"Function","text":"<p>In programming, a function is a sequence of statements that performs a computation. A function has three main parts: arguments, the function body (script), and the output. Python has two types of functions: built-in functions, which are part of the core Python language or included in packages, and user-defined functions, which are written by the user.</p>"},{"location":"book/ch1_primer/ch1_primer/#built-in-function","title":"Built-in function","text":"<p>Python includes a number of core functions that are always available. For more details, see</p> <pre><code>x=[1,2,3]\ntype(x)\nlen(x)\nmin(x)\n</code></pre> <p>To round a value, use the <code>round(value, digits)</code> function, where value is the number to be rounded and digits specifies the number of decimal places.</p> <pre><code>round(0.12345,2)\nround(0.12345,3)\n</code></pre>"},{"location":"book/ch1_primer/ch1_primer/#user-function","title":"User function","text":"<p>A function has three main parts: arguments, the function body (script), and output. It has a simple structure.</p> <pre><code>def name (argument):  \n  script\n  return output\n</code></pre> <p>For instance, write a function that takes two arguments, adds them together, and returns the result.</p> <pre><code>def sum0 (x,y):  \n  s0=x+y\n  return s0\n</code></pre> <p>If you do not specify the arguments explicitly, use a * argument to accept a variable number of arguments.</p> <pre><code>def sum0 (x,*y):  \n  s0=x+mean(y)\n  return s0\n</code></pre> <p>You can define a default value for an argument by assigning a value to it in the function definition. This value will be used if no argument is provided when the function is called. <pre><code>def sum0 (x,y=1):  \n  s0=x+y\n  return s0\n</code></pre></p> <p>You can define an optional argument by assigning a default value to it in the function definition: <pre><code>def sum0 (x,y=None):  \n     if y is None:\n       return x\n     else:\n       return x+y\n</code></pre></p> <pre><code>def letterGrade(score):\n    if score &gt;= 90:\n        letter = 'A'\n    elif score &gt;= 80:\n        letter = 'B'\n    elif score &gt;= 70:\n        letter = 'C'\n    elif score &gt;= 60:\n        letter = 'D'\n    else:\n        letter = 'F'\n    return letter\n</code></pre>"},{"location":"book/ch1_primer/ch1_primer/#in-line-function","title":"In-line function","text":"<p>A simple function can be written in a single line. <pre><code>sum0 = lambda x, y: x + y\nsum0(2,3)\n</code></pre></p> <p>Such a function is more suitable for use inside other operations. The following example takes the first and last names, then sorts them according to the last name:</p> <pre><code>names = ['Sam Amiri','Ryan Amiri']\nsorted(names, key=lambda name: name.split()[-1].lower())\n&gt;&gt;&gt; sorted(names, key=lambda name: name.split()[-1].lower())\n['Sam Amiri', 'Ryan Amiri']\n&gt;&gt;&gt; sorted(names)\n['Ryan Amiri', 'Sam Amiri']\n</code></pre> <p>Example: Write a function to return the derivative for a given expression with respect to dx:  <pre><code>def der(f,dx):\n    def _fun0(x):\n     return((f(x+dx)-f(x))/dx)\n    return(_fun0)\nder0=der(lambda x: x**2,0.1)\nder0(x=2)\n</code></pre></p>"},{"location":"book/ch1_primer/ch1_primer/#map-and-filter","title":"Map and Filter","text":"<p>Python provides access to higher-order functions, which allow functions to operate on other functions, either by taking a function as an argument or by returning a function. The most popular higher-order functions are <code>map</code> (which applies a function to each element) and <code>filter</code> (which applies a function and returns the element if it evaluates to True). Additionally, reduce can be imported from the functools module (<code>from functools import reduce</code>).</p> <pre><code>x=[-1,0,1]\nlist(map(abs, x))\nlist(filter(lambda x: x &lt;= 0,x))\n ```\n\nExample: Write a function to divide two numbers. If the denominator is zero, terminate the function and display a notification.\n\n``` python\ndef divide(x, y):\n  try:\n    x / y\n  except: \n   print('Can not divide by zero!')\n  else:\n   return x / y\n\ndivide(3,1)\ndivide(3,0)\n</code></pre> <p>The function can also be rewritten using <code>raise</code>, which triggers an error and stops the function.</p> <pre><code>def divide(x, y):\n    \"\"\"Divide Function\"\"\"\n    if y == 0:\n        raise Exception('Can not divide by zero!')\n    return x / y\n\n\nmap(lambda x: x + 1, range(10))\nfilter(lambda x: x &gt; 5, range(10))\nreduce(lambda out, x: out + x, range(10))   \n</code></pre>"},{"location":"book/ch1_primer/ch1_primer/#argument","title":"Argument","text":"<p>To pass an undefined number of arguments as a list or dictionary, you can use *args and **kwargs, respectively. For example, if you have a function like this:</p> <pre><code>def printlist(*args):\n     print (args)\n     print(args[1])\n\nprintlist(1, 2, 3, 4, 5)\n\ndef printdict(**kwargs):\n    print (kwargs)\n\nprintdict(name=\"SA\", course=\"STAT\")\n\n\ndef printdict(name,**kwargs):\n    print(name)\n    print((kwargs))\n\n\nd={'name':\"SA\",'course':\"STAT\",'grade':3}\nprintdict(**d)\n\ndef func0(**kwargs):\n  for i, item in kwargs.items():\n        print(f\"{i}: {item}\")\n    print(kwargs['a'])\n\nfunc0(**d)\n\ndef func(*args, **kwargs):\n    print(args[1])\n    print(kwargs['a'])\n\nfunc(1, 2, a=3, b=4)\n</code></pre>"},{"location":"book/ch1_primer/ch1_primer/#iteration","title":"Iteration","text":"<p>Python is equipped with powerful tools for repeating commands or generating sequences of numbers. The \\(:\\) symbol is used to produce a series of numbers between two specified values.</p>"},{"location":"book/ch1_primer/ch1_primer/#range","title":"Range","text":"<pre><code>range(3,15)\n</code></pre> <p>To generate a series of numbers from one value to another with a specific increment.</p> <pre><code>&gt;&gt;&gt; np.arange(8, 20,1)\narray([ 8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n&gt;&gt;&gt; np.arange(21,30,3)\narray([21, 24, 27])\n&gt;&gt;&gt; np.arange(2,1,-0.1)\narray([ 2. ,  1.9,  1.8,  1.7,  1.6,  1.5,  1.4,  1.3,  1.2,  1.1])\n</code></pre> <p>specific element can be repeated a defined number of times.</p> <pre><code>&gt;&gt;&gt; [2,3]*2\n[2, 3, 2, 3]\n&gt;&gt;&gt; numpy.repeat([2, 3],[2,3])\narray([2, 2, 3, 3, 3])\n&gt;&gt;&gt; numpy.repeat([\"A\", \"B\"],[2,3])\narray(['A', 'A', 'B', 'B', 'B'],dtype='&lt;U1')\n</code></pre>"},{"location":"book/ch1_primer/ch1_primer/#for","title":"For","text":"<p>The most useful command for iteration is <code>for</code>, which repeats specified commands a defined number of times. Run the following code to see how it works:</p> <pre><code>&gt;&gt;&gt; for r in range(1,5):\n...  print(r**3)\n...\n2\n1\n0\n7\n\n &gt;&gt;&gt; for i in [2,3,1,7]:\n...  print(i**3)\n...\n1\n0\n2\n4\n</code></pre> <pre><code>&gt;&gt;&gt; score=[10, 15, 7, 20]\n&gt;&gt;&gt; for i in (range(0,4)):\n...  if (score[i]&lt;10):\n...       print(\"fail\")\n...  else:\n...        print(\"pass\")\n...\npass\npass\nfail\npass\n\nfor i, item in enumerate(score):\n  print(i,item)\n</code></pre> <pre><code>&gt;&gt;&gt; for i in range(0,4):\n...   if score[i]&lt;10:\n...       print(\"fail\")\n...   elif(score[i]&gt;=10&amp;score[i]&lt;14):\n...       print(\"middle\")\n...   elif(score[i]&gt;=14&amp;score[i]&lt;17):\n...        print(\"good\")\n...   elif(score[i]&gt;=17):\n...       print(\"BEST\")\n...\nmiddle\nmiddle\nfail\nmiddle\n</code></pre> <pre><code>for i, j in zip(a, b):\n    print(i,j)\n</code></pre>"},{"location":"book/ch1_primer/ch1_primer/#while","title":"While","text":"<p>The <code>while</code> command runs until the condition specified is met.</p> <pre><code>&gt;&gt;&gt; x=8\n&gt;&gt;&gt; i=0\n&gt;&gt;&gt; while(x&lt;12):\n...   i=i+1\n...   x=x+x/8\n...   print(i,x)\n...\n1 9.0\n2 10.125\n3 11.390625\n4 12.814453125\n</code></pre> <p>Conversely, the repeat command continues until the condition specified within the commands is met. In the following code, the loop continues until the condition <code>(x &gt; 12)</code> is no longer true:</p> <pre><code>&gt;&gt;&gt; x=8\n&gt;&gt;&gt; i=0\n&gt;&gt;&gt; while True:\n...  i=i+1\n...  x=x+x/8\n...  print(i,x)\n...  if (x&gt;12):\n...    break\n...\n1 9.0\n2 10.125\n3 11.390625\n4 12.814453125\n</code></pre> <p>Example: Write a simple function to select the prime numbers between 1 and 100 (though not the most efficient approach).</p> <pre><code>num0=[1]\nfor num in range(2,100):      \n    if 0 not in num%np.array(range(2, num)):\n     num0.extend([num])\n\nprint(num0)     \n</code></pre> <p>Example: Write a simple function to select pairs of unequal numbers between 1 and 3.</p> <pre><code>combs=[]\nfor x in range(3):\n for y in range(3):\n  if x!= y:\n    combs.append((x,y))\n</code></pre> <p>The code can be simplified using list comprehension.</p> <pre><code>[(x,y) for x in range(3) for y in range(3) if x!=y]\n</code></pre> <p>Example: Generate numbers between 1 and 10 and store them in different Python data structures.</p> <pre><code># A generator expression\n\nprint ((x for x in range(10)))\n\n# A list comprehension\nprint ([x for x in range(10)])\n\n# A set comprehension\nprint ({x for x in range(10)})\n\n# A dictionary comprehension\nprint ({x: x for x in range(10)})\n</code></pre>"},{"location":"book/ch1_primer/ch1_primer/#variable","title":"Variable","text":"<p>To check the existing variables, use <code>globals()</code>. The environment within a function is <code>local</code>, and it can be accessed using <code>locals()</code>.</p> <p><pre><code>def foo():\n    name=\"SA\"\n    print (locals())\n\nfoo()\n\nprint (locals())\nprint (globals()) \n</code></pre> scope and namespace discusses in more detail the regions in the code.</p>"},{"location":"book/ch1_primer/ch1_primer/#string","title":"String","text":"<p>Python has several function to work with string, in this subsection, we go through some basic in  working with strings. </p> <pre><code>var1='Hello Python 3, it is my 1st sentence'\nvar2='I like it!'\nvar1[0]\nvar1[0]*2\nvar1[0:6]\nvar1+','+var2\n'H' in var1 \n'z' not in var1 \nvar2.capitalize()\nvar1.count('o')\nvar1.count('o',0,6)\nvar1.expandtabs(tabsize=200)\n</code></pre> <p><code>find()</code> the position of the substring, <code>rfind()</code> finds the last occurrence of the specified value. <pre><code>var1.find('t')\nvar1.find('t',0,50)\nvar1.rfind('t',0,50)\nvar1.find('q',0,50)\n</code></pre></p> <p>Checks whether the string consists of alphanumeric characters, alphabetic, numeric digits, lowercase, space, lower, or upper: </p> <pre><code>var1.isalnum()\nvar1.isalpha()\nvar1.isdigit()\nvar1.isnumeric()\nvar1.isspace()\nvar1.islower()\nvar1.isupper()\n</code></pre> <p>You can check whether is the string is numeric or decimal? <pre><code>str = \"2009\"  \nstr.isdecimal()\n</code></pre></p> <pre><code>len(var)\n'_'.join([\"a\", \"b\", \"c\"])\n</code></pre> <p>You can add the space at the right or left:  </p> <pre><code>var1.ljust(50, '0') \nvar1.rjust(50, '0')\n</code></pre> <p><pre><code>var1.lower()\nvar1.upper()\nvar1.swapcase()\n\n\nmax(var1)\nmin(var1)\n</code></pre> Replace a string with an alternative string,  in the below all <code>o</code> replace with 3, in the second one just second occurrence will be replaced.  <pre><code>var1.replace('o','J')\nvar1.replace('o','J',2)\n</code></pre></p> <pre><code>str1.rindex(str2)\nstr1.index(str2)\nstr1.find(str2)\n</code></pre> <p>You can remove the leading, trailing and duplicate spaces:  <pre><code>var1.rstrip()\nvar1.lstrip()\nvar1.strip()\n</code></pre></p> <p>You can split the strig with withspace <pre><code>var1.split('e',1)\nvar1.split(',',1)\n</code></pre></p> <p>Also splits the string at line breaks and returns a list of lines in the string.</p> <pre><code>str=\"It is \\n line\"\nstr.splitlines() \n</code></pre> <p>Fill left with zero  <pre><code>str.zfill(50)\n</code></pre></p> <p>Check whether the string starts\\end with a specific string. <pre><code>var1.startswith('H')\nvar1.endswith('e', 1, 100)\n</code></pre></p>"},{"location":"book/ch1_primer/ch1_scope_and_namespace/","title":"Scope and namespace","text":""},{"location":"book/ch1_primer/ch1_scope_and_namespace/#scope","title":"Scope","text":"<p>Variables are containers for storing data values. The scope of a variable refers to the region in the code where the variable is accessible. Generally, there are three types of scopes: Global, Local, and Nonlocal. Let's explore these concepts in detail.</p> <pre><code>#primer.py\n# Global scope\nVAR1=\"OUT SIDE\"\ndef f():\n    # Local Scope\n    VAR2=\"IN SIDE\"\n    print(VAR1)\n    print(VAR2)\n    print(VAR3)\n    def f_sub():\n        # NonLocal Scope\n        VAR3=\"IN IN SIDE\"\n        print(VAR1)\n        print(VAR2)\n        print(VAR3)\n    f_sub()\n\nf()\nVAR1\nVAR2\nVAR3\n</code></pre> <p>Running this function results in an error because VAR1 is defined in the global scope and is accessible throughout the module. However, VAR2 is defined in the local scope of the function and is accessible only within that function. Similarly, VAR3, which is defined within a nested function, is accessible only within the nonlocal scope. To fix the issue, we need to adjust the function accordingly. Once corrected, rerunning the function should resolve the errors.</p> <pre><code>def f():\n    # Local Scope\n    VAR2=\"IN SIDE\"\n    print(VAR1)\n    print(VAR2)\n    def f_sub():\n    # NonLocal Scope\n        VAR3=\"IN IN SIDE\"\n        print(VAR1)\n        print(VAR2)\n        print(VAR3)\n    f_sub()\n\nf()\nVAR1\nVAR2\nVAR3\n</code></pre> <p>In Python, variables can be categorized into three types based on their scope: local, nonlocal, and global, each serving a distinct purpose. To view the variables in Python's global scope, you can use the dir() function without any arguments. This will display a list of all names available in your current environment.</p>"},{"location":"book/ch1_primer/ch1_scope_and_namespace/#local-variables","title":"Local variables","text":"<p>A local variable is one that is defined within a specific function and is accessible only within that function. It cannot be accessed from outside the function. Here's an example where we define a variable inside a function and then try to access it from outside:</p> <pre><code>#primer.py\n# Global scope\ndef f():\n    # Local scope\n    # local variable\n    VAR=\"IN SIDE\"\n    print(VAR)\n\nf()\nVAR\n</code></pre> <p>The code execution is shown below. As demonstrated, although the variable is defined within the function, it cannot be accessed from the global scope.</p> <pre><code>&gt;&gt;&gt; def f():\n...     # local variable\n...     VAR=\"IN SIDE\"\n...     print(VAR)\n... \n&gt;&gt;&gt; f()\nIN SIDE\n&gt;&gt;&gt; VAR\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nNameError: name 'VAR' is not defined\n</code></pre> <p>To view the local variables, use the locals().keys() function. This returns a dictionary containing all the local variables within the current scope.</p> <pre><code>def f():\n    # Local scope\n    # local variable\n    VAR=\"IN SIDE\"\n    print(VAR)\n    print(locals().keys())\n</code></pre>"},{"location":"book/ch1_primer/ch1_scope_and_namespace/#global-variable","title":"Global variable","text":"<p>Unlike a local variable, a global variable is defined outside of any function but can still be accessed from within functions. Global variables are often used to store data that needs to be shared across multiple functions, both inside and outside.</p> <p>To declare a global variable in Python, use the global keyword followed by the variable name. If you have multiple global variables, separate their names with commas after the global keyword.</p> <p>Let's run the following code:</p> <pre><code>def f():\n    global VAR\n    VAR=\"IN SIDE\"\n    print(VAR)\n\nf()\nVAR\n</code></pre> <p>The code execution is shown below. As you can see, even though the variable is defined inside the function, it cannot be accessed from the global scope.</p> <pre><code>&gt;&gt;&gt; def f():\n...     global VAR\n...     VAR=\"IN SIDE\"\n...     print(VAR)\n... \n&gt;&gt;&gt; f()\nIN SIDE\n&gt;&gt;&gt; VAR\n'IN SIDE'\n</code></pre> <p>Let define as globals. </p> <pre><code>VAR=\"OUT SIDE\"\ndef f():\n    global VAR\n    VAR=\"IN SIDE\"\n    print(VAR)\n\nf()\nVAR\n</code></pre> <p>Clearly, assigning the variable as a global variable changes its value.</p> <pre><code>&gt;&gt;&gt; VAR=\"OUT SIDE\"\n&gt;&gt;&gt; def f():\n...     global VAR\n...     VAR=\"IN SIDE\"\n...     print(VAR)\n... \n&gt;&gt;&gt; f()\nIN SIDE\n&gt;&gt;&gt; VAR\n'IN SIDE'\n</code></pre> <pre><code>VAR=\"OUT SIDE\"\nVAR\nf()\nVAR\n</code></pre> <pre><code>&gt;&gt;&gt; VAR=\"OUT SIDE\"\n&gt;&gt;&gt; VAR\n'OUT SIDE'\n&gt;&gt;&gt; f()\nIN SIDE\n&gt;&gt;&gt; VAR\n'IN SIDE'\n</code></pre> <p>More specifically, when you start a program, you begin in the global scope. Python treats the main script of your program as a module named main to manage the execution of the main program. To test this, run name:</p> <p><pre><code>&gt;&gt;&gt; __name__\n'__main__'\n</code></pre> This demonstrates that the name of the main module is main.</p> <p>To view the global variables, run globals().keys(), which returns a dictionary representing the current global variables. At the global scope, both locals() and globals() return the same dictionary for the global namespace. In contrast, dir() returns a list of the current local variables.</p>"},{"location":"book/ch1_primer/ch1_scope_and_namespace/#nonlocal-variables","title":"Nonlocal Variables","text":"<p>A nonlocal variable is defined inside a nested function. You can share this variable between the local and nonlocal scopes by using the nonlocal keyword followed by the variable name.</p> <pre><code>def f():\n    # Local Scope\n    VAR=\"IN SIDE\"\n    # print(VAR2)\n    # print(VAR3)\n    def f_sub():\n        # NonLocal Scope\n        nonlocal VAR\n        VAR = \"IN IN SIDE\"\n        print(\"nonlocal scope:\",VAR)\n    f_sub()\n    print(\"local scope:\", VAR)\n\nf()\nVAR\n\n\ndef f():\n    # Local Scope\n    VAR=\"IN SIDE\"\n    # print(VAR2)\n    # print(VAR3)\n    def f_sub():\n        # NonLocal Scope\n        # nonlocal VAR\n        VAR = \"IN IN SIDE\"\n        print(\"nonlocal scope:\",VAR)\n    f_sub()\n    print(\"local scope:\", VAR)\n\nf()\nVAR\n</code></pre> <p>In the above example, the f_sub function modifies the value of the local variables. Now, let's explore the use of a nonlocal variable. To compute an average, we need both the sum and the count of numbers. The following code demonstrates how to use nonlocal variables to maintain and update the sum and count when new data is added.</p> <pre><code>def average():\n     sum = 0\n     count = 0\n     def _average(input):\n         nonlocal sum, count\n         sum += input\n         count += 1\n         return sum / count\n     return _average\n\nave=average()\nave(2)\nave(3)\n</code></pre>"},{"location":"book/ch1_primer/ch1_scope_and_namespace/#namespace","title":"Namespace","text":"<p>A namespace is a collection of names that map to values of variables and other objects within a program. In Python, these namespaces are stored as dictionaries and are often referred to as scopes. The most important namespace is the built-in namespace, which is created when the Python interpreter starts and remains available throughout the program's execution. This namespace includes built-in functions like print() and dir(), which are always accessible.</p> <p>You can view the names available in the current Python scope using the following command:</p> <pre><code>&gt;&gt;&gt; dir()\n['__annotations__', '__builtins__', '__doc__', '__loader__', '__name__', '__package__', '__spec__']\n</code></pre> <p>Python also has a standard library module called builtins, which is automatically loaded into the built-in namespace when the interpreter starts. You can access the names of objects in the builtins namespace via builtins. Here's an example:</p> <pre><code>&gt;&gt;&gt; dir(__builtins__)\n['ArithmeticError', 'AssertionError', ..., 'zip']\n\n&gt;&gt;&gt; len(dir(__builtins__))\n158\n</code></pre> <p>Each module has its own global namespace, and similarly, each function has its own local namespace.</p>"},{"location":"book/ch2_computation/ch2_challenges/","title":"Challenge","text":"<p>UNDER CONSTRUCTION. </p> <p>import pandas as pd import scipy as sp</p> <p>data = sp.randn(5, 2)  # Create 5x2 matrix of random numbers for toy example dates = pd.date_range('28/12/2010', periods=5) df = pd.DataFrame(data, columns=('price', 'weight'), index=dates) print(df) sp.mean(data) sp.median(data) sp.std(data)</p>"},{"location":"book/ch2_computation/ch2_numpy/","title":"Numpy","text":"<p>Numpy (NUMerical PYthon) provides very useful arrays structure to work with data. </p>"},{"location":"book/ch2_computation/ch2_numpy/#arrays","title":"Arrays","text":"<p>Numpy's array is a generalization of list discussed in chapter1, it is more appropriate for the computation.</p> <pre><code>import numpy as np\nweight=[58,89,68,74,62,77,65,65]\nweight\nweight_arr=np.array(weight)\nweight_arr\n</code></pre> <p>It is like a vector, all elements should have same type, therefore if you add a strict  element, it saves all elements as strict. It also accept multi lists</p> <pre><code>arr1=np.array([range(i) for i in [1, 2, 3]])\narr1[1]\narr1[1][0]\narr2=np.array([range(i, j+i) for i in [1, 2, 3] for j in [1, 2, 3]])\narr2[1]\narr2[1][0]\n</code></pre> <p>A constant array can be generated using <code>np.full(,)</code></p> <pre><code>np.full(2, 2.2)\nnp.full((2,1), 2.2)\nnp.full((2,2), 2.2)\n</code></pre> <pre><code>np.repeat(2.2, 2)\nnp.repeat([2.1,2.2],2)\nnp.repeat([2.1,2.2], [2, 3])\n</code></pre> <pre><code>np.arange(1,14,4)\nnp.arange(21,30,3)\nnp.arange(2,1,-0.1)\n</code></pre> <p>To create an array of n values between two values</p> <pre><code>np.linspace(0, 1, 10)\n</code></pre> <p>To refer elements of array should use <code>[]</code></p> <pre><code>weight[1]# first element\nweight[2:]# second elements to the rest\nweight[:3]# elements before the third and including the third\n</code></pre> <p>To refer elements of multi array should use <code>[,]</code></p> <pre><code>weight2=np.array([weight_arr,2.20*weight_arr,35.27*weight_arr])\nweight2[1,1]\nweight2[1:,1:]\nweight2[1:,2:]\n</code></pre> <p>To change the shape <pre><code>weight2.reshape((8, 3))\n</code></pre></p>"},{"location":"book/ch2_computation/ch2_numpy/#concatenate","title":"concatenate","text":"<p>It provides functions to concatenate the arrays</p> <pre><code>&gt;&gt;&gt; w1 = weight_arr[:4]\n&gt;&gt;&gt; w2 = weight_arr[4:]\n&gt;&gt;&gt; np.concatenate((w1, w2), axis=0)\narray([58, 89, 68, 74, 62, 77, 65, 65])\n&gt;&gt;&gt; w1r=w1.reshape(2,2)\n&gt;&gt;&gt; w2r=w2.reshape(2,2)\n&gt;&gt;&gt; np.concatenate((w1r,w2r), axis=0)\narray([[58, 89],\n       [68, 74],\n       [62, 77],\n       [65, 65]])\n&gt;&gt;&gt; np.vstack((w1r,w2r))\narray([[58, 89],\n       [68, 74],\n       [62, 77],\n       [65, 65]])\n&gt;&gt;&gt; np.concatenate((w1r,w2r), axis=1)\narray([[58, 89, 62, 77],\n       [68, 74, 65, 65]])\n&gt;&gt;&gt; np.hstack((w1r,w2r))\narray([[58, 89, 62, 77],\n       [68, 74, 65, 65]])\n</code></pre> <p>The array can be split into subsplit</p> <pre><code>w1, w2, w3,w3,w4 = np.split(weight_arr, 4)\n</code></pre>"},{"location":"book/ch2_computation/ch2_numpy/#useful-function","title":"Useful function","text":"<p>Numpy provides very useful bult-in function,  </p> <pre><code>np.sort(weight2,axis=0)\nnp.sort(weight2,axis=1)\n&gt;&gt;&gt; np.argsort(weight2,axis=0)\narray([[0, 0, 0, 0, 0, 0, 0, 0],\n       [1, 1, 1, 1, 1, 1, 1, 1],\n       [2, 2, 2, 2, 2, 2, 2, 2]])\n&gt;&gt;&gt; np.argsort(weight2,axis=1)\narray([[0, 4, 6, 7, 2, 3, 5, 1],\n       [0, 4, 6, 7, 2, 3, 5, 1],\n       [0, 4, 6, 7, 2, 3, 5, 1]])\n</code></pre> <pre><code>&gt;&gt;&gt; np.min(weight2)\n58.0\n&gt;&gt;&gt; np.min(weight2,axis=1)\narray([   58.  ,   127.6 ,  2045.66])\n&gt;&gt;&gt; np.min(weight2,axis=0)\narray([ 58.,  89.,  68.,  74.,  62.,  77.,  65.,  65.])\n</code></pre> <p>The following list includes some useful functions:  </p> Function Name NaN-safe Version Description np.sum np.nansum Compute sum of elements np.prod np.nanprod Compute product of elements np.mean np.nanmean Compute mean of elements np.std np.nanstd Compute standard deviation np.var np.nanvar Compute variance np.min np.nanmin Find minimum value np.max np.nanmax Find maximum value np.argmin np.nanargmin Find index of minimum value np.argmax np.nanargmax Find index of maximum value np.median np.nanmedian Compute median of elements np.percentile np.nanpercentile Compute rank-based statistics of elements np.any N/A Evaluate whether any elements are true np.all N/A Evaluate whether all elements are true <p>The <code>isnan</code> is useful command to study if the object includes the NA or not.</p> <pre><code>&gt;&gt;&gt; y=np.array([1, 2, np.nan])\n&gt;&gt;&gt; np.isnan(y)\narray([False, False,  True], dtype=bool)\n</code></pre>"},{"location":"book/ch2_computation/ch2_numpy/#matrix","title":"Matrix","text":"<p>Numpy has very strong functions for matrices. </p> <pre><code>mat=np.array([i for i in range(9)]).reshape(3,3)\nmat.diagonal()\nnp.diagonal(mat)\nmat.trace()\nnp.trace(mat)\nmat.transpose() # transpose\nnp.transpose(mat)\nmat2=np.array([i for i in range(6)]).reshape(3,2)\nnp.dot(mat,mat2) # dot product \nnp.inner(mat,mat) # inner product \n</code></pre> <p>More matrical functions can be obtained from  Linear algebra, <code>numpy.linalg</code>,  <pre><code>a=np.array([[1,2],[3,4]])\nnp.linalg.inv(a) # inverse\nnp.linalg.pinv(a) # inverse\nnp.linalg.det(a)\n</code></pre> <pre><code>y = np.array([[5.], [7.]])\nnp.linalg.solve(a, y)\nnp.linalg.eig(a)\n</code></pre></p> <p>Instead generating matrix from array, numpy has <code>numpy.matlib</code> that directly can be used to generate matrix </p> <pre><code>import numpy.matlib as npmat\nnp.eye(3)\nnp.zeros((4,2))\nnp.ones((4,2))\n</code></pre> <p>Calculate the beta  XTX = np.dot(X.T, X) INV = np.linalg.inv(XTX) beta = np.dot(np.matmul(INV, X.T), y) beta</p>"},{"location":"book/ch2_computation/ch2_numpy/#random-number","title":"Random number","text":"<p>Numpy has very strong function for generating random number from several statistical distributions. </p> <pre><code>np.random.rand(4,2) #Generate n random number from uniform\n\nnp.random.randn(4,2) #Generate n random number from standard normal\n\nnp.random.randint(low=1,high=20, size=10)\n\nx = np.arange(12).reshape((4 ,3))\nnp.random.shuffle(x)\n\na0=['a','b']\na0=np.array(a0)\nnp.random.choice(a0,size=3, replace=True,p=(.3,.7))\n</code></pre>"},{"location":"book/ch2_computation/ch2_numpy/#subsetting","title":"Subsetting","text":"<p>The logical operator is often used to extract subset of data, using the array can easily achieve selecting subsets.    </p> <pre><code>&gt;&gt;&gt; x= np.array([\"a\", \"b\", \"c\"])\n&gt;&gt;&gt; y= np.array([3, 4, \"c\"])\n&gt;&gt;&gt; set(x).union(y) # union\n{'c', '4', 'b', '3', 'a'}\n&gt;&gt;&gt; set(x).intersection(y)\n{'c'}\n&gt;&gt;&gt; set(x)- set(y)\n{'b', 'a'}\n&gt;&gt;&gt; [x[i]==y[i] for i in  range(len(x))]# the same as is.ellemt in R\n[False, False, True]\n</code></pre> <pre><code>&gt;&gt;&gt; weight=[58,89,68,74,62,77,65,65]\n&gt;&gt;&gt; weight=np.array(weight)\n&gt;&gt;&gt; weight&lt;74\narray([ True, False,  True, False,  True, False,  True,True], dtype=bool)\n&gt;&gt;&gt; (weight&lt;74) &amp; (weight==89)\narray([False, False, False, False, False, False, False, False], dtype=bool)\n&gt;&gt;&gt; weight[(weight&lt;74) &amp; (weight==89)]\narray([], dtype=int64)\n&gt;&gt;&gt; weight[(weight&lt;74) &amp; (weight==62)]\narray([62])\n&gt;&gt;&gt; weight[(weight&lt;74) | (weight==62)]\narray([58, 68, 62, 65, 65])\n&gt;&gt;&gt; weight[~(weight&lt;74) &amp; (weight==62)]\narray([], dtype=int64)\n&gt;&gt;&gt; weight[~((weight&lt;74) | (weight==62))]\narray([89, 74, 77])\n</code></pre> <pre><code>&gt;&gt;&gt;weight2=np.array([weight_arr,2.20*weight_arr,35.27*weight_arr])\n&gt;&gt;&gt; np.sum(weight2 &lt; 127, axis=1)\narray([8, 0, 0])\n&gt;&gt;&gt; np.any(weight2 &lt; 127)\nTrue\n&gt;&gt;&gt; np.sum(weight2 &lt; 127, axis=1)\narray([8, 0, 0])\n</code></pre>"},{"location":"book/ch2_computation/ch2_numpy/#combined-data","title":"Combined data","text":"<p>The data set might include different data like dataframe in R that each column has data with different format, array can save such data.</p> <pre><code>&gt;&gt;&gt;weight=[58,89,68,74,62,77,65,65]\n&gt;&gt;&gt;gender=['F','F','F','M','M','M','M','M']\n&gt;&gt;&gt; data = np.zeros(8, dtype={'names':('sex', 'weight'),'formats':('U10', 'f4')})\n&gt;&gt;&gt; data['sex']=gender\n&gt;&gt;&gt; data['weight']=weight\n&gt;&gt;&gt; data\narray([('F',  58.), ('F',  89.), ('F',  68.), ('M',  74.), ('M',  62.),\n       ('M',  77.), ('M',  65.), ('M',  65.)],\n      dtype=[('sex', '&lt;U10'), ('weight', '&lt;f4')])\n\n&gt;&gt;&gt; data['weight']\narray([ 58.,  89.,  68.,  74.,  62.,  77.,  65.,  65.], dtype=float32)\n&gt;&gt;&gt; data['weight'][1:3]\narray([ 89.,  68.], dtype=float32)     \n</code></pre> <p>When you define the array, you should define the format as well, data can be save with different format see, ?????</p> Character Description Example 'b' Byte np.dtype('b') 'i' Signed integer np.dtype('i4') == np.int32 'u' Unsigned integer 'f' Floating point np.dtype('f8') == np.int64 'c' Complex floating point np.dtype('c16') == np.complex128 'S', 'a' String np.dtype('S5') 'U' Unicode string np.dtype('U') == np.str_ 'V' Raw data (void) np.dtype('V') == np.void"},{"location":"book/ch2_computation/ch2_numpy/#masked-array","title":"masked array","text":"<p>There are many circumstances where one should drop part of it, because of missing, invalid entries, or other reasons.  Consider the weight and mask weight&lt;70, </p> <pre><code>weight_arr=np.array(weight)\nweight_m=np.array(np.zeros(len(weight)))\nweight_m[weight_arr&lt;70]=1\nweight_ma1=np.ma.masked_array(weight_arr, mask=weight_m)\nweight_ma1.data\nweight_ma1.mask\nnp.mean(weight_ma1)\n````\n\n```{Python, echo = FALSE, message = FALSE}\nweight_ma2=np.ma.masked_where(weight_arr&lt;70,weight_arr)\nweight_ma2\nnp.mean(weight_ma1)\n</code></pre> <pre><code>weight_arr=np.array(weight)\nweight_mas=np.ma.masked_where(weight_arr&lt;70,weight_arr)\nweight_mas\nweight_mas.data\nweight_mas.mask\n\nnp.ma.masked_array(weight_arr, mask=aa)\n</code></pre>"},{"location":"book/ch2_computation/ch2_overview/","title":"Overview","text":"<p>This chapter provides a brief overview of NumPy.</p> <ul> <li>Numpy</li> <li>Scipy</li> <li>Challenges</li> </ul>"},{"location":"book/ch2_computation/ch2_scipy/","title":"SciPy","text":"<p>SciPy is built on top of NumPy and is designed for scientific computation. It offers many built-in functions beyond what we have covered here\u2014this is just a brief introduction. The best resource for learning SciPy is its official tutorial. SciPy includes a number of subpackages that organize functions based on their application areas.</p>"},{"location":"book/ch2_computation/ch2_scipy/#matrix","title":"Matrix","text":"<p>It provides useful functions for linear algebra operations, which are compiled implementations of standard libraries such as BLAS (Basic Linear Algebra Subroutines) and LAPACK (Linear Algebra PACKage).</p> <pre><code>from scipy import linalg\nx=np.eye(2)\nlinalg.det(x) # determinant of a square matrix:\nlinalg.inv(x)  # the inverse of a square matrix\nlinalg.eig(x) # generalized eigenvalue\nlinalg.pinv(x) # Compute the (Moore-Penrose) pseudo-inverse of a matrix\na = np.array([[3, 2, 0], [1, -1, 0], [0, 5, 1]])\nb = np.array([2, 4, -1])\nlinalg.solve(a,b) # Solves the linear equation set a @ x == b for the unknown x for square a matrix.\n</code></pre>"},{"location":"book/ch2_computation/ch2_scipy/#statistics-scipystats","title":"Statistics (scipy.stats)","text":"<p><code>scipy.stats</code> contains fundamental tools for statistical analysis, including descriptive statistics, hypothesis testing, and probability distributions.</p>"},{"location":"book/ch2_computation/ch2_scipy/#descriptive-statistics","title":"Descriptive statistics","text":"<p>The <code>scipy.stats</code> subpackage provides functions to summarize and describe the main features of a dataset. In the example below, we compute the mean, median, mode, variance, and standard deviation of the data.</p> <pre><code>from scipy import stats\ndata = [1, 2, 3, 4]\nmean = stats.tmean(data)\nmedian = stats.scoreatpercentile(data, 50)\nmode = stats.mode(data) \nvariance = stats.tvar(data) \nstd_deviation = stats.tstd(data)\n</code></pre>"},{"location":"book/ch2_computation/ch2_scipy/#continuous-distributions","title":"Continuous distributions","text":"<p>In the example below, we explore the normal distribution by generating an array of x values between -2 and 2, along with a random sample from the distribution. We then compute the probability density function (PDF) and cumulative distribution function (CDF).</p> <pre><code>from scipy import stats\nmean0 = 0\nstd_dev0 = 1\nsize0 = 10 \nsamples = stats.norm.rvs(loc=mean0, scale=std_dev0, size=size0)\n\nx = np.linspace(2, 2, 5)\npdf = stats.norm.pdf(x, mean, std_dev)\ncdf = stats.norm.cdf(x, mean, std_dev)\n</code></pre> <p>In the next, we look at the exponential distribution, </p> <pre><code>lambda0 = 1\nsamples = stats.expon.rvs(scale=1/lambda0, size=size0)\n\nx = np.linspace(0, 10, 5)\n\npdf = expon.pdf(x, scale=1/lambda0)\ncdf = expon.cdf(x, scale=1/lambda0)\n</code></pre>"},{"location":"book/ch2_computation/ch2_scipy/#discrete-probability-distributions","title":"Discrete probability distributions","text":"<p>In the below, we look at the binomial distribution \\(Bionom(10,0.3)\\)</p> <pre><code>n0, p0 = 10, 0.3\nsize0=20\nsample = stats.binom.rvs(n=n0, p=p0, size=size0)\n\nx = np.arange(0, 4)\npmf = binom.pmf(x, n0, p0)\ncdf = binom.cdf(x, n0, p0)\n</code></pre> <p>Next is the poisson distribution,</p> <pre><code>mu0 = 3\nsize0 = 20 \nsamples = stats.poisson.rvs(mu=mu0, size=size0)\n\nx = np.arange(0, 10)\n\npmf = stats.poisson.pmf(x, mu=mu0)\ncdf = stats.poisson.cdf(x, mu=mu0)\n</code></pre>"},{"location":"book/ch2_computation/ch2_scipy/#statistical-tests","title":"Statistical tests","text":"<p>For example, let's generate 100 random samples from a standard normal distribution, which has a mean of 0 and a standard deviation of 1. We then fit maximum likelihood estimation of the unknown parameters (stats.norm.fit): </p> <pre><code>from scipy import stats\ndist = stats.norm(loc=0, scale=1)\nsample = dist.rvs(size=100) \nloc, scale = stats.norm.fit(sample) \nloc\n</code></pre> <p>We can perform hypothesis tests that produce a test statistic and a p-value, helping us assess the statistical significance of our results.</p> <pre><code>stat, p_value  = stats.normaltest(sample)\nprint(f\"t-statistic: {stat:.3f}\")\nprint(f\"p-value: {p_value:.3f}\")\n</code></pre> <p>To perform a statistical test between two samples, let's start by generating the samples.</p> <pre><code>group1 = stats.norm.rvs(loc=mean, scale=1, size=size0)\ngroup2 = stats.norm.rvs(loc=mean, scale=1.2, size=100)\nstat, p_value = stats.ttest_ind(group1, group2)\nprint(f\"t-statistic: {stat:.3f}\")\nprint(f\"p-value: {p_value:.3f}\")\n</code></pre> <p>Next, we examine the Chi-Squared test, which is performed on a contingency table. We'll first create the table using NumPy, and then run the statistical test.</p> <pre><code>data = np.array([[5, 8], [10, 6]])\nchi2_stat, p_val, dof, expected \nres= stats.chi2_contingency(data)\n\nprint(f\"Chi-squared statistic: {res.statistic:.4f}\")\nprint(f\"p-value: {res.pvalue:.4f}\")\nprint(f\"Degrees of freedom: {res.dof}\")\nprint(f\"Expected values: \\n{res.expected_freq}\")\n</code></pre>"},{"location":"book/ch2_computation/ch2_scipy/#integration-scipyintegrate","title":"Integration (scipy.integrate)","text":"<p>You can compute the integral of a given function using <code>scipy.integrate</code>, which offers various numerical integration methods.</p>"},{"location":"book/ch2_computation/ch2_scipy/#quadrature","title":"Quadrature","text":"<p>scipy.integrate.quad uses a quadrature approach to compute the numerical integral of a function which has one variable. You need to define the function and the integration range. Let's compute the following integral: $$ \\int_0^1 x^2 dx $$</p> <pre><code>from scipy import integrate\nx2 = lambda x: x**2\nintegral, error = integrate.quad(x2, 0, 1)\nintegral\nerror\nnp.allclose(integral, 1**3 / 3) \n</code></pre> <p>Let compute the integral of  \\(\\int_0^{\\pi/2} \\cos(x) dx\\):</p> <pre><code>integral, error = integrate.quad(np.cos, 0, np.pi/2)\nintegral\nerror\nnp.allclose(integral, 1)\n</code></pre>"},{"location":"book/ch2_computation/ch2_scipy/#double-integral","title":"Double Integral","text":"<p>scipy.integrate.dblquad can be used to calculate double integrals.</p> <pre><code>fx = lambda x, y: 4*x**2*y\nintegral, error = integrate.dblquad(fx, 0, 1,2,4)\nintegral\nerror\n</code></pre>"},{"location":"book/ch2_computation/ch2_scipy/#multiple-integral","title":"Multiple Integral","text":"<p>scipy.integrate.nquad can be used to calculate multiple integrals.</p> <pre><code>fx = lambda x, y, z: 4*x**2*y*z\nranges=[[0,1],[2,4],[3,5]]\nintegral, error = integrate.nquad(fx,ranges)\nintegral\nerror\n</code></pre>"},{"location":"book/ch2_computation/ch2_scipy/#initial-value-problems","title":"Initial Value Problems","text":"<p>The integration of a differential equation can be performed using the solve_ivp function. Let's consider the following example:</p> \\[ \\dfrac{y}{t}=f(y,t) \\] <p>from an initila time \\(t_0\\) and initial state  \\(y(t=t_0)=t_0\\), up to a final time \\(t_f\\).  Let's consider the equation \\(\\dfrac{y}{t}=3 y\\) with the initial condition \\(y(t=0)=1\\) on the interval \\(0&lt;t&lt;2\\). </p> <pre><code>import scipy as sp \ndef f(t, y):\n    return 3 * y\nt_span = (0, 2)  # time interval\nt_eval = np.linspace(*t_span)  # times at which to evaluate `y`\ny0 = [1,]  # initial state\nres = sp.integrate.solve_ivp(f, t_span=t_span, y0=y0, t_eval=t_eval)\nres\nimport matplotlib.pyplot as plt\nplt.plot(res.t, res.y[0])\nplt.show()\n</code></pre>"},{"location":"book/ch2_computation/ch2_scipy/#optimization-scipyoptimize","title":"Optimization (scipy.optimize)","text":"<p>scipy.optimize provides a collection algorithms for solving optimization problems. It can be used to minimize or maximize functions, find function roots, and fit models to data. </p>"},{"location":"book/ch2_computation/ch2_scipy/#root-finding","title":"Root Finding","text":"<p>scipy.optimize.root_scalar() can be used to find a root of a function. Let's consider a case where the function and its derivative exist, along with an initial guess for the solution.</p> <pre><code>def f(x):\n    return (x-2)*(x+3)\ndef df(x):\n    return 2*x + 1\nx0 = 0  # guess\nres = sp.optimize.root_scalar(f, x0=x0, fprime=df)\nres\n</code></pre> <p>It is possible to find the root of a function over a specified interval.</p> <pre><code>res = sp.optimize.root_scalar(f, bracket=(-10, 0))\nres.root\n</code></pre> <p>In the multivariate case, you can use scipy.optimize.root() to find the roots of a system of equations.</p> <pre><code>def f(x):\n    return [x[0] + x[1] - 3 ,\n            x[0]**2 - x[1]-3]\nres = sp.optimize.root(f, x0=[0, 0])\n</code></pre>"},{"location":"book/ch2_computation/ch2_scipy/#curve-fitting","title":"Curve fitting","text":"<p>scipy.optimize.curve_fit uses non-linear least squares to fit a function to data. To illustrate curve fitting, let's consider the following example function:</p> <pre><code>def func(x, a, b, c):\n    return a * np.exp(-b * x) + c\n\na,b,c=2,1,3\n</code></pre> <p>Let's generate some dat </p> <pre><code>xdata = np.linspace(0, 10, 100)\ny = func(xdata, 2, 1, 3)\ny_noise = 0.1 *stats.norm.rvs(loc=0, scale=1, size=xdata.size)\nydata = y + y_noise\n</code></pre> <p>The parameters can be estimated through approximation: <pre><code>params, _ = optimize.curve_fit(func, xdata, ydata, p0=[1, 1, 1])\n</code></pre></p>"},{"location":"book/ch2_computation/ch2_scipy/#interpolate","title":"interpolate","text":"<p>scipy.interpolate is used to estimate values of an unknown function and can be applied to compute its integral, derivative, or inverse. Let's create a dataset and add some noise to it.</p> <pre><code>rng = np.random.default_rng()\nxdata = np.linspace(0, 2*np.pi, 100)\nfunct = np.sin(xdata)\nnoise = stats.norm.rvs(loc=0, scale=0.5, size=100)\nydata = funct + noise\n</code></pre> <p>Now we can fit a model to the data</p> <pre><code>int_sm = sp.interpolate.make_smoothing_spline(xdata, ydata)\nint_xdata = np.linspace(0, 2*np.pi, 300)\nint_fit = int_sm(int_xdata)\n</code></pre> <p>make_smoothing_spline smooths the data and does not necessarily pass through all the points. To force the curve to pass through every point, use make_interp_spline instead.</p> <pre><code>int_in = sp.interpolate.make_interp_spline(xdata, ydata)\n</code></pre>"},{"location":"book/ch2_computation/ch2_scipy/#minimize","title":"Minimize","text":"<p>In general, you can find the minimum of a function using scipy.optimize.minimize(). Let's consider the function \\(f(x_0, x_1) = (x_0-3)^2 + (x_1-1)^3\\)</p> <pre><code>def f(x):\n    return (x[0] - 3)**2 + (x[1] - 1)**3\n\nres = sp.optimize.minimize(f, x0=[0, 0])\nres\n</code></pre>"},{"location":"book/ch2_computation/ch2_scipy/#inputoutput","title":"Input/output","text":"<p>SciPy offers functions for importing and exporting data in a wide variety of formats, including MATLAB, ARFF, WAV, Matrix Market, IDL, NetCDF, TXT, and CSV.</p> <pre><code>import numpy as np\nfrom scipy import io\n\nx=np.eye(2)\nio.savemat('examp.mat', {'col1': x[0],'col2': x[1]}) \nx_2 = io.loadmat('examp.mat', struct_as_record=True)\nx_2['col1']\n</code></pre>"},{"location":"book/ch3_data_analysis/ch3.gitignore/","title":"Ch3.gitignore","text":"In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! <pre>https://www.datasciencemadesimple.com/python-pandas-tutorial-2a/\n</pre> https://www.datasciencemadesimple.com/python-pandas-tutorial-2a/ In\u00a0[\u00a0]: Copied! <pre>df['Quarters_encoded'] = map(lambda x: x.encode('base64','strict'), df['Quarters'])\ndf['Quarters_decoded'] = map(lambda x: x.decode('base64','strict'), df['Quarters_encoded'])\n</pre> df['Quarters_encoded'] = map(lambda x: x.encode('base64','strict'), df['Quarters']) df['Quarters_decoded'] = map(lambda x: x.decode('base64','strict'), df['Quarters_encoded']) In\u00a0[\u00a0]: Copied! <pre>df['Description_Upper'] = df['Description'].str.upper()\ndf['Description_Upper'] = df['Description'].apply(str.upper)\ndf['Description_Upper'] = df['Description'].apply(lambda x: x.upper())\n</pre> df['Description_Upper'] = df['Description'].str.upper() df['Description_Upper'] = df['Description'].apply(str.upper) df['Description_Upper'] = df['Description'].apply(lambda x: x.upper()) In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>Extract Last n characters from right of the column in pandas:\nMethod 1:\n</pre> Extract Last n characters from right of the column in pandas: Method 1: In\u00a0[\u00a0]: Copied! <pre>str[-n:] is used to get last n character of column in pandas\ndf1['Stateright'] = df1['State'].str[-2:]\n</pre> str[-n:] is used to get last n character of column in pandas df1['Stateright'] = df1['State'].str[-2:] In\u00a0[\u00a0]: Copied! <pre>Extract first n Characters from left of column in pandas:\ndf1['StateInitial'] = df1['State'].str[:2]\n</pre> Extract first n Characters from left of column in pandas: df1['StateInitial'] = df1['State'].str[:2] In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>-\nwe will replace the first character of the column by substring \u2018HE\u2019\n</pre> - we will replace the first character of the column by substring \u2018HE\u2019 In\u00a0[\u00a0]: Copied! <pre>df1.replace(regex=['^.'],value='HE')\n</pre> df1.replace(regex=['^.'],value='HE') In\u00a0[\u00a0]: Copied! <pre>- \nReplace a substring with another substring in pandas\ndf1.replace(regex=['zona'], value='Arizona')\n</pre> -  Replace a substring with another substring in pandas df1.replace(regex=['zona'], value='Arizona') In\u00a0[\u00a0]: Copied! <pre>-\nreplaced multiple values of the pandas dataframe at once using apply function and replace function along with regex.\n</pre> - replaced multiple values of the pandas dataframe at once using apply function and replace function along with regex. In\u00a0[\u00a0]: Copied! <pre>df2 = df1.apply(lambda x: x.replace({'zona':'Arizona', 'US':'United States'}, regex=True))\n</pre> df2 = df1.apply(lambda x: x.replace({'zona':'Arizona', 'US':'United States'}, regex=True)) In\u00a0[\u00a0]: Copied! <pre>df2 = df1.replace({'State': 'zona', 'Country': 'US'}, \n    {'State': 'Arizona', 'Country': 'United States'}, regex=True)\n</pre> df2 = df1.replace({'State': 'zona', 'Country': 'US'},      {'State': 'Arizona', 'Country': 'United States'}, regex=True) In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>df1['Country'] = df1['Country'].str.replace('India','IND')\n</pre> df1['Country'] = df1['Country'].str.replace('India','IND') In\u00a0[\u00a0]: Copied! <pre>-\n</pre> - In\u00a0[\u00a0]: Copied! <pre>Replace space with underscore:\ndf1.replace(regex=[' '], value='_')\n</pre> Replace space with underscore: df1.replace(regex=[' '], value='_') In\u00a0[\u00a0]: Copied! <pre>- \nReplace last character of column using regular expression:\n</pre> -  Replace last character of column using regular expression: In\u00a0[\u00a0]: Copied! <pre>df1.replace(regex=['(.)$'],value='HE')\n</pre> df1.replace(regex=['(.)$'],value='HE') In\u00a0[\u00a0]: Copied! <pre>- \ndf1['state_substring'] =df1.State.str.slice(0, 7)\nprint(df1)\n</pre> -  df1['state_substring'] =df1.State.str.slice(0, 7) print(df1) In\u00a0[\u00a0]: Copied! <pre>- \nextracted the last word of the state column using regular expression and stored in other column.\ndf1['State_code'] = df1.State.str.extract(r'\\b(\\w+)$', expand=True)\n</pre> -  extracted the last word of the state column using regular expression and stored in other column. df1['State_code'] = df1.State.str.extract(r'\\b(\\w+)$', expand=True) In\u00a0[\u00a0]: Copied! <pre>df1['Stateright'] = df1['State'].str[-2:]\nprint(df1)\n</pre> df1['Stateright'] = df1['State'].str[-2:] print(df1) In\u00a0[\u00a0]: Copied! <pre>- \nString  compare two columns \u2013 case insensitive:\n</pre> -  String  compare two columns \u2013 case insensitive: In\u00a0[\u00a0]: Copied! <pre>df1['is_equal'] =( df1['State'].str.lower().str.replace('s/+',\"\") == df1['State_1'].str.lower().str.replace('s/+',\"\"))\n</pre> df1['is_equal'] =( df1['State'].str.lower().str.replace('s/+',\"\") == df1['State_1'].str.lower().str.replace('s/+',\"\")) In\u00a0[\u00a0]: Copied! <pre>- \nAppend or add a character or string value to start of the column in pandas:\ndf1['State_new'] ='USA-' + df1['State'].astype(str)\n</pre> -  Append or add a character or string value to start of the column in pandas: df1['State_new'] ='USA-' + df1['State'].astype(str) In\u00a0[\u00a0]: Copied! <pre>- \nExtract substring of a column in pandas:\n</pre> -  Extract substring of a column in pandas: In\u00a0[\u00a0]: Copied! <pre>df1['State_code'] = df1.State.str.extract(r'\\b(\\w+)$', expand=True)\n</pre> df1['State_code'] = df1.State.str.extract(r'\\b(\\w+)$', expand=True)"},{"location":"book/ch3_data_analysis/ch3_challenges/","title":"-- <em> Challenges </em>","text":"In\u00a0[5]: Copied! <pre>import pandas as pd\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\niris=pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',header=None)\n</pre> import pandas as pd import warnings warnings.simplefilter(action='ignore', category=FutureWarning) iris=pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',header=None) <ul> <li>Display the first 6 rows.</li> </ul> In\u00a0[6]: Copied! <pre>iris.head(6)\n</pre> iris.head(6) Out[6]: 0 1 2 3 4 0 5.1 3.5 1.4 0.2 Iris-setosa 1 4.9 3.0 1.4 0.2 Iris-setosa 2 4.7 3.2 1.3 0.2 Iris-setosa 3 4.6 3.1 1.5 0.2 Iris-setosa 4 5.0 3.6 1.4 0.2 Iris-setosa 5 5.4 3.9 1.7 0.4 Iris-setosa <ul> <li>What is the dimension?</li> </ul> In\u00a0[7]: Copied! <pre>iris.shape\n</pre> iris.shape Out[7]: <pre>(150, 5)</pre> <ul> <li>Get a summary of data,</li> </ul> In\u00a0[8]: Copied! <pre>iris.describe()\n</pre> iris.describe() Out[8]: 0 1 2 3 count 150.000000 150.000000 150.000000 150.000000 mean 5.843333 3.054000 3.758667 1.198667 std 0.828066 0.433594 1.764420 0.763161 min 4.300000 2.000000 1.000000 0.100000 25% 5.100000 2.800000 1.600000 0.300000 50% 5.800000 3.000000 4.350000 1.300000 75% 6.400000 3.300000 5.100000 1.800000 max 7.900000 4.400000 6.900000 2.500000 <ul> <li>What are the types of data?</li> </ul> In\u00a0[9]: Copied! <pre>iris.dtypes\n</pre> iris.dtypes Out[9]: <pre>0    float64\n1    float64\n2    float64\n3    float64\n4     object\ndtype: object</pre> <ul> <li>Add label to the data: sepallength,sepalwidth,petal length,petal width, class.</li> </ul> In\u00a0[10]: Copied! <pre>iris.columns=['sepallength','sepalwidth','petal length','petalwidth', 'species']\n</pre> iris.columns=['sepallength','sepalwidth','petal length','petalwidth', 'species'] <ul> <li>Change the type of <code>species</code></li> </ul> In\u00a0[11]: Copied! <pre>iris['species'] = iris['species'].astype('category')\n</pre> iris['species'] = iris['species'].astype('category') <ul> <li>How many different species are there?</li> </ul> In\u00a0[12]: Copied! <pre>iris.species.unique()\n</pre> iris.species.unique() Out[12]: <pre>['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\nCategories (3, object): ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']</pre> <ul> <li>Extract column sepallength</li> </ul> In\u00a0[13]: Copied! <pre>iris['sepallength']\niris.sepallength\n</pre> iris['sepallength'] iris.sepallength Out[13]: <pre>0      5.1\n1      4.9\n2      4.7\n3      4.6\n4      5.0\n      ... \n145    6.7\n146    6.3\n147    6.5\n148    6.2\n149    5.9\nName: sepallength, Length: 150, dtype: float64</pre> <ul> <li>Extract the rows 2,5</li> </ul> In\u00a0[14]: Copied! <pre>iris.iloc[[2,5]]\n</pre> iris.iloc[[2,5]] Out[14]: sepallength sepalwidth petal length petalwidth species 2 4.7 3.2 1.3 0.2 Iris-setosa 5 5.4 3.9 1.7 0.4 Iris-setosa <ul> <li>Extract the rows 2,5 and columns 1,3</li> </ul> In\u00a0[15]: Copied! <pre>iris.iloc[[2,5],[1,3]]\n</pre> iris.iloc[[2,5],[1,3]] Out[15]: sepalwidth petalwidth 2 3.2 0.2 5 3.9 0.4 <ul> <li>Using logical indexing select observations with sepallength&lt;5.</li> </ul> In\u00a0[16]: Copied! <pre>iris[iris.sepallength&lt;5]\n</pre> iris[iris.sepallength&lt;5] Out[16]: sepallength sepalwidth petal length petalwidth species 1 4.9 3.0 1.4 0.2 Iris-setosa 2 4.7 3.2 1.3 0.2 Iris-setosa 3 4.6 3.1 1.5 0.2 Iris-setosa 6 4.6 3.4 1.4 0.3 Iris-setosa 8 4.4 2.9 1.4 0.2 Iris-setosa 9 4.9 3.1 1.5 0.1 Iris-setosa 11 4.8 3.4 1.6 0.2 Iris-setosa 12 4.8 3.0 1.4 0.1 Iris-setosa 13 4.3 3.0 1.1 0.1 Iris-setosa 22 4.6 3.6 1.0 0.2 Iris-setosa 24 4.8 3.4 1.9 0.2 Iris-setosa 29 4.7 3.2 1.6 0.2 Iris-setosa 30 4.8 3.1 1.6 0.2 Iris-setosa 34 4.9 3.1 1.5 0.1 Iris-setosa 37 4.9 3.1 1.5 0.1 Iris-setosa 38 4.4 3.0 1.3 0.2 Iris-setosa 41 4.5 2.3 1.3 0.3 Iris-setosa 42 4.4 3.2 1.3 0.2 Iris-setosa 45 4.8 3.0 1.4 0.3 Iris-setosa 47 4.6 3.2 1.4 0.2 Iris-setosa 57 4.9 2.4 3.3 1.0 Iris-versicolor 106 4.9 2.5 4.5 1.7 Iris-virginica <p>Sort data based on 'sepallength' and 'sepalwidth'.</p> In\u00a0[17]: Copied! <pre>iris.sort_values(['sepallength','sepalwidth'])\n</pre> iris.sort_values(['sepallength','sepalwidth']) Out[17]: sepallength sepalwidth petal length petalwidth species 13 4.3 3.0 1.1 0.1 Iris-setosa 8 4.4 2.9 1.4 0.2 Iris-setosa 38 4.4 3.0 1.3 0.2 Iris-setosa 42 4.4 3.2 1.3 0.2 Iris-setosa 41 4.5 2.3 1.3 0.3 Iris-setosa ... ... ... ... ... ... 118 7.7 2.6 6.9 2.3 Iris-virginica 122 7.7 2.8 6.7 2.0 Iris-virginica 135 7.7 3.0 6.1 2.3 Iris-virginica 117 7.7 3.8 6.7 2.2 Iris-virginica 131 7.9 3.8 6.4 2.0 Iris-virginica <p>150 rows \u00d7 5 columns</p> <ul> <li>Calculate summary of sepallength and sepalwidth for each class</li> </ul> In\u00a0[18]: Copied! <pre>iris.groupby(['species'])[['sepallength','sepalwidth']].describe()\n</pre> iris.groupby(['species'])[['sepallength','sepalwidth']].describe() Out[18]: sepallength sepalwidth count mean std min 25% 50% 75% max count mean std min 25% 50% 75% max species Iris-setosa 50.0 5.006 0.352490 4.3 4.800 5.0 5.2 5.8 50.0 3.418 0.381024 2.3 3.125 3.4 3.675 4.4 Iris-versicolor 50.0 5.936 0.516171 4.9 5.600 5.9 6.3 7.0 50.0 2.770 0.313798 2.0 2.525 2.8 3.000 3.4 Iris-virginica 50.0 6.588 0.635880 4.9 6.225 6.5 6.9 7.9 50.0 2.974 0.322497 2.2 2.800 3.0 3.175 3.8 <ul> <li>Calculate median of sepalwidth for each class</li> </ul> In\u00a0[19]: Copied! <pre>iris.groupby(\"species\")['sepallength'].median()\n</pre> iris.groupby(\"species\")['sepallength'].median()  Out[19]: <pre>species\nIris-setosa        5.0\nIris-versicolor    5.9\nIris-virginica     6.5\nName: sepallength, dtype: float64</pre> <ul> <li>Calculate summary  of  'count', 'min', 'max', 'mean', 'std'  for each class</li> </ul> In\u00a0[21]: Copied! <pre>values = ['count', 'min', 'max', 'mean', 'std']\niris.groupby(by='species').agg(values)\n</pre> values = ['count', 'min', 'max', 'mean', 'std'] iris.groupby(by='species').agg(values) Out[21]: sepallength sepalwidth petal length petalwidth count min max mean std count min max mean std count min max mean std count min max mean std species Iris-setosa 50 4.3 5.8 5.006 0.352490 50 2.3 4.4 3.418 0.381024 50 1.0 1.9 1.464 0.173511 50 0.1 0.6 0.244 0.107210 Iris-versicolor 50 4.9 7.0 5.936 0.516171 50 2.0 3.4 2.770 0.313798 50 3.0 5.1 4.260 0.469911 50 1.0 1.8 1.326 0.197753 Iris-virginica 50 4.9 7.9 6.588 0.635880 50 2.2 3.8 2.974 0.322497 50 4.5 6.9 5.552 0.551895 50 1.4 2.5 2.026 0.274650 <ul> <li>Save the imported data to  CV.</li> </ul> In\u00a0[22]: Copied! <pre>iris.to_csv('iris.csv', index=False)\n</pre> iris.to_csv('iris.csv', index=False) <p>We work with NBA games (https://www.basketball-reference.com/leagues/NBA_2020_games.html) here</p> <ul> <li>Load librariess</li> </ul> In\u00a0[57]: Copied! <pre>import numpy as np\nimport pandas as pd\npd.options.display.max_rows=10\n</pre> import numpy as np import pandas as pd pd.options.display.max_rows=10 <ul> <li>Import data, and show the data</li> </ul> In\u00a0[63]: Copied! <pre>source = pd.read_html(\"https://www.basketball-reference.com/leagues/NBA_2020_games.html\")\nNBA_game = source[0]\nNBA_game.head()\n</pre> source = pd.read_html(\"https://www.basketball-reference.com/leagues/NBA_2020_games.html\") NBA_game = source[0] NBA_game.head() Out[63]: Date Start (ET) Visitor/Neutral PTS Home/Neutral PTS.1 Unnamed: 6 Unnamed: 7 Attend. LOG Arena Notes 0 Tue, Oct 22, 2019 8:00p New Orleans Pelicans 122 Toronto Raptors 130 Box Score OT 20787 2:50 Scotiabank Arena NaN 1 Tue, Oct 22, 2019 10:30p Los Angeles Lakers 102 Los Angeles Clippers 112 Box Score NaN 19068 2:28 STAPLES Center NaN 2 Wed, Oct 23, 2019 7:00p Chicago Bulls 125 Charlotte Hornets 126 Box Score NaN 15424 2:11 Spectrum Center NaN 3 Wed, Oct 23, 2019 7:00p Detroit Pistons 119 Indiana Pacers 110 Box Score NaN 17923 2:22 Bankers Life Fieldhouse NaN 4 Wed, Oct 23, 2019 7:00p Cleveland Cavaliers 85 Orlando Magic 94 Box Score NaN 18846 2:02 Amway Center NaN <p>Print the column and type the data</p> In\u00a0[64]: Copied! <pre>print(NBA_game.columns)\ntype(NBA_game)\n</pre> print(NBA_game.columns) type(NBA_game) <pre>Index(['Date', 'Start (ET)', 'Visitor/Neutral', 'PTS', 'Home/Neutral', 'PTS.1',\n       'Unnamed: 6', 'Unnamed: 7', 'Attend.', 'LOG', 'Arena', 'Notes'],\n      dtype='object')\n</pre> Out[64]: <pre>pandas.core.frame.DataFrame</pre> <p>Rename the column name of data</p> In\u00a0[65]: Copied! <pre>column_names = {'Date': 'date', 'Start (ET)': 'start','Visitor/Neutral': 'visitor','PTS': 'visitor_points','Home/Neutral': 'home',\n'PTS.1': 'home_points','Unnamed: 6': 'box','Unnamed: 7': 'ot','Attend.': 'attend','Notes': 'notes'}\n\nNBA_game=NBA_game.rename(columns=column_names).dropna(thresh=5)[['date','visitor','visitor_points','home','home_points']].assign(date=lambda x: pd.to_datetime(x['date'], format='%a, %b %d, %Y')).set_index('date', append=True).rename_axis([\"id\", \"date\"]).sort_index()\nNBA_game.head()\n</pre> column_names = {'Date': 'date', 'Start (ET)': 'start','Visitor/Neutral': 'visitor','PTS': 'visitor_points','Home/Neutral': 'home', 'PTS.1': 'home_points','Unnamed: 6': 'box','Unnamed: 7': 'ot','Attend.': 'attend','Notes': 'notes'}  NBA_game=NBA_game.rename(columns=column_names).dropna(thresh=5)[['date','visitor','visitor_points','home','home_points']].assign(date=lambda x: pd.to_datetime(x['date'], format='%a, %b %d, %Y')).set_index('date', append=True).rename_axis([\"id\", \"date\"]).sort_index() NBA_game.head() Out[65]: visitor visitor_points home home_points id date 0 2019-10-22 New Orleans Pelicans 122 Toronto Raptors 130 1 2019-10-22 Los Angeles Lakers 102 Los Angeles Clippers 112 2 2019-10-23 Chicago Bulls 125 Charlotte Hornets 126 3 2019-10-23 Detroit Pistons 119 Indiana Pacers 110 4 2019-10-23 Cleveland Cavaliers 85 Orlando Magic 94 <p>Change the data to wide</p> In\u00a0[67]: Copied! <pre>NBA_game_w= (NBA_game.reset_index()\n    .melt(id_vars=['id', 'date'], value_vars=['visitor', 'home'],\n          value_name='team', var_name='home_or_visitor')\n)\n\nNBA_game_w.head()\n</pre> NBA_game_w= (NBA_game.reset_index()     .melt(id_vars=['id', 'date'], value_vars=['visitor', 'home'],           value_name='team', var_name='home_or_visitor') )  NBA_game_w.head() Out[67]: id date home_or_visitor team 0 0 2019-10-22 visitor New Orleans Pelicans 1 1 2019-10-22 visitor Los Angeles Lakers 2 2 2019-10-23 visitor Chicago Bulls 3 3 2019-10-23 visitor Detroit Pistons 4 4 2019-10-23 visitor Cleveland Cavaliers <ul> <li>Load the libraries, and import the data</li> </ul> In\u00a0[74]: Copied! <pre>import numpy as np\nimport pandas as pd\nname_var=[\"id\", \"name\", \"city\", \"country\", \"faa\", \"icao\", \"lat\", \"lon\", \"alt\", \"tz\", \"dst\", \"tzone\"]\nairports_raw = pd.read_csv(\"https://raw.githubusercontent.com/hadley/nycflights13/master/data-raw/airports.dat\",header=None,names=name_var)\n</pre> import numpy as np import pandas as pd name_var=[\"id\", \"name\", \"city\", \"country\", \"faa\", \"icao\", \"lat\", \"lon\", \"alt\", \"tz\", \"dst\", \"tzone\"] airports_raw = pd.read_csv(\"https://raw.githubusercontent.com/hadley/nycflights13/master/data-raw/airports.dat\",header=None,names=name_var) <ul> <li>Get the head and info of data.</li> </ul> In\u00a0[75]: Copied! <pre>airports_raw.head()\n</pre> airports_raw.head() Out[75]: id name city country faa icao lat lon alt tz dst tzone 0 1 Goroka Goroka Papua New Guinea GKA AYGA -6.081689 145.391881 5282 10.0 U Pacific/Port_Moresby 1 2 Madang Madang Papua New Guinea MAG AYMD -5.207083 145.788700 20 10.0 U Pacific/Port_Moresby 2 3 Mount Hagen Mount Hagen Papua New Guinea HGU AYMH -5.826789 144.295861 5388 10.0 U Pacific/Port_Moresby 3 4 Nadzab Nadzab Papua New Guinea LAE AYNZ -6.569828 146.726242 239 10.0 U Pacific/Port_Moresby 4 5 Port Moresby Jacksons Intl Port Moresby Papua New Guinea POM AYPY -9.443383 147.220050 146 10.0 U Pacific/Port_Moresby In\u00a0[76]: Copied! <pre>airports_raw.info()\n</pre> airports_raw.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 8107 entries, 0 to 8106\nData columns (total 12 columns):\n #   Column   Non-Null Count  Dtype  \n---  ------   --------------  -----  \n 0   id       8107 non-null   int64  \n 1   name     8107 non-null   object \n 2   city     8107 non-null   object \n 3   country  8107 non-null   object \n 4   faa      5880 non-null   object \n 5   icao     8043 non-null   object \n 6   lat      8107 non-null   float64\n 7   lon      8107 non-null   float64\n 8   alt      8107 non-null   int64  \n 9   tz       8107 non-null   float64\n 10  dst      8107 non-null   object \n 11  tzone    8107 non-null   object \ndtypes: float64(3), int64(2), object(7)\nmemory usage: 760.2+ KB\n</pre> <ul> <li>Clean data</li> </ul> <ol> <li>Select just country USA and faa is not empty</li> <li>drop id name icao</li> <li>Drop duplicate from faa?</li> </ol> In\u00a0[\u00a0]: Copied! <pre>airports_raw.country.unique()\nairports_usa=airports_raw.loc[(airports_raw['country']=='United States')&amp;('faa'!='')]\nairports_usa=airports_usa.drop(['id','name','icao'],axis=1)\nairports_usa=airports_usa.drop_duplicates('faa')\nairports_usa=airports_usa.set_index('faa')\nairports_usa.head()\n</pre> airports_raw.country.unique() airports_usa=airports_raw.loc[(airports_raw['country']=='United States')&amp;('faa'!='')] airports_usa=airports_usa.drop(['id','name','icao'],axis=1) airports_usa=airports_usa.drop_duplicates('faa') airports_usa=airports_usa.set_index('faa') airports_usa.head() <pre>\nRunning cells with '/opt/homebrew/bin/python3.10' requires the ipykernel package.\n\nRun the following command to install 'ipykernel' into the Python environment. \n\nCommand: '/opt/homebrew/bin/python3.10 -m pip install ipykernel -U --user --force-reinstall'</pre> <p>Calculate distance</p> In\u00a0[78]: Copied! <pre>def great_circle_distance(df, to=\"DSM\"):\n    # https://www.johndcook.com/blog/python_longitude_latitude/\n    df = df.copy()\n    lat = np.deg2rad(90 - df['lat'])\n    lon = np.deg2rad(90 - df['lon'])\n    to_lat, to_lon = df.loc[to, ['lat', 'lon']]\n    cos = (np.sin(lat) * np.sin(to_lat) * np.cos(lon - to_lon) +\n           np.cos(lat) * np.cos(to_lat))\n    arc = np.arccos(cos)\n    kilometers = 6373 * cos\n    df[f'km_to_{to}'] = kilometers\n    return df\n\ngreat_circle_distance(airports_usa)\n</pre> def great_circle_distance(df, to=\"DSM\"):     # https://www.johndcook.com/blog/python_longitude_latitude/     df = df.copy()     lat = np.deg2rad(90 - df['lat'])     lon = np.deg2rad(90 - df['lon'])     to_lat, to_lon = df.loc[to, ['lat', 'lon']]     cos = (np.sin(lat) * np.sin(to_lat) * np.cos(lon - to_lon) +            np.cos(lat) * np.cos(to_lat))     arc = np.arccos(cos)     kilometers = 6373 * cos     df[f'km_to_{to}'] = kilometers     return df  great_circle_distance(airports_usa) Out[78]: city country lat lon alt tz dst tzone km_to_DSM faa 4I7 Greencastle United States 39.633556 -86.813806 842 -5.0 U America/New_York -611.548347 C91 Dowagiac United States 41.992934 -86.128012 748 -5.0 U America/New_York -874.022782 CDI Cambridge United States 39.975028 -81.577583 799 -5.0 U America/New_York -827.065264 SUE Sturgeon Bay United States 44.843667 -87.421556 725 -6.0 U America/Chicago -1122.842947 0P2 Stewartstown United States 39.794824 -76.647191 1000 -5.0 U America/New_York -997.427349 ... ... ... ... ... ... ... ... ... ... UCA Utica United States 43.104167 -75.223333 456 -5.0 A America/New_York -1370.623054 CVO Corvallis United States 44.506700 -123.291500 250 -8.0 A America/Los_Angeles -531.679746 CWT Chatsworth United States 34.256944 -118.598889 978 -8.0 A America/Los_Angeles 594.567494 DHB Deer Harbor United States 48.618397 -123.005960 0 -8.0 A America/Los_Angeles -985.750406 OLT San Diego United States 32.755200 -117.199500 0 -8.0 A America/Los_Angeles 752.239018 <p>1459 rows \u00d7 9 columns</p> <ul> <li>Import the necessary libraries</li> </ul> In\u00a0[79]: Copied! <pre>import numpy as np\nimport pandas as pd \nimport datetime\n</pre> import numpy as np import pandas as pd  import datetime <ul> <li>Import data set</li> </ul> In\u00a0[130]: Copied! <pre>dow_jones = pd.read_csv('../data/dow_jones_index/dow_jones_index.data')\ndow_jones.head(10)\n</pre> dow_jones = pd.read_csv('../data/dow_jones_index/dow_jones_index.data') dow_jones.head(10) Out[130]: quarter stock date open high low close volume percent_change_price percent_change_volume_over_last_wk previous_weeks_volume next_weeks_open next_weeks_close percent_change_next_weeks_price days_to_next_dividend percent_return_next_dividend 0 1 AA 1/7/2011 $15.82 $16.72 $15.78 $16.42 239655616 3.792670 NaN NaN $16.71 $15.97 -4.428490 26 0.182704 1 1 AA 1/14/2011 $16.71 $16.71 $15.64 $15.97 242963398 -4.428490 1.380223 239655616.0 $16.19 $15.79 -2.470660 19 0.187852 2 1 AA 1/21/2011 $16.19 $16.38 $15.60 $15.79 138428495 -2.470660 -43.024959 242963398.0 $15.87 $16.13 1.638310 12 0.189994 3 1 AA 1/28/2011 $15.87 $16.63 $15.82 $16.13 151379173 1.638310 9.355500 138428495.0 $16.18 $17.14 5.933250 5 0.185989 4 1 AA 2/4/2011 $16.18 $17.39 $16.18 $17.14 154387761 5.933250 1.987452 151379173.0 $17.33 $17.37 0.230814 97 0.175029 5 1 AA 2/11/2011 $17.33 $17.48 $16.97 $17.37 114691279 0.230814 -25.712195 154387761.0 $17.39 $17.28 -0.632547 90 0.172712 6 1 AA 2/18/2011 $17.39 $17.68 $17.28 $17.28 80023895 -0.632547 -30.226696 114691279.0 $16.98 $16.68 -1.766780 83 0.173611 7 1 AA 2/25/2011 $16.98 $17.15 $15.96 $16.68 132981863 -1.766780 66.177694 80023895.0 $16.81 $16.58 -1.368230 76 0.179856 8 1 AA 3/4/2011 $16.81 $16.94 $16.13 $16.58 109493077 -1.368230 -17.663150 132981863.0 $16.58 $16.03 -3.317250 69 0.180941 9 1 AA 3/11/2011 $16.58 $16.75 $15.42 $16.03 114332562 -3.317250 4.419900 109493077.0 $15.95 $16.11 1.003130 62 0.187149 <ul> <li>Select 'stock','date','open','high','low' and check the type of them</li> </ul> In\u00a0[131]: Copied! <pre>dow_jones=dow_jones.loc[:,['date','stock','open','high','low']] \ndow_jones.dtypes\n</pre>  dow_jones=dow_jones.loc[:,['date','stock','open','high','low']]  dow_jones.dtypes Out[131]: <pre>date     object\nstock    object\nopen     object\nhigh     object\nlow      object\ndtype: object</pre> <ul> <li>Assign week number as index</li> </ul> In\u00a0[30]: Copied! <pre>def to_week(x):\n  return datetime.datetime.strptime(x, '%m/%d/%Y').strftime(\"%V\")\n</pre> def to_week(x):   return datetime.datetime.strptime(x, '%m/%d/%Y').strftime(\"%V\") <ul> <li>Apply the function to_week on the column data</li> </ul> In\u00a0[132]: Copied! <pre>dow_jones['week']=dow_jones['date'].apply(to_week)\ndow_jones = dow_jones.set_index(['week','stock'])\ndow_jones=dow_jones.drop(['date'], axis=1)\ndow_jones.head()\n</pre> dow_jones['week']=dow_jones['date'].apply(to_week) dow_jones = dow_jones.set_index(['week','stock']) dow_jones=dow_jones.drop(['date'], axis=1) dow_jones.head() Out[132]: open high low week stock 01 AA $15.82 $16.72 $15.78 02 AA $16.71 $16.71 $15.64 03 AA $16.19 $16.38 $15.60 04 AA $15.87 $16.63 $15.82 05 AA $16.18 $17.39 $16.18 <ul> <li>Is there any duplicate dates?</li> </ul> In\u00a0[133]: Copied! <pre>dow_jones.index.is_unique\n</pre> dow_jones.index.is_unique Out[133]: <pre>True</pre> <ul> <li>Drop doller sign from columns and change them to numeric</li> </ul> In\u00a0[134]: Copied! <pre>for i in dow_jones.columns[1:]:\n    dow_jones[i]=dow_jones[i].str.strip('$').astype(float)\n</pre> for i in dow_jones.columns[1:]:     dow_jones[i]=dow_jones[i].str.strip('$').astype(float) <ul> <li>Compute the mean for each week:</li> </ul> In\u00a0[135]: Copied! <pre>dow_jones.iloc[:,1:4].groupby(dow_jones.index).mean()\n</pre> dow_jones.iloc[:,1:4].groupby(dow_jones.index).mean() Out[135]: high low (01, AA) 16.72 15.78 (01, AXP) 45.60 43.11 (01, BA) 70.10 66.00 (01, BAC) 14.69 13.80 (01, CAT) 94.81 92.30 ... ... ... (25, TRV) 58.28 56.12 (25, UTX) 86.21 83.69 (25, VZ) 36.17 35.20 (25, WMT) 53.70 52.35 (25, XOM) 81.12 76.78 <p>750 rows \u00d7 2 columns</p> <ul> <li>Let reconsider time as index.</li> </ul> In\u00a0[137]: Copied! <pre>dow_jones = pd.read_csv('../data/dow_jones_index/dow_jones_index.data')\ndow_jones=dow_jones.loc[:,['date','stock','open','high','low']] \n\ndef to_datatime(x):\n  return datetime.datetime.strptime(x, '%m/%d/%Y')\n\ndow_jones['datatime']=dow_jones['date'].apply(to_datatime)\ndow_jones = dow_jones.set_index(['datatime'])\ndow_jones=dow_jones.drop(['date'], axis=1)\ndow_jones.head()\n</pre> dow_jones = pd.read_csv('../data/dow_jones_index/dow_jones_index.data') dow_jones=dow_jones.loc[:,['date','stock','open','high','low']]   def to_datatime(x):   return datetime.datetime.strptime(x, '%m/%d/%Y')  dow_jones['datatime']=dow_jones['date'].apply(to_datatime) dow_jones = dow_jones.set_index(['datatime']) dow_jones=dow_jones.drop(['date'], axis=1) dow_jones.head() Out[137]: stock open high low datatime 2011-01-07 AA $15.82 $16.72 $15.78 2011-01-14 AA $16.71 $16.71 $15.64 2011-01-21 AA $16.19 $16.38 $15.60 2011-01-28 AA $15.87 $16.63 $15.82 2011-02-04 AA $16.18 $17.39 $16.18 In\u00a0[138]: Copied! <pre>for i in dow_jones.columns[1:]:\n    dow_jones[i]=dow_jones[i].str.strip('$').astype(float)\ndow_jones.head()\n</pre> for i in dow_jones.columns[1:]:     dow_jones[i]=dow_jones[i].str.strip('$').astype(float) dow_jones.head() Out[138]: stock open high low datatime 2011-01-07 AA 15.82 16.72 15.78 2011-01-14 AA 16.71 16.71 15.64 2011-01-21 AA 16.19 16.38 15.60 2011-01-28 AA 15.87 16.63 15.82 2011-02-04 AA 16.18 17.39 16.18 <ul> <li>Get the last business day of each month</li> </ul> In\u00a0[40]: Copied! <pre>dow_jones.iloc[:,1:4].resample('BME').mean()\n</pre> dow_jones.iloc[:,1:4].resample('BME').mean() Out[40]: open high low datatime 2011-01-31 51.671083 52.839417 50.934167 2011-02-28 53.411250 54.465583 52.577917 2011-03-31 53.237083 54.142083 51.929833 2011-04-29 54.377600 55.574533 53.590400 2011-05-31 55.507417 56.335333 54.373500 2011-06-30 53.525167 54.436833 52.197583 <ul> <li>Compute the mean of each month for each index.</li> </ul> In\u00a0[139]: Copied! <pre>dow_jones.groupby(dow_jones.stock).mean().head()\n</pre> dow_jones.groupby(dow_jones.stock).mean().head()  Out[139]: open high low stock AA 16.5640 17.0152 16.0636 AXP 46.4880 47.5684 45.5976 BA 73.2972 74.7712 71.6432 BAC 13.1756 13.4548 12.7776 CAT 103.0672 105.5296 99.9932 In\u00a0[148]: Copied! <pre># dow_jones.groupby([dow_jones.index,dow_jones.stock]).mean()\ndow_jones.groupby([dow_jones.index,dow_jones.stock]).resample('BME').mean()\n</pre> # dow_jones.groupby([dow_jones.index,dow_jones.stock]).mean() dow_jones.groupby([dow_jones.index,dow_jones.stock]).resample('BME').mean() Out[148]: open high low datatime stock datatime 2011-01-07 AA 2011-01-31 15.82 16.72 15.78 AXP 2011-01-31 43.30 45.60 43.11 BA 2011-01-31 66.15 70.10 66.00 BAC 2011-01-31 13.85 14.69 13.80 CAT 2011-01-31 94.38 94.81 92.30 ... ... ... ... ... ... 2011-06-24 TRV 2011-06-30 57.57 58.28 56.12 UTX 2011-06-30 84.36 86.21 83.69 VZ 2011-06-30 35.35 36.17 35.20 WMT 2011-06-30 52.70 53.70 52.35 XOM 2011-06-30 78.65 81.12 76.78 <p>750 rows \u00d7 3 columns</p> In\u00a0[126]: Copied! <pre>dow_jones_df = pd.DataFrame()\nfor i in list(set(dow_jones['stock'])):\n    temp=dow_jones.loc[dow_jones['stock'].isin([i])].iloc[:,1:].resample('BME').mean()\n    temp['stock']=i\n    dow_jones_df=pd.concat([temp, dow_jones_df])\n</pre> dow_jones_df = pd.DataFrame() for i in list(set(dow_jones['stock'])):     temp=dow_jones.loc[dow_jones['stock'].isin([i])].iloc[:,1:].resample('BME').mean()     temp['stock']=i     dow_jones_df=pd.concat([temp, dow_jones_df]) In\u00a0[127]: Copied! <pre>dow_jones_df\n</pre> dow_jones_df Out[127]: open high low stock datatime 2011-01-31 19.0025 19.5625 18.6225 GE 2011-02-28 20.8225 21.3150 20.5375 GE 2011-03-31 20.2475 20.4950 19.4875 GE 2011-04-29 20.1380 20.6020 19.7200 GE 2011-05-31 19.9600 20.1750 19.4875 GE ... ... ... ... ... 2011-02-28 16.9700 17.4250 16.5975 AA 2011-03-31 16.4300 16.8150 15.8100 AA 2011-04-29 17.1820 17.7340 16.6720 AA 2011-05-31 16.8475 17.3375 16.4175 AA 2011-06-30 15.6525 15.9900 15.0225 AA <p>180 rows \u00d7 4 columns</p> In\u00a0[141]: Copied! <pre>dow_jones.loc[dow_jones['stock'].isin(['AA'])].head()\n</pre> dow_jones.loc[dow_jones['stock'].isin(['AA'])].head() Out[141]: stock open high low datatime 2011-01-07 AA 15.82 16.72 15.78 2011-01-14 AA 16.71 16.71 15.64 2011-01-21 AA 16.19 16.38 15.60 2011-01-28 AA 15.87 16.63 15.82 2011-02-04 AA 16.18 17.39 16.18 In\u00a0[147]: Copied! <pre>dow_jones.loc[dow_jones['stock'].isin(['AA'])].iloc[:,1:].resample('BME').mean()\n</pre> dow_jones.loc[dow_jones['stock'].isin(['AA'])].iloc[:,1:].resample('BME').mean() Out[147]: open high low datatime 2011-01-31 16.1475 16.6100 15.7100 2011-02-28 16.9700 17.4250 16.5975 2011-03-31 16.4300 16.8150 15.8100 2011-04-29 17.1820 17.7340 16.6720 2011-05-31 16.8475 17.3375 16.4175 2011-06-30 15.6525 15.9900 15.0225 <ul> <li>Lowerizer the stock column</li> </ul> In\u00a0[179]: Copied! <pre>lowerizer = lambda x: x.lower()\ndow_jones['stock'].apply(lowerizer)\n</pre> lowerizer = lambda x: x.lower() dow_jones['stock'].apply(lowerizer) Out[179]: <pre>datatime\n2011-01-07     aa\n2011-01-14     aa\n2011-01-21     aa\n2011-01-28     aa\n2011-02-04     aa\n             ... \n2011-05-27    xom\n2011-06-03    xom\n2011-06-10    xom\n2011-06-17    xom\n2011-06-24    xom\nName: stock, Length: 750, dtype: object</pre>"},{"location":"book/ch3_data_analysis/ch3_challenges/#challenges","title":"Challenges\u00b6","text":""},{"location":"book/ch3_data_analysis/ch3_challenges/#working-with-data-frame","title":"Working with data frame:\u00b6","text":"<p>Here we consider the iris data to analysis</p> <ul> <li>Read iris data from https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data.</li> </ul>"},{"location":"book/ch3_data_analysis/ch3_challenges/#working-with-html","title":"working with html\u00b6","text":""},{"location":"book/ch3_data_analysis/ch3_challenges/#caluclate-the-distance-flight","title":"Caluclate the distance flight\u00b6","text":"<p>This part credit goes for  https://github.com/TomAugspurger/pandas-best-practices We us airport data here, https://raw.githubusercontent.com/hadley/nycflights13/master/data-raw/airports.dat,</p>"},{"location":"book/ch3_data_analysis/ch3_challenges/#dow-jones-index","title":"Dow Jones Index\u00b6","text":"<p>We are going to use Dow Jones stock Index.</p>"},{"location":"book/ch3_data_analysis/ch3_missing/","title":"Missing","text":"<p>Python can easily handle the missing, it has different symbols to work with missing: <code>None</code> and <code>np.nan</code> acting the same. <code>np.nan</code> is a float number  so when it used, the type of data change to float number. Numpy uses <code>NaN</code> as missing. Panda use <code>pd.NA</code> instead <code>None</code> and <code>np.nan</code>.</p> <pre><code>import numpy as np\nimport pandas as pd \n\nraw_data = {'income': [10,np.nan,14,16],'pay': [9,11,13,pd.NA],}\ndat = pd.DataFrame(raw_data, columns = ['income','pay'])\ndat\n</code></pre> <p>get the number of missing data points per column <pre><code>mvc = dat.isnull().sum()\n</code></pre></p> <p>How many total missing values do we have? <pre><code>total_cells = np.prod(dat.shape)\ntotal_missing = mvc.sum()\n</code></pre></p> <p>Percent of data that is missing <pre><code>percent_missing = (total_missing/total_cells) * 100\nprint(percent_missing)\n</code></pre></p>"},{"location":"book/ch3_data_analysis/ch3_missing/#drop-missing","title":"Drop missing","text":"<p>Remove all the rows that contain a missing value <pre><code>dat.dropna()\ndat.notnull() #let you highlight values which are not empty (NaN)\ndat.isnull() #let you highlight values which are  empty (NaN)\ndat.notna() #let you highlight values which are not NaN\n</code></pre></p> <p>Remove all columns with at least one missing value <pre><code>columns_with_na_dropped =dat.dropna(axis=1)\ncolumns_with_na_dropped.head()\n</code></pre></p>"},{"location":"book/ch3_data_analysis/ch3_missing/#filling-missing","title":"Filling missing","text":"<p>They fill with the mean of other values. <pre><code>dat.income.fillna(dat.income.mean())\ndat.fillna(dat.mean())\n</code></pre></p> <p>replace all NA's with -9 <pre><code>dat.fillna(-9)\n</code></pre></p> <p>pandas defines different procedures for filling missing, the following code interpolate the NaN.</p> <p><pre><code>dat.interpolate()\n</code></pre> Sometimes one needs to define part of data as missing, it can be done using <code>.apply</code> <pre><code>dat.income.apply(lambda x: np.nan if x&lt;=14 else x)\n</code></pre></p> <p>You can use <code>math.isnan</code> to on numpy</p> <pre><code>import math\n[math.isnan(i) for i in dat.income]\n[math.isnan(i) for i in dat.pay]\n</code></pre>"},{"location":"book/ch3_data_analysis/ch3_overview/","title":"Overview","text":"<p>This section covers essential topics related to working with data frames.</p> <ul> <li>Panda</li> <li>Working with time</li> <li>Missing value</li> <li>Challenges</li> </ul>"},{"location":"book/ch3_data_analysis/ch3_panda/","title":"Pandas","text":""},{"location":"book/ch3_data_analysis/ch3_panda/#introduction","title":"Introduction","text":"<p>Pandas is built on top of NumPy, and its functions are highly useful for working with datasets. The shorthand for importing this library is: <pre><code>import pandas as pd\n</code></pre></p>"},{"location":"book/ch3_data_analysis/ch3_panda/#data-frame","title":"Data-frame","text":"<p>A DataFrame in Pandas is a highly useful format for working with datasets. It is a two-dimensional, size-mutable, and potentially heterogeneous tabular data structure with labeled axes (rows and columns). The following code demonstrates how to create a DataFrame from a dictionary:</p> <p><pre><code>var={\"A\": [1,2,0], \"B\": [2,3,4]}\ndf= pd.DataFrame(data=var,index=['A', 'Z', 'C'])\n</code></pre> One can reorder the index, </p> <pre><code>df1= df.reindex(['A','C','Z'])\nprint(df1)\n</code></pre> <p>The column labels can be easily modified: <pre><code>raw_data = {'population': [ 1015.0, 1129.0, 333.0,  515.0],'median_income': [ 1.5, 1.8,  1.7,  3.2]}\ndf=pd.DataFrame(raw_data, columns = ['population', 'median_income'])\n</code></pre></p> <p>In certain situations, it is beneficial to use the data collection time as the index. The following script converts the data to a datetime format and sets it as the index:  <pre><code>df = df.set_index(pd.to_datetime(['2019-04-01','2019-05-04','2019-06-01','2019-07-02']))\n</code></pre></p> <p>Always use <code>to_datetime</code> to ensure the data is stored in a proper datetime format. This allows easy conversion to specific components such as year, weekday, and more.</p> <pre><code>df1['date'] = pd.to_datetime(['2019-04-01','2019-05-04','2019-06-01','2019-07-02'])\ndf1['date'].dt.weekday\ndf1['date'].dt.year\n</code></pre> <p>To create an empty DataFrame, use the following code: <pre><code>df1=pd.DataFrame(columns = ['population', 'median_income'])\ndf2=pd.DataFrame()\n</code></pre></p>"},{"location":"book/ch3_data_analysis/ch3_panda/#adding-new-column","title":"Adding new column","text":"<p>A column can be easily added to a DataFrame:</p> <pre><code>df0=pd.DataFrame([38,40,25,33])\ndf['Ave_hour']=df0\n</code></pre> <p>The <code>assign()</code> method can also be used to add new columns to a DataFrame. Additionally, new columns can be created using functions, as shown below:</p> <pre><code>df=df.assign(Ave_hour=df0)\ndf=df.assign(PI1=lambda x: x['population']*x['median_income'],PI2=df['population']/df['median_income'] )\n</code></pre> <p>A column's name can be renamed using the rename() method, as shown below: <pre><code>df.columns=['population1','median_income','Ave_hour','PI1','PI2']\ndf=df.rename(columns={'population1': 'pop', 'median_income': 'med_income'},inplace=True)\n</code></pre></p>"},{"location":"book/ch3_data_analysis/ch3_panda/#apply-function-on-row-or-column","title":"Apply function on row or column","text":"<p>Using <code>df.apply(fun)</code> allows you to apply a function to either columns or rows of a DataFrame. Here's an example:</p> <pre><code>df.apply(np.sum, axis=0)\ndf.apply(np.sum, axis=1)\n</code></pre> <p>You can even apply a function to specific columns or rows.</p> <pre><code>df.apply(lambda x: x['A'] * x['B'], axis=1)\ndf['productcolmn']=df.apply(lambda x: x['A'] * x['B'], axis=1)\n\n\ndef majority(x):\n    if x &gt; 17:\n        return True\n    else:\n        return False\n\nstud_alcoh['legal_drinker'] = stud_alcoh['age'].apply(majority)\n</code></pre>"},{"location":"book/ch3_data_analysis/ch3_panda/#loading-csv-data","title":"Loading CSV data","text":"<p>The function <code>pd.read_csv</code> is used to import data saved in CSV format. The following example demonstrates how to import a CSV file into Python, with the data being the California housing dataset:</p> <pre><code>source =\"https://storage.googleapis.com/mledu-datasets/california_housing_train.csv\"\nCHT = pd.read_csv(source, sep=\",\")\nCHT.head()\n</code></pre>"},{"location":"book/ch3_data_analysis/ch3_panda/#loading-big-csv-data","title":"Loading big CSV data","text":"<p>If the data is very large, you may need to split it into chunks and perform computations on each chunk.</p> <pre><code>chunk_size=100\nchunk=[]\nfor chunk in pd.read_csv('file.csv',chunksize=chunk_size):\n   do computation\n  chunks.append(chunk)\ndf = pd.concat(chunks, axis=0)\n</code></pre>"},{"location":"book/ch3_data_analysis/ch3_panda/#generating-summary","title":"Generating summary","text":"<p>To view the data types, summary statistics, and general information about the variables in a DataFrame, use <code>.dtypes</code>,  <code>.describe()</code>, and   <code>.info()</code>.</p> <pre><code># show the type of variables\nCHT.dtypes\n# generate summary\nCHT.describe()\nCHT.info()\n</code></pre> <p>It is easy to identify and remove duplicates in a DataFrame. <pre><code>CHT.duplicated()\nCHT.drop_duplicates()\n</code></pre></p> <p>To check for duplicates in specific columns, specify their names as well. <pre><code>CHT.duplicated(['longitude'])\nCHT.drop_duplicates(['longitude'], keep='last')\nCHT.index.duplicated()\n</code></pre></p> <p>To truncate the display of data, you can adjust the display options using <code>pd.set_option()</code> <pre><code>pd.set_option('display.max_rows', 50)\npd.set_option('precision', 4)\n</code></pre></p>"},{"location":"book/ch3_data_analysis/ch3_panda/#data-type","title":"Data type","text":"<p>Pandas has different data types;  object (a mix of different type of data), int64 ( interger numbers), float64(floating-point numbers), bool(True/False values), datetime64(Date and time values), category(a finite number of possible values). The following codes show how to define the data type. </p> <pre><code>raw_data = {'population': [ 1015.0, 1129.0, 333.0,  515.0],'median_income': [ 1.5, 1.8,  1.7,  3.2], 'class_income': ['low', 'low',  'low',  'high'], 'time':['2019-04-01','2019-05-04','2019-06-01','2019-07-02']}\ndf=pd.DataFrame(raw_data, columns = ['population', 'median_income','class_income','time'])\ndf.dtypes\ndf['population']=df['population'].astype('int64')\ndf['median_income']=df['median_income'].astype('float64')\ndf['class_income']=df['class_income'].astype(CategoricalDtype(categories=['low', 'high'], ordered=True))\ndf['time']=df['time'].astype('datetime64')\ndf.dtypes\n</code></pre>"},{"location":"book/ch3_data_analysis/ch3_panda/#size-of-data-frame","title":"Size of data-frame","text":"<p>The dimension of a DataFrame is 2, which can be accessed using <code>.ndim</code>. The number of rows and columns can be obtained with <code>.shape</code>.</p> <pre><code>CHT.ndim\nCHT.shape\nCHT.shape[0]\nCHT.shape[1]\n</code></pre>"},{"location":"book/ch3_data_analysis/ch3_panda/#preview","title":"Preview","text":"<p>Beside the function <code>print</code>, Pandas can show the first and the last part of data, using <code>.head()</code> and <code>.tail()</code>.  By passing a number in the parenthesis, one can specify the output.</p> <pre><code>CHT.head(10)\nCHT.tail(10)\nCHT.sort_values(by='housing_median_age', ascending=False).head(3)\nCHT.columns\n</code></pre>"},{"location":"book/ch3_data_analysis/ch3_panda/#manipulating-data-frame","title":"Manipulating data-frame","text":""},{"location":"book/ch3_data_analysis/ch3_panda/#subset-of-data","title":"Subset of Data","text":"<p>To select the data use the name of variable, or specify the indices via <code>.iloc</code> and <code>.loc</code> (link)[http://pandas.pydata.org/pandas-docs/version/0.22/indexing.html]. <code>.iloc</code> is an integer-based and select should use integer index. On contrary, <code>.loc</code>   is primarily label based, and may also be used with a boolean array.</p> <pre><code>CHT.longitude\nCHT['longitude']\nCHT.iloc[:,1]\nCHT.iloc[:,[1,3,4]]\nCHT.iloc[:,np.r_[1,3:6]]\n</code></pre> <p>To select part of row, you can also use <code>iloc[index of row,:]</code>, also the rows can be selected using the logical values <pre><code>CHT.iloc[2:10]\nCHT.iloc[2:10,:]\nCHT[CHT.iloc[:,1]&lt;34]\n</code></pre></p> <p>To retieve part of row, should pass boolean variable, <code>.iloc</code> does not work boolean variable, and <code>.loc</code> should be used.  Consider the median_income in our data, by using quartile divid it into three categories. <pre><code>CHT['famlev'] = ''\nC1=CHT.median_income&lt;=CHT.median_income.quantile(.3)\nC2=CHT.median_income&gt;=CHT.median_income.quantile(.7)\nCHT.loc[C1,'famlev']='L'\nCHT.loc[~C1&amp;~C2,'famlev']='M'\nCHT.loc[C2,'famlev']='H'\n</code></pre> Obviously, we can use <code>&amp;</code> to bring the <code>~C1</code> and <code>~C2</code> together. In this case we used <code>.loc</code>, obviously we specify column labels to retrieve columns instead of by position.</p> <p>Note: You can also using [][] apply different conditions on data. <pre><code>CHT['median_house_value'][CHT['famlev'] == 'M'].mean()\n</code></pre></p> <p>Selecting or searching can be done also using <code>np.where</code> which evaluate the condition  <pre><code>CHT_R=CHT[['total_rooms','total_bedrooms']]\nCHT_R.where(CHT.total_rooms&lt;1000)\nCHT_R.where(CHT.total_rooms&lt;1000,0)\ncon= CHT_R&lt;1000\nCHT_R.where(con, -999)\n\nCHT.idxmin()\nCHT.idxmax()\n</code></pre></p> <p>Opposite of this <code>np.where</code> is <code>np.mask</code>, replace it with <code>np.where</code> and rerun the codes.  To drop row and columns use <code>.drop</code>. The <code>np.where</code> can be used to create a new  column,  <pre><code>CHT['size']=np.where(CHT.total_rooms&lt;1000, 'small', 'big')\nCHT_R=CHT[['total_rooms','total_bedrooms']]\nCHT_R.where(CHT.total_rooms&lt;1000)\nCHT_R.where(CHT.total_rooms&lt;1000,0)\ncon= CHT_R&lt;1000\nCHT_R.where(con, -999)\n</code></pre></p> <p>Find which ones are 'M' <pre><code>np.where(CHT.loc[:,'famlev'].isin(['M']))\n</code></pre></p> <p><code>isin</code> lets you select data whose value \"is in\" a list of values. <pre><code>CHT.drop([0,5], axis=0)\nCHT.drop('longitude',axis=1, inplace=True)\n</code></pre></p> <pre><code>CHT[CHT['size'].str.startswith('b')]\nCHT.iloc[: , :-3]\nCHT.loc[CHT['size'].isin(['big'])]\n</code></pre> <p>To replace values, use <code>df.replace()</code></p> <pre><code>CHT['famlev'].replace('L','Low').replace('M','Middle').replace('H','High')\nCHT.drop('longitude',axis=1, inplace=True)\n</code></pre> <p>Note: the argument <code>inplace=True</code> apply the change on the original data. To transpose dataframe, run <code>CHT.T</code>. To change the  type of column apply <code>astype(np.int)</code> on them <pre><code>CHT.total_rooms.astype(np.int)\n</code></pre></p> <p>One can take a random subset of data using  <pre><code>CHT.sample(4)\n</code></pre></p> <p>To delete the columdn, use <code>del</code>: <pre><code>del CHT['famlev']\n</code></pre></p>"},{"location":"book/ch3_data_analysis/ch3_panda/#eval","title":"eval","text":"<p>You can evaluate a Python expression before using it, </p> <pre><code>var={\"A\": [1,2,0], \"B\": [2,3,4], \"C\":['A', 'Z', 'C']}\ndf= pd.DataFrame(data=var)\npd.eval('df.A + df.B')\n</code></pre> <pre><code>df.eval('D = A + B')\ndf\n</code></pre> <pre><code>df.eval('D = A + B', inplace=True)\ndf\n</code></pre> <p>Evaluate a Python expression as a string using various backends.</p>"},{"location":"book/ch3_data_analysis/ch3_panda/#select-row-using-query","title":"Select row using query","text":"<p><code>query</code> can be used to to select row, the following code  Selecting or searching can be done also using <code>np.where</code> which evaluate the condition  <pre><code>CHT[CHT.total_rooms&lt;1000)\n</code></pre></p> <pre><code>CHT.query('total_rooms&lt;1000')\n</code></pre> <p>To use a variable inn a panda query use <code>@</code>,  <pre><code>total=1000\nCHT.query('total_rooms&lt; @total')\n</code></pre></p> <p>You can use f-string to not use <code>@</code>: <pre><code>total=1000\nCHT.query(f'total_rooms&lt; {total}')\n</code></pre></p>"},{"location":"book/ch3_data_analysis/ch3_panda/#select-based-on-data-types","title":"Select based on data types","text":"<p><code>df.select_dtypes([])</code> return  columns that has a specic type.  <pre><code>df.select_dtypes(include='int')\ndf.select_dtypes(include='bool')\ndf.select_dtypes(include=['float64'])\n</code></pre></p>"},{"location":"book/ch3_data_analysis/ch3_panda/#delete-row-or-column","title":"delete row or column","text":"<pre><code>CHT.drop([0,2]) # drop first and third rows\nCHT.drop(columns=['famlev']) #\nCHT.drop(CHT.columns[[0,2]], axis = 1) # drop the first and third column\n</code></pre>"},{"location":"book/ch3_data_analysis/ch3_panda/#combining-columns","title":"Combining columns","text":"<p>Columns can easily combine to create a new column</p> <pre><code>CHT['famsize']=CHT['famlev']+'-'+CHT['size']\n</code></pre>"},{"location":"book/ch3_data_analysis/ch3_panda/#repeat","title":"repeat","text":"<p>It is possible to repeat the element in data frame,   </p> <pre><code>df1 = pd.DataFrame([[1, 2], [3, 4], ['a', 'b']], columns=[\"A\", \"B\"])\ndf2 = pd.DataFrame([[5, 6], [7, 8]], columns=[\"c\", \"d\"])\nab=pd.DataFrame(np.repeat(df1.values, 2, axis=0), columns=df1.columns) # repeat column in sequence\nac=df2.iloc[np.tile(np.arange(len(df2)), len(df1))].reset_index(drop = True) # repeat in total\n</code></pre>"},{"location":"book/ch3_data_analysis/ch3_panda/#list-comprehension","title":"list comprehension","text":"<p>Simple operation using the list comprehension can be done on data-frame as well. <pre><code>CHT['size']=['small' if x&lt;100  else 'big'  for x in CHT['total_rooms']]\n</code></pre></p>"},{"location":"book/ch3_data_analysis/ch3_panda/#summarising","title":"Summarising","text":"<p>Although <code>.describe</code> can give a summary of variables,  more specific summery of variables (columns) can be extracted, see</p> <pre><code>CHT.count\nCHT[CHT.iloc[:,1]&lt;34].nunique()\n</code></pre> <p>The following table includes the functions.</p> Function Description <code>count</code> Number of non-null observations <code>sum</code> Sum of values <code>mean</code> Mean of value <code>mad</code> Mean absolute deviation <code>median</code> median of values <code>min</code> Minimum <code>max</code> Maximum <code>mode</code> Mode <code>abs</code> Absolute Value <code>prod</code> Product of values <code>std</code> Unbiased standard deviation <code>var</code> Unbiased variance <code>sem</code> Unbiased standard error of the mean <code>skew</code> Unbiased skewness (3<sup>rd</sup> moment) <code>kurt</code> Unbiased kurtosis (4<sup>th</sup> moment) <code>quantile</code> Sample quantile (value at %) <code>cumsum</code> Cumulative sum <code>cumprod</code> Cumulative product <code>cummax</code> Cumulative maximum <code>cummin</code> Cumulative minimum <code>nunique</code> number of unique elements <code>value_counts</code> Counts of unique values <code>cov</code> Calculate the covariance between columns <code>corr</code> Calculate the correlation between columns"},{"location":"book/ch3_data_analysis/ch3_panda/#groupby","title":"groupby","text":"<p>The summaries can be obtained using any grouping variables in the data set:</p> <pre><code>CHT.groupby(['famlev']).groups.keys()\nCHT.groupby(['famlev']).groups['H']\nCHT.groupby(['famlev']).first()\n\nCHT.groupby(['famlev']).sum()\n\nCHT.groupby(['famlev'])['median_house_value'].sum()\n# better output\nCHT.groupby(['famlev'])[['median_house_value']].sum()\n</code></pre> <p>The grouped variables would be assigned as indices, to bring them back as variables use <code>pf.reset.index()</code> <pre><code>CHT.reset_index(drop = True)\n</code></pre></p> <p>It is possible to apply even complex function, the following scripts calculate the coefficient of data.</p> <pre><code>def cv(x):\n return (np.mean(x)/np.var(x))\n\naggr = {\n    'total_rooms':'sum',\n    'population': lambda x: cv(x)\n}\nCHT.groupby('famlev').agg(aggr)\n</code></pre> <p>The output can be tidied up,</p> <pre><code>aggr = {\n    'total_rooms':['mean','std']\n}\ngrouped = CHT.groupby('famlev').agg(aggr)\ngrouped.columns = grouped.columns.droplevel(level=0)\ngrouped.rename(columns={\"mean\": \"total_rooms\", \"std\": \"total_rooms\"})\ngrouped.head()\n</code></pre> <p>To apply the transform on the individual data point in thee data frame, use <code>.transform()</code>, let run the standardization on the  <pre><code>CHT.median_income.transform(lambda x: (x - x.mean())/x.std()) \n</code></pre></p>"},{"location":"book/ch3_data_analysis/ch3_panda/#pivot_table","title":"pivot_table","text":"<p>The summarizations can be done using pivot table,  <pre><code>pd.pivot_table(CHT, index=['famlev'], aggfunc=['mean'])\n</code></pre></p> <p>Let consider two variables in the index of pivot table, the result will be a stack table which using <code>.unstack()</code>, it convert to stack, see below </p> <pre><code>pv_0=pd.pivot_table(CHT, index=['famlev','size'], aggfunc=['mean'])\npv_0.columns = pv_0.columns.droplevel() # drop a level from a multi level comulmn index\npv_0.unstack()\n</code></pre> <p>Pivot can provide more tools, see below <pre><code>df = pd.DataFrame([[\"a\",\"n1\",\"1\"], [\"a\",\"n2\",\"2\"], [\"b\",\"n1\",\"3\"], [\"b\",\"n2\",\"s4\"],[\"b\",\"n2\",\"s4\"]], columns=[\"meta1\", \"name\", \"data\"])\ndf.pivot_table(values='data', index='meta1', columns='name', aggfunc=\",\".join)\n</code></pre></p>"},{"location":"book/ch3_data_analysis/ch3_panda/#iterating-over-rows","title":"Iterating over rows","text":"<p>Unlike numpy, pandas is column based, to create numpy array just use  <code>CHT.to_numpy()</code>. A simple way tp iterate over row, one can use <code>.iterrows()</code> and <code>.itertuples()</code>. The <code>.iterrows()</code> creates series from row,</p> <pre><code>for index, row in CHT.iterrows():\n    print(row)\n</code></pre> <p>The <code>.itertuples()</code> generates tuple of rows. <pre><code>for row2 in CHT.itertuples():\n    print(row2)\n</code></pre></p>"},{"location":"book/ch3_data_analysis/ch3_panda/#merging","title":"Merging","text":"<p>Panada is very useful for merging dataset, to achieve merging data consider the following data sets, where 'id1' and 'id2' include the ids of data.</p> <pre><code>raw_data = {'id1': range(4),'income': [10,12,14,16]}\ndat1 =pd.DataFrame(raw_data, columns = ['id1', 'income'])\n\nraw_data = {'id2': range(6),'pay': [9,11,13,15,17,19]}\ndat2 =pd.DataFrame(raw_data, columns = ['id2', 'pay'])\n</code></pre> <p>Obviously the id variable are not the same, they can be compared using <pre><code>dat1['id1'].isin(dat2['id2']).value_counts()\ndat2['id2'].isin(dat1['id1']).value_counts()\n</code></pre></p> <p><code>value_counts()</code> produce list of unique values and how often they occur in the dataset.  <code>pd.merge</code> can merge different data-frames, the merging can be done based on the identities of left dataset, if there is no match in the right file, Python adds <code>NaN</code>. <pre><code>result = pd.merge(dat1, dat2, left_on='id1', right_on='id2',how='left')\n</code></pre></p> <p>On contrary, one can the right dataset as matching, <pre><code>result = pd.merge(dat1, dat2, left_on='id1', right_on='id2',how='right')\n</code></pre></p> <p>Since the ids are not the same, one can do merging based on the intersection of the ids, <pre><code>result = pd.merge(dat1, dat2, left_on='id1', right_on='id2',how='inner')\n</code></pre></p> <p>Merging can also be done based on the union of the ids, <pre><code>result = pd.merge(dat1, dat2, left_on='id1', right_on='id2',how='outer')\n</code></pre></p> <p>Note: If the names of id variables are the same in the both datasets, you can use <code>on=id_name</code> instead  <code>left_on=</code> and <code>right_on=</code>. Note: if you want to identify where the date in rows are from, add  argument <code>indicator=True</code>, then new column named <code>_merge</code> would be added to the merged data which show its originate. <pre><code>result = pd.merge(dat1, dat2, left_on='id1', right_on='id2',how='outer', indicator=True)\n</code></pre></p> <p>To combine row-wise, use <code>concat</code>. <pre><code>result = pd.concat([dat1, dat2],axis=1)\n</code></pre></p> <p>To combine column-wise: <pre><code>result = pd.concat([dat1,dat1], axis=0)\n</code></pre></p> <p>note, if dat1 and dat2 are not dataframe, the result will bot be dataframe, so you might use  <pre><code>result.to_frame()\n</code></pre></p> <p>If the dataframes ahve the same columns, they can be combined using  <code>df1.append(df2)</code>. </p>"},{"location":"book/ch3_data_analysis/ch3_panda/#melt","title":"Melt","text":"<p>To change from wide to long, we can use <code>pd.melt(df, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None, ignore_index=True)</code>. </p> <pre><code>var={\"A\": [1,2,0], \"B\": [2,3,4], \"C\":['A', 'Z', 'C']}\ndf= pd.DataFrame(data=var)\npd.melt(df, id_vars=['A'], value_vars=['B', 'C'])\npd.melt(df, id_vars=['A'], var_name=\"id\",value_vars=['B', 'C'],value_name='A_or_B')\npd.melt(df, id_vars=['A'], value_vars=['B', 'C'],var_name=\"test\",value_name='value2',ignore_index=False) # keep orifinal index\npd.melt(df, id_vars=['A'], value_vars=['B', 'C'],var_name=\"test\",value_name='value2',ignore_index=True) # generate new index\npd.melt(df, id_vars=['A'], value_vars=['B', 'C'],var_name=\"test\",value_name='value2',ignore_index=True)\n</code></pre> <p>If columns are a MultiIndex then use <code>col_level =0, 1</code> to decide which level to melt.</p>"},{"location":"book/ch3_data_analysis/ch3_panda/#creating-bins","title":"Creating bins","text":"<p>To create bins from the data value, one can use <code>pd.cut</code>, it actually creates a categorical variable from continuous variables </p> <pre><code>var={\"A\": [1,2,0,7,9,4,3,1]}\ndf= pd.DataFrame(data=var)\npd.cut(df.A,3)  # creat three bins\npd.cut(df.A,3,labels=[\"low\",'middle', \"high\"]) # add label\npd.cut(df.A,3,labels=[\"low\",'middle', \"high\"], ordered=False) # drop order\npd.cut(df.A,3, labels=False) # drop label\npd.cut(df.A,[0, .25, .5, .75, 1.]) # add the bins manually\n</code></pre> <p>To generate bins according the quantiles, use <code>.gcut()</code> <pre><code>pd.qcut(df.A,[0, .25, .5, 1.])\n</code></pre></p>"},{"location":"book/ch3_data_analysis/ch3_panda/#interval_range","title":"interval_range","text":"<p>The function <code>interval_range</code> can eb used to data with range format, such data can be use as index as well.  <pre><code>pd.interval_range(start=0, end=10, freq=3)\npd.interval_range(start=0, end=10, freq=3, closed='left')\npd.interval_range(start=pd.Timestamp('2021-01-01'),end=pd.Timestamp('2021-01-30'))\npd.interval_range(start=pd.Timestamp('2021-01-01'),periods=4)\n</code></pre></p>"},{"location":"book/ch3_data_analysis/ch3_panda/#dummy","title":"Dummy","text":"<p>It generates a dummy variable from categorial variable  <pre><code>var={\"A\": [1,2,0], \"B\": [2,3,4], \"C\":['A', 'Z', 'C']}\ndf= pd.DataFrame(data=var)\npd.get_dummies(df)\npd.get_dummies(df.C)\n</code></pre></p>"},{"location":"book/ch3_data_analysis/ch3_panda/#factorize","title":"Factorize","text":"<p>The function <code>pd.factorize()</code>  is useful to get distinct value of array or represent the array as numeric,  Encode the object as an enumerated type or categorical variable. <pre><code>var=pd.DataFrame({\"A\": [1,2,0], \"B\": [2,3,4], \"C\":['A', 'Z', 'C']})\nlab, uniques = pd.factorize(var.C)\nlab\nuniques\n</code></pre></p> <p>Pandas has the function <code>pd.Categorical()</code> that can be use to represent a categorical data, the followinf scripts show how pd.factorize can be use on categorical data. <pre><code>var = pd.Categorical(['a', 'a', 'c'], categories=['a', 'b', 'c'])\nlab, uniques = pd.factorize(var)\nlab\nuniques\n</code></pre></p>"},{"location":"book/ch3_data_analysis/ch3_panda/#crosstab","title":"Crosstab","text":"<p>Consider housing_median_age and total_rooms, group them using their quantile, then find the cross tabulate of them, <pre><code>CHT['houlev'] = ''\nC1=CHT.housing_median_age&lt;=CHT.median_income.quantile(.3)\nC2=CHT.housing_median_age&gt;=CHT.median_income.quantile(.7)\nCHT.loc[C1,'houlev']='L'\nCHT.loc[~C1&amp;~C2,'houlev']='M'\nCHT.loc[C2,'houlev']='H'\n\nCHT['roomlev'] = ''\nC1=CHT.total_rooms&lt;=CHT.total_rooms.quantile(.3)\nC2=CHT.total_rooms&gt;=CHT.total_rooms.quantile(.7)\nCHT.loc[C1,'roomlev']='L'\nCHT.loc[~C1&amp;~C2,'roomlev']='M'\nCHT.loc[C2,'roomlev']='H'\n\npd.crosstab(CHT.roomlev, CHT.houlev, margins=True)\n</code></pre></p> <p>Now use <code>famlev</code> as third variable and find their cross tab.</p> <pre><code>pd.crosstab([CHT.roomlev, CHT.houlev], CHT.famlev, margins=True)\n</code></pre>"},{"location":"book/ch3_data_analysis/ch3_panda/#accessors","title":"Accessors","text":"<p>The accessors include the built-in functions that come in handy when you want to do some basic function, list is  <pre><code>&gt;&gt;&gt; pd.Series._accessors\n{'sparse', 'str', 'cat', 'dt'}\n</code></pre> The <code>sparse</code>, <code>cat</code>, and <code>dt</code> can be used to handles sparse matrices, handles categorical data, and handles date formats.  'str' is very handy to string, see below. </p>"},{"location":"book/ch3_data_analysis/ch3_panda/#string-accessor","title":"String accessor","text":"<p>Pandas has useful functions to work with text data, and it also accepts \"regular expressions\" and \"re\" module, a complete description can be  in (link)[https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html],few examples are given in the below</p> <pre><code>var=pd.DataFrame({\"Name\":[\"Sa\", \"La\", \"Ry\"],\"Family\":[\"Am\", \"Al\", \"Am_AL\"], \"Date\":[\"2019\", \"2020\",\"2021\"]})\nvar.Family.str.count('Am') # show where it happens (0/1)\nvar.Family.str.match('Am') # show where it happens (True/False)\nvar.Family.isin(['Am'])   \nvar.Family.str.len()       # Compute the length\nvar.Family.str.isdigit()  # Shows is it number or not. \nvar.Family.str.lower()    # Convert to lower case\nvar.Family.str.upper()    # Convert to  upper case\nvar.Family.str.replace('Al','Am') # Replace 'Al' with 'Am'\nvar.Family.str.split(\"_\", expand=True) # Split where \"_\" observed\nvar.Family.str.cat(sep=\",\")            # Concatenate  \nvar.Family.str.cat(var.Name, join=\"left\",sep=\",\")   # Concatenate  with another variable\nvar.columns=var.columns.str.lower() # Convert the column's names to lower case \n</code></pre>"},{"location":"book/ch3_data_analysis/ch3_panda/#normalizestandardize","title":"Normalize\\Standardize","text":"<p>Sometime, we need to scale data, there are diifernt method.</p>"},{"location":"book/ch3_data_analysis/ch3_panda/#z-sccore","title":"Z-sccore","text":"<p>To normalize, we can use <code>zscore</code> from <code>scipy</code>: <pre><code>import pandas pd \nvar={\"A\": [1,2,3,4], \"B\": [4,3,2,1]}\ndf= pd.DataFrame(data=var,index=(range(4)))\nfrom scipy import stats\nstats.zscore(df)\n</code></pre></p>"},{"location":"book/ch3_data_analysis/ch3_panda/#box-cox-transformation","title":"Box-Cox Transformation","text":"<p>To run Box-Cox Transformation on data, you can use <code>boxcox</code> from <code>scipy</code>, 'the below run it on aspecific function. </p> <pre><code>df['A']=stats.boxcox(df.A)[0]\n</code></pre> <p>To run on all columsn, run the below code.  <pre><code>for col in df.columns[0:]:\n  df[col]=stats.boxcox(df[col])[0]\n</code></pre></p>"},{"location":"book/ch3_data_analysis/ch3_panda/#min-max-scaling","title":"Min-Max scaling","text":"<p>An alternative approach to z-score normalization is min-max which scale data 0-1, <code>minmax_scaling</code> from <code>mlxtend</code> achieve this aim. </p> <pre><code>from mlxtend.preprocessing import minmax_scaling\nvar={\"A\": [1,2,3,4], \"B\": [4,3,2,1]}\ndf= pd.DataFrame(data=var,index=(range(4)))\nminmax_scaling(df, columns=[\"A\",\"B\"])\n</code></pre> <p>This function can be used to numpy's array as weel </p> <pre><code>import numpy as np\narray = np.array([[1, 4], [2, 3], [3, 2], [4, 1]])\nminmax_scaling(array, columns=[0, 1])\n</code></pre>"},{"location":"book/ch3_data_analysis/ch3_panda/#pipeline","title":"Pipeline","text":"<p>Pipeline in pandas allows to build a sequence of function to run in order on data-frame. </p> <pre><code>def categ(x,col):\n  x[col].quantile(.3)\n  x['lev'] = ''\n  C1=x[col]&lt;=x[col].quantile(.3)\n  C2=x[col]&gt;=x[col].quantile(.7)\n  x.loc[C1,'famlev']='L'\n  x.loc[~C1&amp;~C2,'famlev']='M'\n  x.loc[C2,'famlev']='H'\n  return x\n\ndef cv(x):\n return (np.mean(x)/np.var(x))\n\nCHT.pipe(categ, col='median_income').pipe(cv)\n</code></pre>"},{"location":"book/ch3_data_analysis/ch3_panda/#convert-to-numpy","title":"Convert to Numpy","text":"<p>Data frame can easily be converted to an array and a matrix: </p> <pre><code>CHT.values\nCHT.as.matrix\n</code></pre>"},{"location":"book/ch3_data_analysis/ch3_panda/#save","title":"save","text":"<p>One of best format for saving data set is CSV data, the following script save the data as CSV without add row number and name, index=False.</p> <pre><code>CHT.to_csv(\"CHT.csv\", index=False, encoding='utf8')\nCHT.to_excel(\"CHT.xlsx\")\n</code></pre>"},{"location":"book/ch3_data_analysis/ch3_panda/#good-references","title":"Good References","text":"<p>http://jonathansoma.com/lede/foundations/ https://github.com/TomAugspurger/effective-pandas https://www.shanelynn.ie/summarising-aggregation-and-grouping-data-in-python-pandas/ https://chrisalbon.com/python/data_wrangling/pandas_crosstabs/ https://github.com/guipsamora/pandas_exercises</p>"},{"location":"book/ch3_data_analysis/ch3_time/","title":"Time","text":"<p>Here, we explain two time-related modules in Python.</p>"},{"location":"book/ch3_data_analysis/ch3_time/#datetime-module","title":"datetime module","text":"<p>The <code>datetime</code> module  provide functions to work with the date format, which they can be used to maniuplate and parsing a dates and time. </p> <pre><code>import  datetime\ntodays_date = datetime.date.today()\nprint(todays_date)\nnow = datetime.datetime.now()\nprint(now)\n</code></pre> <p>You can a general date object to represents a date (year, month and day).</p> <pre><code>dt = datetime.date(2024, 1, 2)\nprint(dt)\nprint(dt.year,dt.month,dt.day)\n</code></pre> <p>You can a general time object to represents a time (hour, minute, second and microsecond).</p> <pre><code>tm = datetime.time(12,3,4,5)\nprint(tm)\nprint(tm.hour,tm.minute,tm.second,tm.microsecond)\n</code></pre> <p>In a general you can you datetime object, </p> <pre><code>dtm = datetime.datetime(2024, 1, 2,12,3,4,5)\nprint(dtm)\nprint(dtm.year,dtm.month,dtm.day,dtm.hour,dtm.minute,dtm.second,dtm.microsecond)\n</code></pre> <p>You can change the structure of time, using  <code>strftime</code>; US format mm/dd/yyyy, UK's format dd/mm/yyyy</p> <p><pre><code>print(dtm.strftime(\"%m/%d/%Y, %H:%M:%S\"))\nprint(dtm.strftime(\"%d/%m/%Y, %H:%M:%S\"))\n</code></pre> %Y - year, %m - month, %B - month in full name, %d - day, %H - hour, %M - minute, %S - second.  The output is in string  format. You can reform tha sting format to datetime format. </p> <pre><code>date_string = \"25 January, 2024\"\ndate_string\n\ndate_object = datetime.datetime.strptime(date_string, \"%d %B, %Y\")\ndate_object\n</code></pre> <p>You can find different between time,  <pre><code>now_dtm = datetime.datetime.now()\ndtm = datetime.datetime(2024, 1, 2,12,3,4,5)\n\ndiff_dtm = now_dtm - dtm\ndiff_dtm\nprint(diff_dtm)\n</code></pre> Obviously the output the timedelta objects, to compute the total second of seconfd you can use <code>diff_dtm.total_seconds()</code></p> <p>You can handle the timezone in Python, </p> <pre><code>import pytz\nnow_dtm = datetime.datetime.now()\ntz_NY = pytz.timezone('America/New_York') \ndatetime_NY = datetime.datetime.now(tz_NY)\nprint(\"Local:\", now_dtm)\nprint(\"NY:\", datetime_NY)\n</code></pre>"},{"location":"book/ch3_data_analysis/ch3_time/#numerial-format","title":"numerial format","text":""},{"location":"book/ch3_data_analysis/ch3_time/#timestamp","title":"timestamp","text":"<p>A unix timestamp is the number of second between a particular date and January 1, 1970, at UTC. You can convert date to the timestamp() method.</p> <pre><code>now = datetime.datetime.now()\nprint(now)\nts=datetime.datetime.timestamp(now)\nprint(ts)\n</code></pre> <p>You can convert a timestamp to a date using the fromtimestamp() method.</p> <pre><code>timestamp = datetime.datetime.fromtimestamp(ts)\nprint(\"Date =\", timestamp)\n</code></pre>"},{"location":"book/ch3_data_analysis/ch3_time/#ordinal","title":"ordinal","text":"<p>Other approach to work with number instead data forma is to us the proleptic Gregorian ordinal of the date, where January 1 of year 1 is 1. </p> <pre><code>date1 = datetime.date(1, 1, 1)\ndate2=date1.toordinal()\nprint(date2)\n</code></pre> <p>and back:</p> <pre><code>print(datetime.date.fromordinal(date2))\n</code></pre>"},{"location":"book/ch3_data_analysis/ch3_time/#panda-date","title":"Panda date","text":"<pre><code>import numpy as np\nimport pandas as pd \nX1=[\"2023-1-1\",\"2023-2-1\",\"2023-3-1\",\"2023-4-1\"]\nX2=[10,11,12,13]\nraw_data = {'X1': X1,'X2': X2}\ndf=pd.DataFrame(raw_data)\ndf\n</code></pre> <pre><code>df.dtypes\ndf.X1 = pd.to_datetime(df.X1)\ndf\ndf.dtypes\n</code></pre> <pre><code>pd.to_datetime(df['X1']).dt.day\npd.to_datetime(df['X1']).dt.month\npd.to_datetime(df['X1']).dt.year\n</code></pre> <pre><code>df = df.set_index('X1')\ndf\ndf.index.is_unique\ndf.sort_index(ascending = True).head()\n</code></pre> <p>To work on read data let consider Dow Jones Index:  </p> <pre><code>dow_jones = pd.read_csv('data/dow_jones_index/dow_jones_index.data')\ndow_jones.head(20)\ndow_jones.info()\n</code></pre> <p>Select 'stock','date','open','high','low' <pre><code>dow_jones=dow_jones.loc[:,['date','stock','open','high','low']] \n</code></pre></p> <p>Assign week number as index  <pre><code>import datetime\ndef to_week(x):\n  return datetime.datetime.strptime(x, '%m/%d/%Y').strftime(\"%V\")\n</code></pre></p> <p>Apply the function to_week on the column data  <pre><code>dow_jones['week']=dow_jones['date'].apply(to_week)\ndow_jones = dow_jones.set_index('week')\ndow_jones=dow_jones.drop(['date'], axis=1)\n</code></pre></p> <p>Drop doller sign from columns and change them to numeric <pre><code>for i in dow_jones.columns[1:]:\n    dow_jones[i]=dow_jones[i].str.strip('$').astype(float)\n</code></pre></p> <p>Compute the mean for each week:</p> <pre><code>dow_jones.iloc[:,1:4].groupby(dow_jones.index).mean()\n</code></pre>"},{"location":"book/ch3_data_analysis/ch3_time/#time-module","title":"time module","text":"<p>The <code>time</code> module provide various time-related function for time access, to get the current time: </p> <pre><code>import time \nprint(time.asctime())\ntime.localtime()\nprint(time.strftime('%a %d.%m.'))\n</code></pre> <p>Pause the execution of a program for two seconds: <pre><code>time.sleep(2) \n</code></pre></p> <p>You can create a simple code to check running time. </p> <pre><code>import time\nstart_time = time.time()\nsome code \nprint(\"--- %s seconds ---\" % (time.time() - start_time))\n</code></pre> <p>timeit is a module to check running of small code. </p>"},{"location":"book/ch4_visualization/ch4_boken/","title":"Boken","text":""},{"location":"book/ch4_visualization/ch4_boken/#bokeh-server","title":"Bokeh server","text":"<p>Bokeh server is a advanced graphical tools for building the web visualization for the Python, R, etc and has capabilities for serving live-streaming, interactive visualizations that update with real-time data.</p> <pre><code>from bokeh.server.server import Server\nfrom bokeh.application import Application\nfrom bokeh.application.handlers.function import FunctionHandler\nfrom bokeh.plotting import figure, ColumnDataSource\n\ndef make_document(doc):\n    fig = figure(title='Line plot!', sizing_mode='scale_width')\n    fig.line(x=[1, 2, 3], y=[1, 4, 9])\n    doc.title = \"Hello, world!\"\n    doc.add_root(fig)\n\napps = {'/': Application(FunctionHandler(make_document))}\n\nserver = Server(apps, port=8003)\nserver.start()\nIOLoop.current().start()\n</code></pre>"},{"location":"book/ch4_visualization/ch4_boken/#live","title":"Live","text":"<pre><code>import random\n\ndef make_document(doc):\n    source = ColumnDataSource({'x': [], 'y': [], 'color': []})\n    def update():\n        new = {'x': [random.random()],\n               'y': [random.random()],\n               'color': [random.choice(['red', 'blue', 'green'])]}\n        source.stream(new)\n    doc.add_periodic_callback(update, 100)\n    fig = figure(title='Streaming Circle Plot!', sizing_mode='scale_width',\n                 x_range=[0, 1], y_range=[0, 1])\n    fig.circle(source=source, x='x', y='y', color='color', size=10)\n    doc.title = \"Now with live updating!\"\n    doc.add_root(fig)\n\napps = {'/': Application(FunctionHandler(make_document))}\n\nserver = Server(apps, port=5001)\nserver.start()\nIOLoop.current().start()\n</code></pre>"},{"location":"book/ch4_visualization/ch4_matplotlib/","title":"Matplotlib","text":"<p>Python offers sophisticated plotting capabilities. Plotting can be approached in two ways: - Non-Pythonic Approach: This approach relies on external libraries like <code>matplotlib</code>, which provides user-friendly tools for interactive plotting. A common shorthand for importing this module is <code>import matplotlib.pyplot as plt</code>. - Pythonic Approach: In this method, an empty object is created, and plots are constructed programmatically, then assigned to the empty object using code.</p> <p>In the below, you can see how to run code </p>"},{"location":"book/ch4_visualization/ch4_matplotlib/#scatter-plot","title":"Scatter plot","text":"<p>The most commonly used plot is the scatter plot, see the following scripts that generate random number and plot</p> <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nn = 100\nx = 2 * np.random.rand(n)\ny=2*x+np.random.rand(n)\nplt.scatter(x, y)\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.title('Scatter Plot')\nplt.show(block=False)\n</code></pre> <p></p> <p>Indeed, you can customize the appearance of a scatter plot using various arguments: - Size of point (<code>s</code>): you can adjust the size of the points, for example,  <code>s=10</code> make the point smaller, - colour (<code>c</code>): You can specify the color of pointy. For example, <code>c=red</code> will make the points red.  - <code>marker</code>: you can choose different marker styles for points. For example <code>marker=s</code> w ill use squares for presenting points. </p> <pre><code>plt.scatter(x, y, s=20 /(.2+x) , c='green', marker=\"s\")\nplt.show(block=False)\n</code></pre> <p></p> <p>In this example, we've customized the scatter plot to use red square for data points which obviously smaller x get bigger square. You can further explore the links provided for more marker styles and line properties in matplotlib. The following figure displays a more sophisticated plot. </p> <pre><code>xy=x**2+y**2\nselect=xy&lt;1\nplt.scatter(x, y, alpha=0.3)\nplt.scatter(x[select], y[select],facecolor='none',edgecolors='red')\nplt.show(block=False)\n</code></pre> <p></p> <p>Fit a linear model to a sample data. <pre><code>plt.scatter(x, y, alpha=0.5, color='orchid') \nplt.suptitle('Scatter Plot') \nplt.tight_layout(pad=2);\nplt.grid(True)\nfit = np.polyfit(x, y, deg=1) \nplt.plot(x, fit[0]*x + fit[1], '-',color='red', linewidth=2)\nplt.show(block=False)\n</code></pre></p> <p></p> <p>If you want to save the figure to a file, put the script between</p> <pre><code>plt.savefig('name.png')\n</code></pre>"},{"location":"book/ch4_visualization/ch4_matplotlib/#line","title":"line","text":"<p>Using <code>plt.plot</code> can plot the line, to explain let consider timesries data: </p> <pre><code>import pandas as pd\nx=pd.period_range('2019-11-06', periods=12*10,freq='M').to_timestamp()\ny = np.random.randn(len(x)).cumsum()\ny=abs(min(y))+y\nplt.plot(x, y, label='ED')\nplt.title('Example Data') \nplt.xlabel('Date') \nplt.ylabel('Y')\nplt.grid(True)\nplt.figtext(1,0, 'note',ha='right', va='bottom')\nplt.legend(loc='best', framealpha=0.5,prop={'size':'small'})\nplt.tight_layout(pad=1)\nplt.gcf().set_size_inches(10, 5)\nplt.show(block=False)\nplt.close()\n</code></pre> <p></p> <p>To excercise, let write a function to plot the following function</p> \\[ f(x) = \\begin{cases}     sin(x),       &amp; x\\leq \\pi/2,\\\\     cos(x)  &amp; x&gt; \\pi/2.\\\\   \\end{cases} \\] <pre><code>x=np.arange(0,np.pi,np.pi/100)\ny=np.where(x&lt;np.pi/2,np.cos(x),np.sin(x))\nplt.plot(x,y)\n</code></pre> <p></p> <p>The other approach is to use two function instead one, it can be done using the following script,</p> <pre><code>x=np.arange(0,np.pi,np.pi/100)\ny=np.where(x&lt;np.pi/2,np.cos(x),np.sin(x))\nx0=x[x&lt;np.pi/2]\nplt.plot(x0,np.cos(x0), linestyle='--',label='cos(x)')\nplt.axis([0,np.pi,0,1])\nx1=x[(x&gt;=np.pi/2)]\nplt.plot(x1,np.sin(x1), linestyle='--',label='sin(x)')\nplt.legend()\n# it can be done using\n# plt.plot(x0,np.cos(x0), '--',x1,np.sin(x1), '--')\n</code></pre> <p></p> <p>The argument <code>plt.axis()</code> defines axes limits, it can also be done using  <code>plt.xlim(,)</code>, <code>plt.ylim(,)</code>.  The style of line is define in <code>'--'</code>, other styles are</p> Type Description '-' or 'solid' solid line '--' or 'dashed' dashed line '-.' or 'dashdot' dash-dotted line ':' or 'dotted' dotted line 'None' or ' ' draw nothing <p>There are more options for axis, for instance <code>plt.axis('equal')</code>  and  <code>plt.axis('tight')</code>. The labels and title  can be added to plot using <code>plt.axes()</code>, </p> <pre><code>plt.axes(xlim=(0, 10), ylim=(-2, 2),xlabel='x', ylabel='sin(x)', title='A Simple Plot')\nplt.plot(x, np.sin(x), '-')\nplt.show(block=False)\nplt.close()\n</code></pre> <p></p> <p>The following plot lines with different markers</p> <pre><code>n = 5\nlinestyles = ['-', '--', '-.', ':']\nmarkers = list('ov^&lt;&gt;')\nx = np.linspace(0, 100, 10)\nfor i in range(n): \n  y = x + x/5*i + i\n  st = linestyles[i % len(linestyles)]\n  ma = markers[i % len(markers)] \n  plt.plot(x, y,label='Line '+str(i+1)+' '+st+ma, marker=ma,linestyle=st)\nplt.grid(True)\nplt.axis('tight')\nplt.legend(loc='best', prop={'size':'small'}) \nplt.show(block=False)\nplt.close()\n</code></pre> <p></p>"},{"location":"book/ch4_visualization/ch4_matplotlib/#pythonic-line","title":"Pythonic line","text":"<p>The following codes shows how pythonic approach can be applied to generate several plots; first generate an empty figure from the global Figure factory, then generate your plot and assign to figure. </p> <pre><code>fig = plt.figure()\nfor i in range(1,10):\n  x=pd.period_range('2019-11-06', periods=12*10,freq='M').to_timestamp()\n  y = np.random.randn(len(x)).cumsum()\n  y=abs(min(y))+y\n  plt.plot(x, y, label='ED%s'%i)\n  plt.title('Example Data') \n  plt.xlabel('Date') \n  plt.ylabel('Y')\n  plt.grid(True)\n  plt.legend(loc='best', framealpha=0.5,prop={'size':'small'})\n  fig = plt.figure(i) # get the figure\nplt.show()\n</code></pre> <p>You can close figures according the number <code>plt.close(fig.number)</code>,  all figures <code>plt.close(all)</code>,  the current one <code>plt.close()</code>. Note, plt.cla clears the current axes, plt.clf() clears the current figure, and the plt.close() closes the entire window.</p>"},{"location":"book/ch4_visualization/ch4_matplotlib/#subplot","title":"subplot","text":"<p>Figures can be plotted in one figure using <code>.subplot(#row,#col,position)</code>, </p> <pre><code>x = np.linspace(0, 16, 800)\nplt.subplot(2, 2, 1)\nplt.plot(x, np.sin(x))\nplt.title(\"Fig1\")\nplt.xlim(0,1.5*np.pi)\nplt.xlabel(\"X-axis\")\nplt.ylabel(\"sin(x)\")\nplt.subplot(2, 2, 2)\nplt.plot(x, np.cos(x))\nplt.subplot(2, 2, 3)\nplt.plot(x, np.sin(x)*np.cos(x))\nplt.subplot(2, 2, 4)\nplt.plot(x, np.sin(x)+np.cos(x))\nplt.show(block=False)\n</code></pre> <p></p> <p>You can not use <code>plt.axes()</code> for subplot. </p>"},{"location":"book/ch4_visualization/ch4_overview/","title":"Overview","text":"<p>Python offers advanced plotting capabilities. In this chapter, we discuss various modules used for generating plots.</p> <ul> <li>Matplotlib</li> <li>Seaborn</li> <li>Plotnine</li> </ul>"},{"location":"book/ch4_visualization/ch4_plotnine/","title":"plotnine  -nneed to work","text":"<p><code>ggplot2</code> is a very useful package in R for creating advanced plots. In Python, the <code>plotnine</code> library is used to create <code>ggplot2</code>-like plots. You can import the module using <code>import plotnine as p9</code>. Generating plots in <code>ggplot2</code> (plotnine) follows a structured series of steps, which can be accomplished via:</p> <ul> <li>initialize it</li> </ul> <pre><code>import plotnine as p9\nCHD_plot=p9.ggplot(data=CHD)\n</code></pre> <p></p> <ul> <li>Define aesthetics using <code>aes</code> and specify your arguments. The most important aesthetics include: <code>x</code>, <code>y</code>, <code>alpha</code>, <code>color</code>, <code>colour</code>, <code>fill</code>, <code>linetype</code>, <code>shape</code>, <code>size</code>, and <code>stroke</code>. To create variations of the plot with different parameters, you can assign it to a variable.</li> </ul> <pre><code>CHD_plot=CHD_plot + p9.aes(x='median_income', y='median_house_value')\n# or CHD_plot=p9.ggplot(data=CHD,mapping=p9.aes(x='median_income', y='median_house_value'))\nCHD_plot.show()\n</code></pre> <p></p> <ul> <li>Specify what you want to display and use the <code>+</code> operator to add layers and customize your plot.</li> </ul> <pre><code>CHD_plot=CHD_plot+p9.geom_point()\nCHD_plot.show()\n</code></pre> <p></p> <p>You can easily add scale and define label: </p> <pre><code>CHD_plot=CHD_plot+ p9.geom_point(alpha=0.15)+ p9.xlab(\"median_income\") +\n p9.ylab(\"median_house_value\") + p9.scale_x_log10() + \n p9.theme_bw()+ p9.theme(text=p9.element_text(size=10))\n</code></pre> <p></p> <ul> <li>After creating your plot, you can save it to a file in your favourite format</li> </ul> <pre><code>CHD_plot = CHD_plot + p9.geom_point()\nCHD_plot.save(\"CHD_plot.png\", dpi=300)\n</code></pre>"},{"location":"book/ch4_visualization/ch4_plotnine/#bar-chart","title":"bar chart","text":"<p>To generate a bar chart, you can use <code>geom_bar()</code></p> <pre><code>CHD_bar=(p9.ggplot(data=CHD,mapping=p9.aes(x='famlev'))+ p9.geom_bar())\n</code></pre> <p></p>"},{"location":"book/ch4_visualization/ch4_plotnine/#plotting-distributions","title":"Plotting distributions","text":"<ul> <li>A boxplot can be created using <code>geom_boxplot()</code>:</li> </ul> <pre><code>CHD_dist=(p9.ggplot(data=CHD,\n           mapping=p9.aes(x='famlev',\n                          y='median_income'))\n    + p9.geom_boxplot()\n    + p9.scale_y_log10()\n )\n</code></pre> <ul> <li>To add points behind the boxplot, you can use geom_jitter() to plot the points with some random noise to avoid overlapping points. This will create a visual representation of the data points behind the boxplot. Here's an example:</li> </ul> <pre><code>CHD_dist=(p9.ggplot(data=CHD,\n           mapping=p9.aes(x='famlev',\n                          y='median_income'))\n    + p9.geom_boxplot()\n    + p9.geom_jitter(alpha=0.1, color=\"green\")\n    + p9.scale_y_log10()\n )\n</code></pre>"},{"location":"book/ch4_visualization/ch4_seaborn/","title":"Seaborn","text":"<p>Seaborn provides advanced graphical capabilities for creating sophisticated statistical visualizations with ease. It simplifies the process of generating complex plots from pandas DataFrames using simple commands. Let consider the <code>CHD_test.csv</code>, </p> <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd \nCHD=pd.read_csv('./data/CHD_test.csv',index_col=False)\nCHD.head()\n</code></pre> <p></p>"},{"location":"book/ch4_visualization/ch4_seaborn/#histogram","title":"Histogram","text":"<p>Standardize the 'median_income' and  'median_house_value' and plot the </p> <pre><code>import seaborn as sns\nsns.set(color_codes=True)\n\nCHD['median_income'] = (CHD['median_income'] -CHD['median_income'].mean()) / CHD['median_income'].std()\nCHD['median_house_value'] = (CHD['median_house_value'] -CHD['median_house_value'].mean()) / CHD['median_house_value'].std()\nfor col in ['median_income','median_house_value']:\n    plt.hist(CHD[col], density=True)\nplt.show(block=False)\n</code></pre> <p></p> <p>We can get a smooth estimate of the distribution using a kernel density estimation (KDE): <pre><code>import warnings\nwarnings.filterwarnings(\"ignore\")\nsns.kdeplot(data=CHD, x='median_income', y='median_house_value')\nplt.show(block=False)\n</code></pre></p> <p></p> <p>You can create a hexagonally-based histogram using <code>jointplot</code>: <pre><code>sns.jointplot(data=CHD, x='median_income', y='median_house_value',kind=\"hex\")\n</code></pre></p> <p></p> <pre><code>sns.jointplot(data=CHD, x='median_income', y='median_house_value',kind=\"kde\", hue='famlev')\n</code></pre> <p></p> <p>The following illustrates how to draw a box plot for different family levels. <pre><code>g=sns.catplot(data=CHD, x='median_income', y='famlev', kind=\"box\")\ng.set_axis_labels(\"Income\", \"Family level\");\n</code></pre></p> <p></p>"},{"location":"book/ch4_visualization/ch4_seaborn/#pairplots","title":"Pairplots","text":"<p>We can generalize joint plots for multidimensional data, which is very useful for exploring correlations between multiple dimensions of data. <pre><code>sns.pairplot(CHD, hue='famlev');\n</code></pre></p> <p></p>"},{"location":"book/ch4_visualization/ch4_seaborn/#joyplot","title":"Joyplot","text":"<p>Joyplot is a useful plot to compare distributions, the following show how to plot </p> <pre><code>sns.set_theme(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n</code></pre> <p>Create the data <pre><code>rs = np.random.RandomState(1979)\nx = rs.randn(500)\ng = np.tile(list(\"ABCDEFGHIJ\"), 50)\ndf = pd.DataFrame(dict(x=x, g=g))\nm = df.g.map(ord)\ndf[\"x\"] += m\n</code></pre></p> <p>Initialize the FacetGrid object <pre><code>pal = sns.cubehelix_palette(10, rot=-.25, light=.7)\ng = sns.FacetGrid(df, row=\"g\", hue=\"g\", aspect=15, height=.5, palette=pal)\n</code></pre></p> <p>Draw the densities in a few steps <pre><code>g.map(sns.kdeplot, \"x\",bw_adjust=.5, clip_on=False,fill=True, alpha=1, linewidth=1.5)\ng.map(sns.kdeplot, \"x\", clip_on=False, color=\"w\", lw=2, bw_adjust=.5)\n</code></pre></p> <p>Define and use a simple function to label the plot in axes coordinates <pre><code>def label(x, color, label):\n    ax = plt.gca()\n    ax.text(0, .2, label, fontweight=\"bold\", color=color,\n            ha=\"left\", va=\"center\", transform=ax.transAxes)\ng.map(label, \"x\")\n</code></pre></p> <p>Set the subplots to overlap <pre><code>g.fig.subplots_adjust(hspace=-.25)\n</code></pre></p> <p>Remove axes details that don't play well with overlap <pre><code>g.set_titles(\"\")\ng.set(yticks=[], ylabel=\"\")\ng.despine(bottom=True, left=True)\nplt.show(block=False)\n</code></pre></p> <p></p>"},{"location":"book/ch4_visualization/ch4_seaborn/#displot","title":"Displot","text":"<p>This function can be used for visualizing the univariate or bivariate distribution of data,</p> <pre><code>import seaborn as sns\nimport matplotlib.pyplot as plt\ndata1 = np.random.normal(size = 100)\ndata2 = np.random.normal(size = 100)\n\nvar={\"A\": data1, \"B\": data2}\ndf= pd.DataFrame(data=var,index=(range(100)))\nsns.displot(data=df,kde=True)\nplt.show(block=False)\n</code></pre> <p></p>"},{"location":"book/ch5_file/ch5_challenges/","title":"Challenge","text":""},{"location":"book/ch5_file/ch5_challenges/#challenge-1","title":"Challenge 1","text":"<p>Open a file and splitting by newlines:</p> Respond: <pre><code>with open(\"out.txt\") as f:\n    data = f.read().splitlines()\n    print (\"h\\n\")\n</code></pre>"},{"location":"book/ch5_file/ch5_challenges/#challenge-2","title":"Challenge 2","text":"<p>Open a file a print out all lines starting with a pattern:</p> Respond: <pre><code>with open(\"test.fasta\") as f:\n   for line in f:\n       if line.startswith(\"&gt;\"):\n           print line,\n</code></pre>"},{"location":"book/ch5_file/ch5_csv/","title":"CSV","text":"<p>Working with CSV in python is very simple </p>"},{"location":"book/ch5_file/ch5_csv/#read","title":"Read","text":"<p>Read the DataFrame from a CSV file, specifying that the first row contains the header or None <pre><code>df=pd.read_csv('file.csv',heder=1)\ndf=pd.read_csv('file.csv',header=None)\n</code></pre></p> <p>Specifying that a column is dates <pre><code>df = pd.read_csv('file.csv', parse_dates=['dates'])\n</code></pre></p> <p>Select only specific columns. <pre><code>df = pd.read_csv('file.csv', usecols=['foo', 'bar'])\n</code></pre></p> <p>If the first column is not selected, try setting index_col=False <pre><code>DF=pd.read_csv('file.csv', sep='\\t',index_col=False)\n</code></pre></p> <p>Adding column names, and therefore an index <pre><code>  df=pd.read_csv('file.csv',names=['col1','col2','col3'])\n</code></pre></p> <p>To skip the  comments: <pre><code>df = pd.read_csv(\"DF.txt\",comment='#')\n</code></pre></p>"},{"location":"book/ch5_file/ch5_csv/#export","title":"export","text":"<pre><code>df.to_csv('births1880.csv',index=False,header=False)\n</code></pre>"},{"location":"book/ch5_file/ch5_csv/#tab-separated-file","title":"tab-separated file","text":"<p>To work with a tab-separated values file, we use the csv module. The following code shows how to create a file. <pre><code>import csv\nwith open('my_data.csv', 'w') as csvfile:\n    fieldnames = ['SampleID','Age','Treatment', 'Weight'] # Create a list with the column\n    writer = csv.DictWriter(csvfile, fieldnames=fieldnames, delimiter='\\t')    \n    writer.writeheader()\n    writer.writerow({\"SampleID\":\"mouse1\", \"Age\":4, \"Treatment\":\"Control\", \"Weight\":3.2})\n    writer.writerow({\"SampleID\":\"mouse2\", \"Age\":5, \"Treatment\":\"Control\", \"Weight\":3.6 })\n    writer.writerow({\"SampleID\":\"mouse3\", \"Age\":4, \"Treatment\":\"Control\", \"Weight\":3.8 })\n    writer.writerow({\"SampleID\":\"mouse4\", \"Age\":4, \"Treatment\":\"ad libitum\", \"Weight\":3.6 })\n    writer.writerow({\"SampleID\":\"mouse5\", \"Age\":4, \"Treatment\":\"ad libitum\", \"Weight\":3.7 })\n    writer.writerow({\"SampleID\":\"mouse6\", \"Age\":4, \"Treatment\":\"ad libitum\", \"Weight\":3.5 })\n</code></pre></p> <p>You can use <code>.read_csv()</code> from the Panda module..  <pre><code>df=pd.read_csv('my_data.csv', sep='\\t')\n</code></pre></p> <p>The following code shows how to handle read the file using <code>r</code> mode:</p> <pre><code>with open('my_data.csv', 'r') as csvfile:\n    reader = csv.DictReader(csvfile, delimiter='\\t')\n    for row in reader:\n        print(f\"SampleID:{row['SampleID']}, Age:{row['Age']}, Treatment:{row['Treatment']}, Weight:{row['Weight']}\")\n</code></pre>"},{"location":"book/ch5_file/ch5_csv/#blocksize","title":"blocksize","text":"<p>Dask is a library designed for parallel computing, you can manage large datasets more efficiently using block sizes. It allows you to work with large data by breaking it up into smaller, called partitions. Each partition can be processed in parallel.</p> <pre><code>import dask.dataframe as dd\n\ndf = dd.read_csv('largefile.txt', names=['chr','pos','cov'], sep='\\t', blocksize=34000000) # blocksize controls the size of each partition.\n\nprint(\"Descriptors: {0}\".format(df['cov'].describe().compute()))\n</code></pre>"},{"location":"book/ch5_file/ch5_overview/","title":"Overview","text":"<p>Here, we discuss how to work with files in Python.</p> <ul> <li>Text files Presents functions for working with general text files in Python.</li> <li>Storing objects: Reviews pickle, which is used to store Python objects. </li> <li>CSV :  Discusses how to handle CSV files in Python.</li> <li>XLSX: Explains how to read Excel (.xlsx) files in Python.</li> <li>Challenges</li> </ul>"},{"location":"book/ch5_file/ch5_pickle/","title":"Storing objects","text":"<p>One of the best ways to store objects in Python is by using the pickle module. Pickle is primarily used for serializing and deserializing Python object structures. In simpler terms, it converts a Python object into a byte stream, embedding all the information needed to reconstruct/unpack the object later in our code. This enables the object to be stored in a file, easily transported, and restored later. It can be loaded using <code>import pickle</code>.</p>"},{"location":"book/ch5_file/ch5_pickle/#pickle-dump","title":"Pickle dump","text":"<p><code>pickle.dump()</code> function allow user to stor the the objects. Let create different objects, and store them. </p> <pre><code>weights=[20,15,19,21,16]\ncolors=('red','blue','green','black','white')\ncolors_set={'red','blue','green','black','white'}\nprices = {'BMW': 50,'BENZ': 55,'Ford': 25,'Chevy': 30, 'GM': 28}\n\nimport pickle\n\nfile = open('backup.pkl','wb')\npickle.dump(weights, file)\npickle.dump(colors, file)\npickle.dump(colors_set, file)\npickle.dump(prices, file)\nfile.close()\n</code></pre>"},{"location":"book/ch5_file/ch5_pickle/#pickle-load","title":"Pickle load","text":"<p><code>pickle.load()</code> is used to retrieve pickled data.  <pre><code>file = open('backup.pkl','wb')\nweights=pickle.load(file)\ncolors=pickle.load(file)\ncolors_set=pickle.load(file)\nprices=pickle.load(file)\nfile.close()\n</code></pre></p>"},{"location":"book/ch5_file/ch5_pickle/#dill","title":"dill","text":"<p>The dill library is a drop-in alternative to pickle that can robustly handle function serialization. </p>"},{"location":"book/ch5_file/ch5_text/","title":"Text files","text":"<p>Python has strong function to work with file and folders.  </p>"},{"location":"book/ch5_file/ch5_text/#manipulating","title":"Manipulating","text":"<p>To access a text file in Python, you need to: 1) open the file, 2) read\\write it, and 3) close the file.</p>"},{"location":"book/ch5_file/ch5_text/#write","title":"Write","text":"<p>The following code creates a new file and writes text to it; if the file already exists, it will be overwritten <pre><code>test = open(\"example.txt\", \"w\")\nfor i in range(0,10):\n    test.write(f\"add {i}\\n\")\ntest.close()  \n</code></pre> As you can see here we use 'w' mode, which means Write-only. Overwrites file if it exists; creates new if it doesn\u2019t. </p> <p>Lines can be added easily to file. <pre><code>lines = ['first line\\n', 'second line\\n']\nopen('my_file.txt','w').writelines(lines)\n</code></pre></p> <p>Table can be added to file as below:  <pre><code>names = ['Emily', 'Bob', 'Charlie']\nages = [23, 45, 67]\n\nf = open('my_file.txt', 'w')\nfor name, age in zip(names, ages):\n    line = f'{name};{age}\\n'\n    f.write(line)\nf.close()\n</code></pre></p>"},{"location":"book/ch5_file/ch5_text/#append","title":"Append","text":"<p>To append new line use <code>a</code> mode, you can use  <code>.write()</code> or <code>writelines()</code>:  <pre><code>test = open(\"example.txt\", \"a\")  # append mode\ntest.write(\"Today \\n\")\ntest.close()\n</code></pre></p> <pre><code>test = open(\"example.txt\", \"a\")\nL = [\"This is just example Delhi \\n\", \"in Python \\n\"]\ntest.writelines(L) \ntest.close()\n</code></pre>"},{"location":"book/ch5_file/ch5_text/#read","title":"Read","text":"<p>The entire file can be viewed using the following code; as you can see, we use the 'r' mode. <pre><code>test = open(\"example.txt\", \"r\")\nprint(test.read())\ntest.close()\n</code></pre></p> <p>The entire file can be read in a file  <pre><code>f = open('example.txt')\ntext = f.read()\nf.close()\n</code></pre></p> <p>You can access each line of the file element by element as follows:</p> <p><pre><code>with open(\"example.txt\", \"r\") as handle:\n    for line in handle:\n        print(line.strip())\n\nwith open(\"example.txt\", \"r\") as handle:\n    print(handle.read())\n</code></pre> In Python, the next() function is used to retrieve the next item from an iterator.</p> <pre><code>handle = open(\"example.txt\", \"r\")\nline = next(handle)\nprint(line)    \nline = next(handle)\nprint(line)    \n</code></pre> <p>If the columns are separated using ;, the file can be separated as  <pre><code>for line in open('my_file.txt'):\n    columns = line.strip().split(';')\n    first = columns[0]\n    last = columns[1]\n    age = int(columns[2])\n</code></pre></p> <p>If the file in not in the directory folder, you can recall it  <pre><code>import os\np = os.path.join('/home/ubuntu', 'data.csv')\n\nwith open(p) as fp:\n    data = fp.read()\n</code></pre></p>"},{"location":"book/ch5_file/ch5_text/#online-file","title":"Online file","text":"<p>A simple way to access to a file online is to use <code>urllib</code> module, </p> <pre><code>import urllib.request\nurl = \"https://raw.githubusercontent.com/ucdavis-bioinformatics-training/2020-Bioinformatics_Prerequisites_Workshop/master/Intro_to_Python/example_data.fastq.gz\"\nurllib.request.urlretrieve(url, 'example_data.fastq.gz')\n</code></pre> <pre><code>import os\n# to check whether file is in the working path\nos.path.isfile(\"example_data.fastq.gz\")\n# to check the size of file\nos.path.getsize(\"example_data.fastq.gz\")\n</code></pre>"},{"location":"book/ch5_file/ch5_text/#zip-file","title":"zip file","text":"<p>To handle the zip file, use the gzip module, as shown below. <pre><code>import gzip\nhandle = gzip.open(\"example_data.fastq.gz\", 'rt')\nl = next(handle)\nprint(l)\nhandle.close()\n</code></pre></p>"},{"location":"book/ch5_file/ch5_text/#table","title":"table","text":"<p>If the data is saved as table, use <code>pd.read_table</code>,  <pre><code>users = pd.read_table('https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user', sep='|', index_col='user_id')\nusers.head()\n</code></pre></p>"},{"location":"book/ch5_file/ch5_xlsx/","title":"XLSX","text":""},{"location":"book/ch5_file/ch5_xlsx/#import-using-panda","title":"Import using Panda","text":"<p>You can the panda library function <code>read_excel()</code> to import Excel files into a DataFrame</p> <pre><code>import pandas as pd\nDF = pd.read_excel('path/file.xlsx', 1) # 1 is the ix of the worksheet\n</code></pre>"},{"location":"book/ch5_file/ch5_xlsx/#import-using-openpyxl","title":"Import Using openpyxl","text":"<p>To read Excel files (.xls format) in Python, you can use the openpyxl package: </p> <pre><code>import openpyxl\nimport pandas as pd\ndataframe = openpyxl.load_workbook(\"./data/chapter5/titianic.xlsx\")\nsheet1 = dataframe['Sheet1']\nrows_sheet1 = []\nfor row_sheet1 in sheet1.iter_rows(values_only=True):\n    rows_sheet1.append(row_sheet1)\ndf_sheet1 = pd.DataFrame(rows_sheet1[1:], columns=rows_sheet1[0])\n\nsheet2 = dataframe['Sheet2']\nrows_sheet2 = []\nfor row_sheet2 in sheet2.iter_rows(values_only=True):\n    rows_sheet2.append(row_sheet2)\ndf_sheet2 = pd.DataFrame(rows_sheet2[1:], columns=rows_sheet2[0])\n</code></pre>"},{"location":"book/ch5_file/ch5_xlsx/#combining-files","title":"Combining files","text":"<p>To combine .xlsx files, use the following code: <pre><code>marketing_analyst_names = pd.read_excel(\"MarketingAnalystNames.xlsx\")\nsales_rep_names = pd.read_excel(\"SalesRepNames.xlsx\")\nsenior_leadership_names = pd.read_excel(\"SeniorLeadershipNames.xlsx\")\nall_df_list = [marketing_analyst_names, sales_rep_names, senior_leadership_names]\nappended_df = pd.concat(all_df_list)\n</code></pre> Merge all the dataframes in all_df_list, Pandas will automatically append based on similar column names.  Write the appended dataframe to an excel file</p> <pre><code>appended_df.to_excel(\"AllCompanyNames.xlsx\", index=False)\n</code></pre> <p>Add <code>index=False</code> parameter to not include row numbers</p>"},{"location":"book/ch6_os/ch6_challenges/","title":"Challenge","text":"<p>Under construction</p>"},{"location":"book/ch6_os/ch6_os/","title":"OS","text":"<p>The module <code>os</code>  (<code>import os</code>) provides many useful functions to work with file and folders. The following provides the current working director</p> <pre><code>import os\nprint(os.getcwd())\n</code></pre> <p>To change the directory use <code>os.chdir</code>: </p> <pre><code>os.chdir('~/folder1')\nprint(os.getcwd())\n</code></pre> <p>To join paths, run the following.  <pre><code>base_path = '/home/ubuntu/'\nfilename = 'data.csv'\nos.path.join(base_path, filename)\n</code></pre></p> <p>You can get the full (absolute) path of a file or folder: <pre><code>os.path.abspath(fullpath)\n</code></pre></p> <p>A list of useful function are presented in the below:  </p> <p>|--|--| |function | description | |os.chdir():| Change the directory | |os.getcwd(): | Get the current directery | |os.listdir(): |Get a list of files and folders, os.listdir('.')| |os.mkdir('test'): | make a new directory| |os.rename('test','new_one'): |rename a directory  or file | |os.remove('old.txt'):| remove file or directory | |os.rmdir('old'): | if the directory is empty | |os.path.exists(path):| checks whether the given file or directory exists | |os.path.isdir(path): | checks whether the given path is a directory | |os.path.isfile(path):| checks whether the given path is a file | |os.path.getsize(path):|    returns file size | |os.path.dirname(path):|    returns path of folder containing file | |os.path.expanduser('~'):|  returns path of the home directory | |os.path.splitext(path) | return file extension| |os.chmod(file,permission)| Change permission of a file| |os.path.basename(path) |  Get file name without directory| </p> <p>The following code extract the extention of file Get file name without directory <pre><code>fullpath = \"/python/data.csv\"\n_, ext = os.path.splitext(fullpath)\next\n</code></pre></p> <p>Find all files in a directory tree that match a specified pattern</p> <pre><code>import os, fnmatch\npattern = '*.py'\n\nfor path, subdirs, files in os.walk('.'):\n        for name in files:\n            if fnmatch.fnmatch(name, pattern):\n                print(os.path.join(path, name))\n</code></pre> <p>You can access environment variables using <code>os.environ</code>, which is useful for retrieving values such as user names and API keys.</p> <pre><code>db_user = os.environ.get('DB_USER')\ndb_password = os.environ.get('DB_PASS')\nprint(db_user)\nprint(db_password)\n</code></pre>"},{"location":"book/ch6_os/ch6_os/#system","title":"system","text":"<p>You can run bash command using <code>system</code> function: the following copy README.md to copy.md.  <pre><code> os.system('cp README.md copy.md')\n</code></pre></p> <pre><code>os.system(\"ls -l &gt; result.txt\")\n</code></pre>"},{"location":"book/ch6_os/ch6_os/#shutil","title":"shutil","text":"<p><code>shutil</code> provides additional operations for working with files and directories. <pre><code>from shutil import make_archive\nmake_archive(\"data.csv\", \"gztar\", \"/My Drive/python\")\n</code></pre></p>"},{"location":"book/ch6_os/ch6_os/#pathlib","title":"pathlib","text":"<p><code>pathlib</code> module do most of 'os'. </p> <pre><code>from pathlib import Path\npath = Path(\"/usr/bin\")\nlist(path.glob(\"*\"))[0:2]\nlist(path.glob(\"*.csv\"))\nlist(path.glob(\"**/*.csv\"))\npath.cwd()\npath.exists()\npath.as_posix()\n</code></pre>"},{"location":"book/ch6_os/ch6_os/#zip","title":"zip","text":"<p>To create a zip file <pre><code>import zipfile\nz = zipfile.ZipFile('archive.zip', 'w')\nz.write('testfile1.txt')\nz.write('testfile2.txt')\nz.close()\n</code></pre></p> <p>To see the content  <pre><code>z = zipfile.ZipFile('archive.zip')\nprint(z.namelist())\n</code></pre></p> <p>To extract all files.  <pre><code>z.extractall('myfolder')\nz.close()\n</code></pre></p> <p>To extract a specific file.  <pre><code>z.extract(testfile1.txt','myfolder')\nz.close()\n</code></pre></p>"},{"location":"book/ch6_os/ch6_overview/","title":"Overview","text":"<p>Here, we discuss how to work with operation system.</p> <ul> <li>os: This section explain how to interact with the operating system in a platform-independent manner. </li> <li>sys: Explain how how use sys to access to variables and functions that interact directly with the Python interpreter.</li> <li>subproces: This section explain subprocess module that allows you to spawn new processes, connect to their input/output/error pipes, and obtain their return codes.</li> <li>Challenges: Under the construction. </li> </ul>"},{"location":"book/ch6_os/ch6_subprocess/","title":"Subprocess","text":"<p>The subprocess module allows you to spawn new processes, connect to their input/output/error pipes, and obtain their return codes.</p>"},{"location":"book/ch6_os/ch6_subprocess/#run","title":"run","text":"<p><code>subprocess.run()</code> executes a shell command or external program from within a Python script.</p> <pre><code>from subprocess import run,Popen,PIPE\n\nuser_input = \"-l\"\nout = run([\"ls\", user_input])\nif out.returncode == 0:\n    print(\"was a success\")\nelse:  \n    print(\"was unsuccesful\")\n</code></pre> <p>The command must be provided as a list; if it's given as a string, use <code>.split()</code> to convert it.</p> <pre><code>import shlex\nproc1=\"ls -l\"\nout = run(shlex.split(proc1))\n</code></pre> <p>If you have a sequence of commands in a Bash script file, you can run it as shown below:</p> <pre><code>methodproc1 = run([\"process_one.sh\"], stdout=PIPE)\nsubprocess.run([\"process_two.sh\"], stdin=proc1.stdout)\n</code></pre>"},{"location":"book/ch6_os/ch6_subprocess/#popen","title":"Popen","text":"<p>Use <code>subprocess.run()</code> to execute a command and wait for it to finish. If you want to perform other tasks while the process is running, use <code>subprocess.Popen</code> instead. To send input to and receive output from the process, call <code>Popen.communicate()</code>. In fact, <code>subprocess.run()</code> is a higher-level wrapper around <code>Popen</code> and <code>Popen.communicate()</code>.</p> <pre><code>with Popen([\"ls\", user_input], stdout=PIPE) as proc: \n    out = proc.stdout.readlines()\n    print(out)\n\n\nfor file in out:\n    print(file.strip())\n</code></pre> <p>We often use try/except blocks to handle errors, as shown below.</p> <pre><code>proc = Popen([\"ls\", user_input], stdout=PIPE)\ntry:    \n    out,err = proc.communicate(timeout=30)\nexcept TimeoutExpired:\n    proc.kill()  \n    out,err= proc.communicate()\n\nprint(out)\nprint(err)\n</code></pre> <p>Let's test <code>ls ~</code> using  Popen: </p> <pre><code>import os \nuser_input = \"~\"  # or any path from user input\nexpanded_path = os.path.expanduser(user_input)\nwith Popen([\"ls\", expanded_path], stdout=PIPE, stderr=PIPE) as proc: \n     print(proc.stderr)\n     print(proc.stdout)\n\nwith Popen([\"ls\", expanded_path], stdout=PIPE, stderr=PIPE) as proc: \n     print(proc.stderr.readlines())\n     print(proc.stdout.readlines())\n</code></pre> <p>In larger programs, this is especially useful for writing pipelines. The following function runs an R script without exiting the Python environment.</p> <p><pre><code>import subprocess\nsubprocess.check_call(['/usr/local/bin/Rscript', './Desktop/rtest.R'])\n</code></pre> To save output of R in Python, run  <pre><code>Out=subprocess.check_output(['/usr/local/bin/Rscript', './Desktop/rtest.R'])\n</code></pre></p> <p>To control error, use try\\except:  <pre><code>try:\n    Out=subprocess.check_output(['/usr/local/bin/Rscript', './Desktop/rtest.R'])\nexcept subprocess.CalledProcessError as e:\n    print(e.output)\n</code></pre></p>"},{"location":"book/ch6_os/ch6_sys/","title":"sys","text":"<p>The <code>sys</code> module provides an interface to the Python runtime environment, allowing access to interpreter variables such as the module search path (<code>sys.path</code>), standard input/output/error streams (<code>sys.stdin</code>, <code>sys.stdout</code>, <code>sys.stderr</code>), and functions for exiting the interpreter (<code>sys.exit()</code>), among others. <pre><code>import sys\n# Version of the Python interpreter:\nprint(sys.version)\n# Directories in which Python looks for modules:\nprint(sys.path)\nprint ('\\n'.join(sys.path))\n# Exit Python altogether:\nsys.exit()\n</code></pre></p> <p>The standard input, output, and error streams (sys.stdin, sys.stdout, and sys.stderr) are particularly useful for debugging and are discussed further in the logging section. To test stdout and stderr, run the following function, then open the files stdout.file and error.log, which capture the standard output and error streams, respectively. <pre><code>import sys\n\ndef test(outfile,errfile):\n        sys.stdout = open(outfile,\"w\")\n        sys.stderr = open(errfile,\"w\")\n        print(str(2) + \" \" + \"Hello\")\n        print(2 + \" \" + \"Hello\")\n        return()\n\ntest('stdout.file','error.log')\n</code></pre></p> <p>To test the function via the terminal, create a file named test.py and run it. <pre><code>$ python3 test.py\n$ cat stdout.file\n2 Hello\n$ cat error.log  \nTraceback (most recent call last):\n  File \"~/test.py\", line 10, in &lt;module&gt;\n    test('stdout.file','error.log')\n  File \"~/test.py\", line 7, in test\n    print(2 + \" \" + \"Hello\")\n          ~~^~~~~\nTypeError: unsupported operand type(s) for +: 'int' and 'str'\n</code></pre></p>"},{"location":"book/ch6_os/ch6_sys/#sysargv","title":"sys.argv","text":"<p>To pass the names of the output and error files to the script, create a file named test2.py and paste the following code into it.</p> <pre><code>import sys\n\ndef test(outfile,errfile):\n        sys.stdout = open(outfile,\"w\")\n        sys.stderr = open(errfile,\"w\")\n        print(str(2) + \" \" + \"Hello\")\n        print(2 + \" \" + \"Hello\")\n        return()\n# we pass the name of std and error file here\ntest(sys.argv[1],sys.argv[2])\nprint(f'name of file is {sys.argv[0]}')\nprint(f'first parameter is {sys.argv[1]}')\nprint(f'second parameter is {sys.argv[1]}')\n</code></pre> <p>Run the following command to pass the names of the standard output and error files to the script.</p> <pre><code>python3 test.py stdout2.file error2.log\n</code></pre>"},{"location":"book/ch7_decorator/ch7_decorator/","title":"Decorators","text":"<p>Decorators in Python allow you to enhance or modify the behavior of a function without changing its original structure. They work by \"wrapping\" one function with another. Decorators are a powerful and clean way to add functionality such as logging, access control, timing, or caching.</p> <p>The following example shows how to add a message before and after an existing function runs:</p> <pre><code>def wrapper(func):\n   def inner_fun():\n       print(\"Before calling function.\")\n       print(\"-\" *10)\n       func()\n       print(\"-\" *10)\n       print(\"After calling function.\")\n   return inner_fun\n\ndef print_me():\n    print('ThAnKs')\n\nprint_me()\nprint_me = wrapper(print_me)\nprint_me()   \n</code></pre> <p>Decorators are often used in a simplified form with the <code>@decorator_name</code> syntax placed above the function definition.</p> <pre><code>@wrapper\ndef print_me2():\n    print('ThAnKs')\n\nprint_me2()\n</code></pre>"},{"location":"book/ch7_decorator/ch7_decorator/#functions-arguments","title":"Function's arguments","text":"<p>If your function takes arguments, you can pass them using <code>*args</code> in the decorator.</p> <pre><code>def wrapper(func):\n   def inner_fun(*arg):\n       print(\"Before calling function.\")\n       func(*arg)\n       print(\"After calling function.\")\n   return inner_fun\n\ndef square(x):\n    print(x*x)\n\nsquare(4)\nsquare = wrapper(square)\nsquare(4)   \n\n# OR user simplifier\n@my_decor\ndef square(x):\n    print(x*x)\nsquare(4)\n</code></pre> <p>In this function, <code>*args</code> is used to pass positional arguments from the original function to the inner wrapper function.</p> <p>To explore how <code>*args</code> works, let's define a decorator that measures the execution time of a function:</p> <pre><code>import time\nstart_time = time.time()\n\ndef timestamp_Check(func):\n    def wrapper(*args):\n        start_time = time.time()\n        result = func(*args) # calls the addition function\n        print('Total running time')\n        print(time.time()-start_time)\n        return result\n    return wrapper\n\n@timestamp_Check\ndef pow(a, b):\n    return(a**b)\n\npow(10, 10)\n</code></pre> <p>Alternatively, you can write it as shown below, where <code>*args</code> and <code>**kwargs</code> are used to support the positional and keyword arguments of the function being decorated.</p> <pre><code>def timeit(fn): \n    def get_time(*args, **kwargs): \n        start = time.time() \n        output = fn(*args, **kwargs)\n        print(f\"Time taken in {fn.__name__}: {time.time() - start:.7f}\")\n        return output  # make sure that the decorator returns the output of fn\n    return get_time\n\n@timeit\ndef pow(a, b):\n    return(a**b)\n\npow(10, 10)\n</code></pre>"},{"location":"book/ch7_decorator/ch7_decorator/#chaining-decorators","title":"Chaining Decorators","text":"<p>We can apply multiple decorators to a single function by placing them one after the other, with the innermost decorator (the one closest to the function) being applied first.</p> <p>This allows you to layer functionality by using multiple decorators on a single function.</p> <pre><code>def wrapper (fn): \n    def inner_print(*args, **kwargs): \n        print(\"------------\")\n        output = fn(*args, **kwargs)\n        print(\"------------\")\n        return output  # make sure that the decorator returns the output of fn\n    return inner_print\n\n@wrapper\n@timeit\ndef pow(a, b):\n    return(a**b)\n\npow(10, 10)\n</code></pre>"},{"location":"book/ch7_decorator/ch7_decorator/#defining-decorators-with-arguments","title":"Defining Decorators With Arguments","text":"<p>Sometimes, it\u2019s useful to pass arguments to decorators. For example, the <code>@do_twice</code> decorator could be extended to a <code>@repeat(num_times)</code> decorator, where the number of times to execute the decorated function is given as an argument.</p> <p>To define a <code>@repeat</code> decorator, you could implement it like this: You can pass arguments to decorators in a similar manner.</p> <pre><code>def repeat(num_times):\n    def wrapper(func):\n        def inner(*args, **kwargs):\n            print(\"#-*\" * num_times)\n            value = func(*args, **kwargs)\n            return value\n        return inner\n    return wrapper\n\n@repeat(num_times=5)\ndef print_me(x):\n    print(f\"Hey {x}\")\n\nprint_me(\"Friend\")\n</code></pre>"},{"location":"book/ch7_decorator/ch7_decorator/#optional-arguments","title":"Optional Arguments","text":"<p>The following example shows how to define a decorator that ignores the argument if it is not provided.</p> <pre><code>def repeat(_func=None, *, num_times=2):\n    def decorator_repeat(func):\n        def wrapper_repeat(*args, **kwargs):\n            for _ in range(num_times):\n                value = func(*args, **kwargs)\n            return value\n        return wrapper_repeat\n    if _func is None:\n        return decorator_repeat\n    else:\n        return decorator_repeat(_func)\n\n\n@repeat\ndef print_me1():\n      print(\"ThAnKs\")\n\n\n@repeat(num_times=3)\ndef print_me2(name):\n    print(f\"ThAnKs {name}\")\n\nsay_whee()\ngreet(\"SAM\")\n</code></pre>"},{"location":"book/ch7_decorator/ch7_decorator/#tracking-state","title":"Tracking State","text":"<p>Sometimes, you can keep track of the state within the decorator. In the following example, <code>inner</code> is the inner function, and <code>inner.num</code> keeps track of the number of times the function has been called.</p> <pre><code>def count_runs(func):\n    def inner(*args, **kwargs):\n        inner.num += 1\n        print(f\"count {wrapper.num} of {func.__name__}()\")\n        return func(*args, **kwargs)\n    inner.num = 0\n    return wrapper\n\n@count_runs\ndef print_me():\n     print(\"ThAnKs\")\n</code></pre>"},{"location":"book/ch7_decorator/ch7_overview/","title":"Overview","text":"<p>Here, we discuss how to work with decorator in Python.</p> <ul> <li>Decorator: This section explain how to interact with the operating system in a platform-independent manner. </li> </ul>"},{"location":"book/ch8_class/ch8_challenges/","title":"Challenge","text":"<p>Under construction</p>"},{"location":"book/ch8_class/ch8_class/","title":"Class and object","text":""},{"location":"book/ch8_class/ch8_class/#introduction","title":"introduction","text":"<p>Python is an object-oriented programming language and provides powerful tools for working with various types of objects. When a suitable data structure is not already available, you can define your own object. An object is simply a collection of data (variables) and functions (methods) that operate on that data. While basic structures like lists can group values, classes allow you to define custom data structures or modify existing ones.</p> <p>Classes are particularly useful for combining related data and behavior, keeping everything organized and reusable. You can think of a class as a blueprint or a well-structured factory, where each component (like a department) has a clear and well-planned role.</p> <pre><code>class body(object):\n    \"\"\"Define class\"\"\"\n    \"\"\" we can use weigt and height\"\"\"\n    def __init__(self, weight,height):\n     self.weight=weight\n     self.height=height\ndef bmi_body(b):\n    print (' BMI is (%g)' %((b.weight/b.height)))\n\nSAM = body(90,79)\nSAM.weight\nSAM.height\nprint (SAM)\nbmi_body(SAM)\n</code></pre> <p>Or, it can be simplified as follows:</p> <pre><code>class body(object):\n    \"\"\"Define class\"\"\"\n    \"\"\" we can use wheigt and height\"\"\"\ndef bmi_body(b):\n    print (' BMI is (%g)' %((b.weight/b.height)))\n\nSAM = body()\nSAM.weight = 90\nSAM.height = 79\nprint (SAM)\nbmi_body(SAM)\n</code></pre> <p>Let's explain it further with an example. In the U.S., dates are typically written as Month/Day/Year. Write a function that converts this format to the Canadian style, which is Day/Month/Year.</p> <pre><code>class dateg(object):\n    \"\"\"Define class\"\"\"\n    \"\"\"Month, Day, Year \"\"\"\ndef ca_date(d):\n    print (' Canadian date is (%g/%g/%g)' %((d.day,d.month,d.year)))\n\nmybirt = dateg()\nmybirt.day = 11\nmybirt.month = 11\nmybirt.year = 11\nprint (mybirt)\nca_date(mybirt)\n</code></pre> <p>A class creates a new local namespace and stores all its attributes, which can include both data and functions.</p> <pre><code>print(dateg.__doc__)\n</code></pre>"},{"location":"book/ch8_class/ch8_class/#initialize","title":"initialize","text":"<p>Sometimes it's better to initialize variables at the beginning, which can be done using the <code>__init__</code> method.</p> <pre><code>class dateg(object):\n    \"\"\"Define class\"\"\"\n    \"\"\"Month, Day, Year \"\"\"\n    def __init__(object,d=1,m=1,y=1):\n        object.day=d\n        object.month=m\n        object.year=y\n\ndef ca_date(d):\n    print (' Canadian date is (%g/%g/%g)' %((d.day,d.month,d.year)))\n\nmybirt = dateg()\nmybirt.day = 11\nmybirt.month = 11\nmybirt.year = 11\nprint (mybirt)\nca_date(mybirt)\n</code></pre> <p>Since the value has limitations, we need to enforce boundaries. This can be done using setter and getter methods.</p> <pre><code>class body(object):\n    def __init__(object,weight,height):\n        object.set_weight(weight)\n        object.set_hight(height)\n  # getter method\n    def get_weight(object):\n        return object._weight\n    def get_height(object):\n        return object._height        \n    # setter method\n    def set_weight(object, value):\n        if value &lt; 0:\n            raise ValueError(\"Weight below 0 is not possible.\")\n        self._weight = value\n    def set_height(object, value):\n        if value &lt; 0:\n            raise ValueError(\"Height below 0 is not possible.\")\n        self._height = value\n def bmi_body(b):\n    print (' BMI is (%g)' %((b.weight/b.height)))\n\nSAM = body(90,79)\nprint(SAM)\nprint(SAM.get_weight)\nprint(SAM.get_height)\nprint(SAM.bmi_body)\n</code></pre> <p>Note: In Python, a leading underscore (_) before a variable name is a convention that indicates it is intended to be private, meaning it should not be accessed directly from outside the class.</p> <p>Clearly, the code must be written carefully to avoid errors. To help with this, Python provides the property class, which allows you to define getters and setters without creating separate method names. The following example shows how property simplifies access and updates to class attributes.</p> <pre><code>class body(object):\n    def __init__(object,weight=.01,height=.01):\n        object.weight=weight\n        object.height=height\n    def bmi_body(b):\n        print (' BMI is (%g)' %((b.weight/b.height)))\n    # getter method\n    def get_weight(object):\n        return object._weight\n    def get_height(object):\n        return object._height        \n    # setter method\n    def set_weight(object, value):\n        if value &lt; 0:\n            raise ValueError(\"Weight below 0 is not possible.\")\n        object._weight = value\n    def set_height(object, value):\n        if value &lt; 0:\n            raise ValueError(\"Height below 0 is not possible.\")\n        object._height = value\n    weight = property(get_weight, set_weight)\n    height = property(get_height, set_height)\n\n\n\nSAM = body(90,79)\nprint(SAM)\nprint(SAM.get_weight())\nprint(SAM.bmi_body())\n</code></pre> <p>Using decorators can simplify the structure. A decorator is a function that adds new functionality to another function, which is passed as an argument.</p> <pre><code>class body(object):\n    def __init__(object,weight=.01,height=.01):\n        object.weight=weight\n        object.height=height\n    def bmi_body(b):\n        print(' BMI is (%g)' %((b.weight/b.height)))\n    @property\n    def weight(object):\n        return object._weight\n    @property\n    def height(object):\n        return object._height        \n    @weight.setter\n    def weight(object, value):\n        if value &lt; 0:\n            raise ValueError(\"Weight below 0 is not possible.\")\n        object._weight = value\n    @height.setter    \n    def height(object, value):\n        if value &lt; 0:\n            raise ValueError(\"Height below 0 is not possible.\")\n        object._height = value\n\n\nSAM = body(90,79)\nprint(SAM)\nprint(SAM.weight)\nprint(SAM.bmi_body())\n</code></pre> <p>Let's explain it further with an example. Create a function to generate an email for a new employee.</p> <pre><code>class Create_employee:\n    def __init__(self, first, last):\n        self.first = first\n        self.last = last\n        print('New Employee: {} - {}'.format(self.fullname, self.email))\n    @property\n    def email(self):\n        return '{}.{}@email.com'.format(self.first, self.last)\n    @property\n    def fullname(self):\n        return '{} {}'.format(self.first, self.last)\n\nnew_emp_1 = Create_employee('Sam', 'Amiri')\nnew_emp_1.email\nnew_emp_1.fullname\n</code></pre> <p>To practice further, let's write a function to calculate the mean (average) of a list of numbers.</p> <pre><code>class Mean(object):\n  def __init__(self):\n    self.vals = []\n  def add_value(self, x):\n    self.vals.append(x)\n  def result(self):\n    return sum(self.vals)/len(self.vals)\n  def  reset_states(self):\n    self.vals = []\n\naa=Mean()\nprint(aa)\naa.add_value(3)\naa.add_value(2)\naa.result()\naa.reset_states()\n</code></pre>"},{"location":"book/ch8_class/ch8_class/#object-presentation","title":"Object presentation","text":"<p>To display the values of an object's attributes, you can use the <code>__str__</code> method, which is an example of operator overloading and is discussed in:</p> <pre><code>class body(object):\n    \"\"\"Define class\"\"\"\n    \"\"\" we can use weigt and height\"\"\"\n    def __init__(bd, weight,height):\n     bd.weight=weight\n     bd.height=height\n    def __str__(bd):\n     return(\"weight: {0} Height: {1}\".format(bd.weight, bd.height))\n\nSAM = body(90,79)\nprint(SAM)\nSAM.__str__()\n</code></pre>"},{"location":"book/ch8_class/ch8_class_as_decorators/","title":"Class as Decorator","text":"<p>You can write a class as a decorator, a technique where a class is used to modify the behavior of a function, similar to how a regular function decorator works. In this case, you need to take the function as an argument in <code>__init__</code>. Let\u2019s write a class that counts the number of times the class method is executed.</p> <pre><code>class count_run:\n    def __init__(self, func):\n        self.func = func\n        self.num = 0\n    def __call__(self, *args, **kwargs):\n        self.num += 1\n        print(f\"Execute # {self.num} of {self.func.__name__}()\")\n        return self.func(*args, **kwargs)\n\n\n@count_run\ndef print_me():\n    print(\"ThAnKs\")\n\nprint_me()\n</code></pre>"},{"location":"book/ch8_class/ch8_inheritance/","title":"Inheritance","text":""},{"location":"book/ch8_class/ch8_inheritance/#introduction","title":"Introduction","text":"<p>Inheritance allows a class (called a child or subclass) to inherit attributes and methods from another class (called a parent or base class). This enables code reuse and establishes a hierarchical relationship between classes. In other words, it allows a new class to build upon an existing one, inheriting its structure and behavior.</p> <pre><code>class Parent:\n    ...\n\nclass Child(Parent):\n    ...\n</code></pre> <p>The new class, Child, is called a subclass.</p> <pre><code>class Stock:\n    def __init__(self, name, shares, price):\n        self.name = name \n        self.shares = shares\n        self.price = price\n    def cost(self):\n        return(self.shares*self.price)\n    def sell(self, nshares):\n        self.shares -= nshares\n\n\nclass MyStock(Stock): \n    def panic(self):\n        self.sell(self.shares)\n\ns = MyStock('GOOG', 100, 490)\ns.shares\ns.sell(20)\ns.shares\ns.panic()\n</code></pre> <p>If you need to access a temporary object from the parent class, use the super() function. <pre><code>class MyStock3(Stock):\n    def cost(self):\n        actual_cost = super().cost()\n        return(f'1.2 * {actual_cost}')\n\ns = MyStock('GOOG', 100, 490)\ns.shares\ns.sell(20)\ns.shares\ns.cost()\n</code></pre></p> <p>If <code>__init__</code> is defined in a subclass, it is essential to initialize the parent class using super().</p> <pre><code>class Stock:\n    def __init__(self, name, shares, price):\n        self.name = name\n        self.shares = shares\n        self.price = price\n    def cost(self):\n        return(self.shares*self.price)\n\n\nclass MyStock(Stock):\n    def __init__(self, name, shares, price, factor):\n        super().__init__(name, shares, price)\n        self.factor = factor\n    def cost(self):\n        return self.factor * super().cost()\n\ns = MyStock('GOOG', 100, 490,5)\ns.cost()\n</code></pre> <p>You can inherit from multiple classes in Python, a feature known as multiple inheritance.</p> <pre><code>class Mother:\n    ...\n\nclass Father:\n    ...\n\nclass Child(Mother, Father):\n    ...\n</code></pre> <pre><code>class Stock_n:\n    def __init__(self, name, shares, price):\n        self.name = name\n        self.shares = shares\n        self.price = price\n\nclass Stock_sp:\n    def __init__(self,name, shares, price):\n        self.name = name\n        self.shares = shares\n        self.price = price\n    def cost(self):\n        return(self.shares*self.price)\n\n\nclass MyStock(Stock_n,Stock_sp):\n    def __init__(self, name, shares, price, factor):\n        super().__init__(name,shares, price)\n        self.factor = factor\n    def cost(self):\n        return self.factor * super().cost()\n\n\ns = MyStock('GOOG', 100, 490,5)\ns.cost()\n</code></pre>"},{"location":"book/ch8_class/ch8_operator_overloading/","title":"Operator Overloading","text":""},{"location":"book/ch8_class/ch8_operator_overloading/#introduction","title":"Introduction","text":"<p>In Python, you can define operators to perform specific computations. The following example shows how to define operators for addition and subtraction.</p> <pre><code>class point:\n    def __init__(self, x=0, y=0):\n        self.x = x\n        self.y = y\n    def __str__(self):\n        return \"({self.x},{self.y})\"\n    def __add__(self, other):\n        x = self.x + other.x\n        y = self.y + other.y\n        return point(x, y)\n    def __sub__(self, other):\n        x = self.x - other.x\n        y = self.y - other.y\n        return point(x, y)\n</code></pre> <p>Functions can be called as shown below:</p> <pre><code>p1 = Point(1, 2)\np2 = Point(2, 3)\n\nprint(p1+p2)\nprint(p1.__add__(p2))\nprint(Point.__add__(p1,p2))\n</code></pre> <p>The special functions are listed below:</p> <code>__init__</code> initialize the attributes of the object <code>__str__</code> returns a string representation of the object <code>__len__</code> returns the length of the object <code>__call__</code> call objects of the class like a normal function <code>__add__</code> adds two objects <code>p1 + p2</code> <code>p1.__add__(p2)</code> <code>__sub__</code> Subtraction <code>p1 - p2</code> <code>p1.__sub__(p2)</code> <code>__mul__</code> Multiplication <code>p1 * p2</code> <code>p1.__mul__(p2)</code> <code>__pow__</code> Power <code>p1 ** p2</code> <code>p1.__pow__(p2)</code> <code>__truediv__</code> Division <code>p1 / p2</code> <code>p1.__truediv__(p2)</code> <code>__floordiv__</code> Floor Division <code>p1 // p2</code> <code>p1.__floordiv__(p2)</code> <code>__mod__</code> Remainder (modulo) <code>p1 % p2</code> <code>p1.__mod__(p2)</code> <code>__lshift__</code> Bitwise Left Shift <code>p1 &lt;&lt; p2</code> <code>p1.__lshift__(p2)</code> <code>__rshift__</code> Bitwise Right Shift <code>p1 &gt;&gt; p2</code> <code>p1.__rshift__(p2)</code> <code>__and__</code> Bitwise AND <code>p1 &amp; p2</code> <code>p1.__and__(p2)</code> <code>__or__</code> Bitwise OR <code>p1 | p2</code> <code>p1.__or__(p2)</code> <code>__xor__</code> Bitwise XOR <code>p1 ^ p2</code> <code>p1.__xor__(p2)</code> <code>__invert__</code> Bitwise NOT <code>~p1</code> <code>p1.__invert__()</code>"},{"location":"book/ch8_class/ch8_operator_overloading/#call","title":"call","text":"<p>When <code>__init__</code> is called, an object is created and initialized. Sometimes, you may want to redefine or modify the behavior of an object after it's created, which can be done using the <code>__call__</code> method.</p> <pre><code>class test(object):\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n        print (f'{self.x} {self.y}')\n    def __call__(self, y):\n        self.y = y\n        print (f'__call__ {self.x} {self.y}')\n\ninit1 = test(1, 2)\ninit1.x=2\ninit1(7)\ninit1(8)\n</code></pre> <p>The following example shows how to use <code>__call__</code> to track the number of executions.</p> <pre><code>class counter:\n     def __init__(self, start=0):\n         self.count = start\n     def __call__(self):\n         self.count += 1\n         print(f\"Current count is {self.count}\")\n\ncounter = counter()\ncounter()\n</code></pre>"},{"location":"book/ch8_class/ch8_operator_overloading/#iter-and-next","title":"iter and next","text":"<p><code>iter</code> and <code>next</code> are very useful for iterating through elements one by one. The <code>iter</code> function assigns an object as an iterator, while the next() function returns the next item from an iterator. Its syntax is <code>next(iterator, default)</code>, where default is the value returned when the iterator reaches its end.</p> <pre><code>list = iter([\"one\", \"two\"])\nx = next(list, \"end\")\nprint(x)\nx = next(list, \"end\")\nprint(x)\nx = next(list, \"end\")\nprint(x)\n</code></pre> <p>The following example shows how to generate the Fibonacci series.</p> <p><pre><code>class Fib:                                        \n    def __init__(self, max):                      \n        self.max = max\n    def __iter__(self):                           \n        self.a = 0\n        self.b = 1\n        return self\n    def __next__(self):                           \n        fib = self.a\n        if fib &gt; self.max:\n            raise StopIteration                   \n        self.a, self.b = self.b, self.a + self.b\n        return fib       \n</code></pre> <pre><code>for n in Fib(1000):\n   print(n, end=' ')\n</code></pre></p>"},{"location":"book/ch8_class/ch8_operator_overloading/#classmethod-and-staticmethod","title":"classmethod and staticmethod","text":"<p>These are functions within an object's namespace, accessible as attributes. A class method receives the class itself (usually referred to as cls) as its implicit first argument, while a static method does not receive any implicit first argument (similar to a regular function).</p> <p>A <code>@staticmethod</code> is essentially a function defined inside a class that can be called without creating an instance of the class. Its behavior is not affected by inheritance, meaning it remains immutable in derived classes.</p> <pre><code>from datetime import date\n\nclass Person:\n    def __init__(self, name, age):\n        self.name = name\n        self.age = age\n    # a class method to create a\n    # Person object by birth year.\n    @classmethod\n    def fromBirthYear(cls, name, year):\n        return cls(name, date.today().year - year)\n    # a static method to check if a\n    # Person is adult or not.\n    @staticmethod\n    def isAdult(age):\n        return age &gt; 18\n\nperson1 = Person('mayank', 21)\nperson2 = Person.fromBirthYear('mayank', 1996)\n\nprint(person1.age)\nprint(person2.age)\n</code></pre>"},{"location":"book/ch8_class/ch8_overview/","title":"Overview","text":"<p>Here, we discuss how to work with class in Python.</p> <ul> <li>Class and object : It explains how to write a class. </li> <li>Inheritance: It disccuses how to inherit attributes and methods from an existing class. </li> <li>Operator Overloading: It shows how to define custom behavior for operators when applied to objects of a class. </li> <li>Class as decorators:  It explains how use a class as a decorator to modify the behavior of a function or method. </li> <li>Challenges</li> </ul>"},{"location":"book/ch9_high_funcs/ch9_functools/","title":"functools","text":"<p>functools is a module that provides tools for working with functions and other callable objects.</p>"},{"location":"book/ch9_high_funcs/ch9_functools/#partial","title":"partial","text":"<p>One of its useful is <code>partial</code> which allows write and maintain the existing functions to achieve new purpose. The following function shows how to rewrite the t-test in a way just calculate the p-value.. </p> <pre><code>from functools import partial\nimport numpy as np\nimport scipy.stats\nx, y = np.random.normal(0, 1, (100,2)).T\nttest_0=partial(scipy.stats.ttest_ind, equal_var=False)\n\ndef ttest_NE(x,y):\n   return print(\"p-value=\",ttest_0(x,y)[1])\n\nttest_NE(x,y)\n</code></pre>"},{"location":"book/ch9_high_funcs/ch9_functools/#wraps","title":"wraps","text":"<p><code>wraps</code> can be used to write a decorators in Python, by using @wraps, you can preserves that metadata by copying it from the original function to the wrapper function.</p> <pre><code>from functools import wraps\n\ndef do_nothing_decorator(f):\n   @wraps(f)\n   def wrapper(*args, **kwds):\n          print('INSIDE DECORATOR: This is called before function')\n          return f(*args, **kwds)\n   return wrapper\n\n@do_nothing_decorator\ndef hello_world():\n  \"\"\"This is a hello world function\"\"\"\n  print(\"AAA\")\n</code></pre> <p>Let run this function  <pre><code>&gt;&gt;&gt; hello_world()\nINSIDE DECORATOR: This is called before function\nAAA\n&gt;&gt;&gt; print(f\"Function Name: {hello_world.__name__}\")\nFunction Name: hello_world\n&gt;&gt;&gt; print(hello_world.__doc__)\nThis is a hello world function\n</code></pre></p> <p>Now let run without the wrape</p> <pre><code>def do_nothing_decorator(f):\n   def wrapper(*args, **kwds):\n          print('INSIDE DECORATOR: This is called before function')\n          return f(*args, **kwds)\n   return wrapper\n\n@do_nothing_decorator\ndef hello_world():\n  \"\"\"This is a hello world function\"\"\"\n  print(\"AAA\")\n</code></pre> <pre><code>&gt;&gt;&gt; hello_world()\nINSIDE DECORATOR: This is called before function\nAAA\n&gt;&gt;&gt; print(f\"Function Name: {hello_world.__name__}\")\nFunction Name: wrapper\n&gt;&gt;&gt; print(hello_world.__doc__)\nNone\n</code></pre> <p>So, wraps ensures the decorated function retains its original identity. </p>"},{"location":"book/ch9_high_funcs/ch9_itertor/","title":"Itertor","text":""},{"location":"book/ch9_high_funcs/ch9_itertor/#itertools","title":"itertools","text":"<p>itertools provides several functions for efficient iteration. Below is an example of how to use it to generate combinations and permutations:</p> <pre><code>from itertools  import combinations\nlist(combinations([1,2,3], r=2))\nprint([list(c) for c in combinations([1,2,3], r=2)])\n\nfrom itertools  import permutations\nlist(permutations('abc'))\nprint([''.join(p) for p in permutations('abc')])\n</code></pre> <p>As an exercise, let's write an example that generates the permutations and combinations of the numbers 1 to 6, and then selects those whose elements sum to 9.</p> <pre><code>import itertools as it\n\nmy_list = [1,2,3,4,5,6]\ncomb = combinations(my_list, 3)\nperm = permutations(my_list, 3)\n\n[result for result in comb if sum(result) == 9]\n[result for result in perm if sum(result) == 9]\n</code></pre>"},{"location":"book/ch9_high_funcs/ch9_itertor/#groupby","title":"groupby","text":"<p>Let's look at groupby, which groups consecutive items. In the example below, we group animals based on the length of their names.</p> <pre><code>from itertools  import groupby\nanimals = sorted(['pig', 'cow', 'giraffe', 'dolphin','dog', 'cat', 'lamma', 'lion', 'tiger'], key=len)\nfor k, g in groupby(animals, key=len):\n    print(k, list(g))\n</code></pre> <p>Always sort the data before using groupby, otherwise unexpected results may occur. Now, let's group the animals.</p> <pre><code>animals = ['pig', 'cow', 'giraffe', 'dolphin','dog', 'cat', 'lamma', 'lion', 'tiger']\nanimals.sort(key=lambda x: x[0])  # Sort by first letter\n\nfor k, g in groupby(animals, key=lambda x: x[0]):\n    print(k, list(g))\n</code></pre>"},{"location":"book/ch9_high_funcs/ch9_itertor/#concatenate-lists","title":"Concatenate lists:","text":"<p>You can use <code>chain</code> to combine multiple iterables into a single continuous sequence.</p> <pre><code>from itertools import chain\n\nch = itertools.chain([1, 2], [3, 4])\nprint(list(ch))\n</code></pre>"},{"location":"book/ch9_high_funcs/ch9_itertor/#repeat","title":"repeat","text":"<p>You can use repeat to repeat a single value multiple times:</p> <pre><code>from itertools import repeat\nprint(list(repeat([1, 2], 3)))\n</code></pre> <p>You can repeat a value infinitely by omitting the repeat count, </p> <pre><code>from itertools import repeat\nfor i, item in enumerate(repeat([1, 2])):\n    print(item)\n    if i == 6:\n        break\n</code></pre>"},{"location":"book/ch9_high_funcs/ch9_itertor/#generator","title":"Generator","text":"<p>A simple way to create an iterator is by using a generator, which yields items one at a time instead of storing the entire sequence in memory.</p> <pre><code>def gen(n):\n    print('first one')\n    yield n+1\n    print('second one')\n    yield n+2\n    print('third one')\n    yield n+3\n\na = gen(0)\nnext(a)\nnext(a)\nnext(a)\n</code></pre> <p>We often use yield inside a while loop to create generators that produce values until a condition is met.</p> <pre><code>def gen2(n):\n    count = 1\n    while count &lt;= n:\n        yield count\n        count += 1\n\na = gen(0)\nnext(a)\nnext(a)\nnext(a)\n\nb = gen2(5)\nfor i in a:\n    print(i)\n</code></pre>"},{"location":"book/ch9_high_funcs/ch9_overview/","title":"Overview","text":"<p>In this chapter, we discuss the higher-order functions that takes another function as an argument, returns a function. </p> <ul> <li>functools</li> <li>itertor</li> </ul>"},{"location":"concise_notes/","title":"Concise notes","text":"<p>Here, we gather concise notes.</p>"},{"location":"concise_notes/2024/10/26/how-run-apply-on-array/","title":"How run apply on array","text":"<pre><code>import numpy as np\nx = np.array([[5,2,1,3], [2,1,5]])\nfun = lambda t: np.argmax(t)\nnp.array([fun(xi) for xi in x])\n</code></pre>"},{"location":"concise_notes/2024/10/26/applying-function-on-data-frame/","title":"Applying function on data-frame","text":"<p>Using <code>df.apply(fun)</code> can apply a function on columns or row:</p> <pre><code>df.apply(np.sum, axis=0)\ndf.apply(np.sum, axis=1)\n</code></pre> <p>Even can write a new function and run on columns or rows <pre><code>def prod(col):\n    return col['A'] * col['B']\n\ndf.apply(prod, axis=1)\ndf['productcolmn']=df.apply(prod, axis=1)\n</code></pre></p>"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/","title":"Cheat Sheet of python core, Numpy, and Panda","text":""},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#primer","title":"Primer","text":"<p>Here and a brief of Useful functions of python core, Numpy and Panda are presented. </p>"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#libraries","title":"Libraries","text":"<code>pip install numpy</code> Install library <code>pip install git+https://github.com/mwaskom/seaborn.git</code> Install from GitHub <code>import numpy</code> load library"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#starting","title":"starting","text":"<p>By putting # infront line, Python ignores running the rest. </p> # <code>x=1 # Python ignore</code> <code>import os</code> <code>os.getcwd()</code> See the working directory <code>os.chdir()</code> Change  the working directory"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#mathematical-operations","title":"Mathematical operations","text":"<code>1 + 2</code> Addition <code>1 - 2</code> Subtraction <code>1 / 2</code> Division <code>1 * 2</code> Multiplication <code>1 ** 2</code> Power <code>x += 1</code> Assign the value of x + 1 to x <code>x -= 1</code> Assign the value of x - 1 to x"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#built-in-constants","title":"Built-in Constants","text":"<code>None</code> Absence of a value <code>False</code> The bool type false <code>True</code> The bool type true"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#type","title":"Type","text":"<code>str()</code> Convert the string <code>int()</code> Convert the integer <code>float()</code> Convert the floating <code>bool()</code> Convert the boolen"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#lists","title":"Lists","text":"<code>l = list()</code> Assign an empty list to l <code>l = [3,2]</code> Create list and assgn 3 and 2 to it <code>l[0]</code> Return the first value <code>l[-1]</code> Return the last value <code>l[-4:]</code> Return that last 4 items. <code>l[1:4]</code> Return subset containing the second till  fourth values <code>l[1::3]</code> Return every third items starting from l[1] <code>l.append(1)</code> Append the value 1 to the end of l <code>l+[1]</code> Append the value 1 to the end of l <code>l.sort()</code> Sort l and replace original with it <code>l.reverse()</code> Sort reversely the items in l <code>l.remove(a)</code> Removes the first item equals to a. <code>l.pop(2)</code> Restun the second item and drop it from l <code>[i for i in range(1,100) if i%2==0]</code> Generate list of even number between 1 and 100 <code>l= [1, \"\", 3]</code> Creat a list with missing value."},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#dictionary","title":"Dictionary","text":"<code>d={\"weight\":2.4, \"height\":15}</code> Creat a dictionary with keys \"weight\" and \"height\", and their corresponding values of 2.4, 15 <code>d[\"weight\"]</code> Return values corrsponding \"weight\" <code>d.keys()</code> Return the keys from d <code>d.values()</code> Return the values from d <code>d.items()</code> Return  (key, value) pairs from d"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#built-in-function","title":"Built-in function","text":"<code>len(x)</code> Return the number of elements in x <code>min(x)</code> Return the min of the values of x <code>sum(x)</code> Return the sum of the values of x <code>type(x)</code> Return type of the values of x <code>range(3,10)</code> Generate a series of number from a number (3) to another number (10) with specific increment"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#user-function","title":"User Function","text":"<code>def name (argument):</code> <code>script</code> <code>return output</code> Create a function <code>name = lambda arguments: script</code> Create one line function <code>if state1:</code> <code>script1</code> <code>elif x &lt; 0:</code> <code>script2</code> <code>else:</code> <code>script3</code> Test state1 and state2, and run script corresponding to the correct statement, otherwise run script3"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#iterates","title":"Iterates","text":"<code>for value in obj:</code> <code>script</code> Iterate the code for each value in obj <code>while cond:</code> <code>script</code> Run the code until reach to condion"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#boolean-comparisons","title":"Boolean Comparisons","text":"<code>x == 2</code> Test whether x is equal to 2 <code>x != 2</code> Test whether x is not equal to 2 <code>x &lt; 2</code> Test whether x is less than 2 <code>x &lt;= 2</code> Test whether x is less than or equal to 2 <code>x &gt; 2</code> Test whether x is greater than 2 <code>x &gt;= 2</code> Test whether x is greater than or equal to 2 <code>(x == 2) or (y == 1)</code> Test whether x is equal to 5 or y is equal to 1 <code>(x == 2) | (y == 1)</code> Test whether x is equal to 5 or y is equal to 1 <code>(x == 2) and  (y == 1)</code> Test whether x is equal to 5 and y is equal to 1 <code>(x == 2) &amp; (y == 1)</code> Test whether x is equal to 5 and  y is equal to 1 <code>3 in l</code> Checks whether the value 3 exists in the  l"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#numpy","title":"Numpy","text":"<p>Numpy (NUMerical PYthon) provides very useful arrays structure to work with data. </p> <code>import numpy as np</code> <code>pips install numpy</code> <code>python3 -m pip install --upgrade  numpy</code>"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#arrays","title":"Arrays","text":"<code>np.array([1,2,3])</code> One dimensional array <code>np.array([(1,2,3),(4,5,6)])</code> Two dimensional array <code>arr[i]</code> The ith element <code>arr[i:]</code> The ith row <code>arr[i][j]</code> The ith and jth element, the same as <code>arr[i,j]</code> <code>np.full((2,1),2.2)</code> 2x1 array with all values 2.2 <code>np.linspace(0, 1, 10)</code> <code>np.eye(3)</code> A diagonal array of size 3x3 (Identity matrix) <code>np.zeros(3)</code> An array of length 3 with all values 0 <code>np.ones((4,2))</code> An array of size 4x2 with all values 1 <code>np.arange(1,14,4)</code> An 1D array from 1 to 14 with step 4"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#random","title":"Random","text":"<code>np.random.rand(4,2)</code> Generates a 4x2  array of random number from uniform <code>np.random.rand(4,2)</code> Generates a 4x2 array  of random number from standard normal <code>np.random.randint(low=1,high=20, size=(2,3))</code> Generates a 2x3 array of random ints between 1\u201320 <code>np.random.choice(arr,size=s,replace=True,p=pr)</code> Resamples of size s from arr acording probability pr"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#os","title":"O\\S","text":"<code>np.savetxt('file.txt',arr,delimiter=' ')</code> Writes to a text file <code>np.savetxt('file.csv',arr,delimiter=',')</code> Writes to a CSV file <code>np.loadtxt('file.txt')</code> Loads from a text file <code>np.genfromtxt('file.csv',delimiter=',')</code> Loads from a CSV file <code>np.save('file_of_arr.npy ', arr)</code> Saves  array into a file <code>np.savez('file_of_arr.npz', arr1, arr2)</code> Saves  array into a file <code>np.load('my_array.npy')</code> Loads arrays"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#inspecting-arrays","title":"Inspecting arrays","text":"<code>arr.dtype</code> Returns type of elements in array <code>arr.size</code> Returns number of elements in array <code>len(arr)</code> Length of array <code>arr.shape</code> Returns dimensions of arr <code>arr.astype(dtype)</code> Convert arr elements to type dtype <code>arr.tolist()</code> Convert arr to a Python list"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#sorting","title":"Sorting","text":"<code>arr.sort()</code> Sort elements of arr <code>arr.sort(axis=0)</code> Sorts elements of axis=0 of arr"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#reshaping","title":"Reshaping","text":"<code>arr.reshape(4,3)</code> Reshapes arr to 4x3 without changing data <code>arr.resize((4,3))</code> Changes arr shape to 4x3 and fills new values with 0 <code>arr.T</code> Transposes arr"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#concatenate","title":"Concatenate","text":"<code>np.concatenate(arr1,arr2,axis=0)</code> concatenate arr2 to arr1 along  the axis <code>np.hstack((arr1,arr2))</code> Stack arrays horizontally (column wise) <code>np.vstack((arr1,arr2))</code> Stack arrays vertically (row wise)"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#copying","title":"Copying","text":"<code>arr2 = arr1.view()</code> Create a view of the array with the same data <code>np.copy(arr)</code> Create a copy of aar <code>arr2 = arr1.copy()</code> Create a deep copy of the array"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#addingremoving-elements","title":"Adding/Removing Elements","text":"<code>np.append(arr1,arr2)</code> Append arr2 to arr1 <code>np.insert(arr, 1, 10)</code> Insert 10 on index 1 items <code>np.delete(a,2)</code> Delete element on index 1 from array"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#indexing","title":"Indexing","text":"<code>arr[2]</code> Returns the element at index 2 <code>arr[2]=3</code> Assigns 3 to the element on index 2 <code>arr[2,3]</code> Returns the array element on index [2,3] <code>arr[2,3]=10</code> Assigns 3 to the element on index [2,3]"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#slicing","title":"Slicing","text":"<code>arr[:2]</code> Returns the elements at indices 0,1 <code>arr[2:4]</code> Returns the elements at indices 2,3 <code>arr[0:2,3]</code> Returns the elements on rows 0,1 at column 3 <code>arr[:,1]</code> Returns the elements on column 2 <code>arr[[1,2],[2,3]]</code> Returns the elements at indices [1,3] and [2,3]"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#subsetting","title":"Subsetting","text":"<code>arr&lt;2</code> Returns a boolen array, True for arr&lt;2 and False for the rest <code>(arr1&lt;2) &amp; (arr2&gt;3)</code> Returns a boolen array, True for (arr1&lt;3) &amp; (arr2&gt;5) and False for the rest <code>arr[arr&lt;2]</code> Select array with elements smaller than 2 <code>arr[~(arr&lt;2)]</code> Select array with elements not smaller than 2"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#vector-math","title":"Vector Math","text":"<code>np.add(arr1,arr2)</code> Elementwise add arr2 to arr1 <code>np.subtract(arr1,arr2)</code> Elementwise subtract arr2 from arr1 <code>np.multiply(arr1,arr2)</code> Elementwise multiply arr1 by arr2 <code>np.divide(arr1,arr2)</code> Elementwise divide arr1 by arr2 <code>np.power(arr1,arr2)</code> Elementwise raise arr1 raised to the power of arr2 <code>np.array_equal(arr1,arr2)</code> Returns True if the arrays have the same elements and shape <code>np.sqrt(arr)</code> Square root of each element in the array <code>np.sin(arr)</code> Sine of each element in the array <code>np.log(arr)</code> Natural log of each element in the array <code>np.abs(arr)</code> Absolute value of each element in the array <code>np.ceil(arr)</code> Rounds up to the nearest int <code>np.floor(arr)</code> Rounds down to the nearest int <code>np.round(arr)</code> Rounds to the nearest int"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#aggregate-functions","title":"Aggregate Functions","text":"<code>arr.min()</code> Returns minimum value of arr <code>arr.max(axis=0)</code> Returns maximum value of specific axis <code>np.mean(arr,axis=0)</code> Returns mean of specific axis <code>np.median(arr,axis=0)</code> Returns median of  specific axis <code>arr.sum()</code> Returns sum of arr <code>np.var(arr)</code> Returns the variance of array <code>np.std(arr,axis=1)</code> Returns the standard deviation of specific axis <code>np.quantile(arr,q=(q1,q2,..), axis=1)</code> Returns the (q1,q2, ....) quantiles of specific axis <code>arr.corrcoef()</code> Returns correlation coefficient of array"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#pandas","title":"Pandas","text":"<p>Pandas is built for working with data set.</p> <code>import pandas as pd</code> <code>pip3 install pandas</code> <code>python3 -m pip install --upgrade  pandas</code>"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#create-data-frame-and-series","title":"Create Data frame and series","text":"<code>pd.DataFrame(matrix, column=)</code> Create data frame from matrix. <code>pd.DataFrame(dict)</code> Create data frame from a dict, keys would be used as the name of columns <code>pd.Series(list)</code> Create a series from a list <code>df.index = pd.date_range('2000/1/1', periods=df.shape[0])</code> Add a date index to the data frame"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#io","title":"I/O","text":"<code>pd.read_csv(filename)</code> Load CSV file <code>pd.read_table(filename)</code> Load from a delimited text file <code>pd.read_excel(filename)</code> Load from an Excel file <code>pd.read_sql(query, connection_object)</code> Load from a SQL table/database <code>pd.read_json(json_string)</code> Load from Read JSON formatted file s <code>pd.read_html(url)</code> Create a data from from an html URL <code>pd.read_clipboard()</code> Create a data frame from  the contents of your clipboard <code>df.to_csv(filename)</code> Save df as  a CSV file <code>df.to_excel(filename)</code> Save df as an Excel file <code>df.to_sql(table_name, connection_object)</code> Save df to a SQL table <code>df.to_json(filename)</code> Save df as a file in JSON format"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#inspecting-arrays_1","title":"Inspecting arrays","text":"<code>arr.dtype</code> Returns type of elements in array <code>arr.size</code> Returns number of elements in array <code>len(arr)</code> Length of array <code>arr.shape</code> Returns dimensions of arr <code>arr.astype(dtype)</code> Convert arr elements to type dtype <code>arr.tolist()</code> Convert arr to a Python list <code>arr.value_counts(dropna=False)</code> View unique values and counts <code>df.head(l)</code> Return the first l rows of the DataFrame <code>df.tail(l)</code> Return  the last l rows of the DataFrame <code>df.shape</code> Return the number of rows and columns <code>df.info()</code> Return index, datatype, and memory information <code>df.describe()</code> Return the summary statistics of numerical columns"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#sorting_1","title":"Sorting","text":"<code>df.sort_values(col)</code> Sort data frame values by col in ascending order <code>df.sort_values(col,ascending=False)</code> Sort data frame values by col in descending order <code>df.sort_values([col1,col2],ascending=[True,False])</code> data frame values by col1 in ascending order then col2 in descending order"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#addingremoving-elements_1","title":"Adding/Removing Elements","text":"<code>df.columns = ['name1','name2']</code> Add new name to  columns <code>df.rename(columns={'old_name': 'new_ name'})</code> Rename columns <code>df.set_index('colu')</code> Change the index to the given column <code>s.replace([1,2],['two','one'])</code> Replace 1 and 2 with  'two' and 'one', respectively"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#missing","title":"Missing","text":"<code>pd.isnull()</code> Find the null values, True for the null <code>pd.notnull()</code> Opposite to  pd.isnull() <code>df.dropna()</code> Drop all rows that contain null values <code>df.dropna(axis=1)</code> Drop all columns that contain null values <code>df.dropna(axis=1,thresh=n)</code> Keep only the column with at least n non null values <code>df.fillna(x)</code> Replace all null values with x <code>df.fillna([\u2018A\u2019:0,\u2018B\u2019:0])</code> Replace all null values in column \u2018A\u2019, and \u2018B\u2019, with 0, 1 respectively. <code>s.fillna(s.mean())</code> Replace all null values with the mean or any other statistics you define"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#indexing_1","title":"Indexing","text":"<code>df[col]</code> Returns column with label col as Series <code>df[[col1, col2]]</code> Returns columns corresponding  col1, col2 <code>df.iloc[i,:]</code> The (i-1)th row <code>df.iloc[i,j]</code> The (i-1)th and (j-1)th element <code>s.iloc[i]</code> Return elements in position (i-1) by position <code>s.loc['index']</code> Return elements correspondingthe index"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#subsetting_1","title":"Subsetting","text":"<code>df[df[col] &lt; 1]</code> Return element less than 1 in column col <code>df[(df[col] &gt; 0.5) &amp; (df[col] &lt; 1)]</code> Return 0.5&lt; element &lt; 1 in column col"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#group-by","title":"Group by","text":"<code>df.groupby(col)</code> Group data frame based on col. <code>df.groupby(col).mean()</code> Calculate mean after grouping based on col. <code>df.groupby(col1).agg(fun)</code> Group the data frame based on col and run function on it. <code>df.pivot_table(index=col1,values=[col2,col3],aggfunc=mean)</code> Create a pivot table using index of col1 and calculates the mean (or any other function) of col2 and col3"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#apply","title":"Apply","text":"<code>df.apply(fun)</code> Apply the function fun across each column <code>df.apply(np.max,axis=1)</code> Apply the function fun across each row"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#joincombine","title":"Join/Combine","text":"<code>df1.append(df2)</code> Add the rows in df1 to the end of df2 (columns should be identical) <code>pd.concat([df1, df2],axis=1)</code> Add the columns in df1 to the end of df2 (rows index should be identical)"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#aggregate-functions_1","title":"Aggregate Functions","text":"<code>df.describe()</code> Summary statistics for numerical columns <code>df.count()</code> Returns the number of non-null values in each DataFrame column <code>df.min()</code> Returns the minimum in each column <code>df.max()</code> Returns the maximum in each column <code>df.mean()</code> Returns the mean in each column <code>df.median()</code> Returns the median in each column <code>df.std()</code> Returns the standard deviation in each column <code>df.corr()</code> Returns the correlation between columns"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#datetime","title":"Datetime","text":"<p>Datetime is built for working with date and tim.</p> <code>import datetime as dt</code> <code>pip3 install datetime</code> <code>python3 -m pip install --upgrade datetime</code> <code>now = dt.datetime.now()</code> Assigns datetime object representing the current time to now <code>wks4 = dt.datetime.timedelta(weeks=4)</code> Assigns a timedelta object representing a timespan of 4 weeks to wks4 <code>now - wks4</code> Returns a datetime object representing the time 4 weeks prior to now <code>newyear_2020 = dt.datetime(year=2020, month=12, day=31)</code> Assigns a datetime object representing December 25, 2020 to newyear_2020 <code>newyear_2020.strftime(\"%A, %b %d, %Y\")</code> Returns \"Thursday, Dec 31, 2020\" <code>dt.datetime.strptime('Dec 31, 2020',\"%b %d, %Y\")</code> Returns a datetime object representing December 31, 2020"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#back-to-top","title":"\u2b06 back to top","text":""},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#references","title":"References","text":"<p>[sw] https://swcarpentry.github.io/sql-novice-survey/  [dpo] https://docs.python.org/3.7/library/sqlite3.html  [sw2] https://swcarpentry.github.io/sql-novice-survey/10-prog/index.html  [gc] https://github.com/CoreyMSchafer/code_snippets/tree/master/Python-SQLite  [dor] https://datacarpentry.org/R-ecology-lesson/05-r-and-databases.html  [wdc] https://www.datacamp.com/community/tutorials/sqlite-in-r  [sw3] https://swcarpentry.github.io/sql-novice-survey/11-prog-R/index.html  [w3]  https://www.w3schools.com/sql/sql_create_table.asp  [wt] https://www.techonthenet.com/sql/index.php  [qlt] https://www.sqlitetutorial.net </p>"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-python-core-numpy-and-panda/#license","title":"License","text":"<p>Copyright \u00a9 2019 Saeid Amiri and Leila Alimehr</p>"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-sklearn/","title":"Cheat Sheet of Sklearn","text":""},{"location":"concise_notes/2024/10/26/cheat-sheet-of-sklearn/#sklearn","title":"Sklearn","text":"<p>Sklearn is built for general machine learning.</p> <code>import sklearn</code> <code>pip3 install sklearn</code> <code>python3 -m pip install --upgrade  sklearn</code>"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-sklearn/#training-and-test-set","title":"Training and test set","text":"<p><code>from sklearn.model_selection import train_test_split</code> ||| |---|---| <code>X_train, X_test, Y_train, Y_test =train_test_split(X,Y,test_size=.2)</code>| Split arrays or matrices to training and testing sets,  |</p>"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-sklearn/#preprocessing-data","title":"Preprocessing Data","text":"<p><code>from sklearn import preprocessing</code></p>"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-sklearn/#standardization","title":"Standardization","text":"<p>Normalize each column individually to unit norm. ||| |---|---| <code>st_scaler = preprocessing.StandardScaler().fit(X_train)</code>| Calculate the mean (m) and std (s) from X_train columns <code>stand_X = st_scaler.transform(X)</code>|  Standardize X using m and s</p>"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-sklearn/#normalization","title":"Normalization","text":"<p>Normalize row individually to unit norm.</p> <code>nr_scaler = preprocessing.Normalizer().fit(X_train)</code> Calculate the mean (m) and std (s) from X_train rows <code>normal_X = nr_scaler.transform(X)</code> Normalize X using m and s"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-sklearn/#binarization","title":"Binarization","text":"<p>Binarize the data for a given threshold.</p> <code>bn = preprocessing.Binarizer(threshold=0.0).fit(X)</code> Define binarization for a given threshold <code>bin_X = bn.transform(X)</code> Run binarization on X"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-sklearn/#encoding","title":"Encoding","text":"<p>Relabel the elements of array to integer number ||| |---|---| <code>le = preprocessing.LabelEncoder()</code>| Assign the label coding function to le  <code>y = le.fit_transform(y)</code>| Run transformation on y</p>"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-sklearn/#modeling","title":"Modeling","text":""},{"location":"concise_notes/2024/10/26/cheat-sheet-of-sklearn/#building-model","title":"Building model","text":"<p><code>from sklearn.linear_model import LinearRegression</code> ||| |---|---| <code>lr = LinearRegression(normalize=True)</code>| Create linear model| |<code>from sklearn.svm import SVC</code> <code>svc = SVC(kernel='linear')</code>| Create support vector machine for classification| |<code>from sklearn import neighbors</code> <code>knn = neighbors.KNeighborsClassifier(n_neighbors=4)</code>| Create Knn | |<code>from sklearn.cluster import KMeans</code> <code>k_means = KMeans(n_clusters=4, random_state=0)</code>| Create KMeans |</p>"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-sklearn/#fitting-model-to-data","title":"Fitting model to Data","text":"<code>lr.fit(X_train, Y_train)</code> Fit linear model <code>svc.fit(X_train, Y_train)</code> fit SVC <code>knn.fit(X_train, Y_train)</code> fit knn <code>k_means.fit(X_train)</code> Fit KMeans"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-sklearn/#predicting","title":"Predicting","text":"<code>Y_pred = lr.predict(X_test)</code> Predict using linear <code>Y_pred = svc.predict(X_test)</code> Predict using SVC <code>Y_pred = knn.predict_proba(X_test)</code> Predict using Knn <code>Y_pred = k_means.predict(X_test)</code> Predict using KMeans"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-sklearn/#evaluation","title":"Evaluation","text":""},{"location":"concise_notes/2024/10/26/cheat-sheet-of-sklearn/#linear-model","title":"Linear model","text":"<p><code>from sklearn.metrics import mean_absolute_error, mean_squared_error,r2_score</code> ||| |---|---| <code>mean_absolute_error(Y_test, Y_pred)</code>| Calculate MAE <code>mean_squared_error(Y_test, Y_pred)</code>| Calculate MSE <code>r2_score(Y_test, Y_pred)</code> | Calculate  R-square</p>"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-sklearn/#classification","title":"Classification","text":"<p><code>from sklearn.metrics import accuracy_score,classification_report,confusion_matrix</code> ||| |---|---| <code>accuracy_score(Y_test, Y_pred)</code>|Calculate accuracy| <code>classification_report(Y_test, Y_pred)</code>| Calculate different classification metrics| <code>confusion_matrix(Y_test, Y_pred)</code>| Calculate the confusion matrix</p>"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-sklearn/#clustering","title":"Clustering","text":"<p><code>from sklearn.metrics import adjusted_rand_score,homogeneity_score,v_measure_score</code> ||| |---|---| <code>adjusted_rand_score(Y_true, Y_pred)</code>|  Calculate adjusted_rand_score <code>homogeneity_score(Y_true, Y_pred)</code>| Calculate homogeneity_score <code>v_measure_score(Y_true, Y_pred)</code>| Calculate v_measure_score</p>"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-sklearn/#crosse-validation","title":"Crosse-validation","text":"<p><code>from sklearn.cross_validation import cross_val_score</code> ||| |---|---| |<code>cross_val_score(lr, X_train, Y_train, cv=2)</code>| Cross-validation on linear model |<code>cross_val_score(knn, X_train, Y_train, cv=4)</code>|Cross-validation on Knn</p>"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-sklearn/#tuning-model","title":"Tuning Model","text":""},{"location":"concise_notes/2024/10/26/cheat-sheet-of-sklearn/#grid-search","title":"Grid Search","text":"<p><code>from sklearn.grid_search import GridSearchCV</code> ||| |---|---| <code>params = {\"n_neighbors\": np.arange(1,3),\"metric\": [\"euclidean\", \"cityblock\"]}</code>| Define parameters <code>grid = GridSearchCV(estimator=knn,param_grid=params)</code>| Define estimator <code>grid.fit(X_train, y_train)</code>| Fit to training set <code>print(grid.best_score_)</code>| print the best score <code>print(grid.best_estimator_.n_neighbors)</code>| Print the estimate of parameters</p>"},{"location":"concise_notes/2024/10/26/cheat-sheet-of-sklearn/#randomized-parameter-optimization","title":"Randomized parameter optimization","text":"<p><code>from sklearn.grid_search import RandomizedSearchCV</code> ||| |---|---| <code>params = {\"n_neighbors\": range(1,5),\"weights\": [\"uniform\", \"distance\"]}</code>|  Define parameters <code>rand_search = RandomizedSearchCV(estimator=knn, param_distributions=params, cv=4, n_iter=8,random_state=5)</code>|  Define estimator <code>rand_search.fit(X_train, y_train)</code>| Fit to training set <code>print(rand_search.best_score_)</code>| print the best score <code>print(grid.best_estimator_.n_neighbors)</code>| Print the estimate of parameters</p>"},{"location":"concise_notes/2024/10/26/crosstab/","title":"Crosstab","text":"<p>To show how generate the cross tabulate, let us categorize the columns; consider two continuous variables ( e.g., housing_median_age and total_rooms), categorize them according their .3 and .7 quantiles, and label the elements as L, M, and H. Then find the cross tabulate of them,</p> <pre><code>CHT['houlev'] = ''\nC1=CHT.housing_median_age&lt;=CHT.median_income.quantile(.3)\nC2=CHT.housing_median_age&gt;=CHT.median_income.quantile(.7)\nCHT.loc[C1,'houlev']='L'\nCHT.loc[~C1&amp;~C2,'houlev']='M'\nCHT.loc[C2,'houlev']='H'\n\nCHT['roomlev'] = ''\nC1=CHT.total_rooms&lt;=CHT.total_rooms.quantile(.3)\nC2=CHT.total_rooms&gt;=CHT.total_rooms.quantile(.7)\nCHT.loc[C1,'roomlev']='L'\nCHT.loc[~C1&amp;~C2,'roomlev']='M'\nCHT.loc[C2,'roomlev']='H'\n\npd.crosstab(CHT.roomlev, CHT.houlev, margins=True)\n</code></pre> <p>You can add more than two columns.</p>"},{"location":"concise_notes/2024/10/26/data-control-structure/","title":"Data control structure","text":""},{"location":"concise_notes/2024/10/26/data-control-structure/#boolean-value","title":"Boolean value","text":"<p>The value True (T) and False (F) are referred to as logical values and used the same in Python; their corresponding values are 1 and 0. Run the following codes and explains what the codes do.</p> <pre><code>&gt;&gt;&gt; 8&lt;9\nTrue\n&gt;&gt;&gt; 9&lt;8\nFalse\n&gt;&gt;&gt; x=3\n&gt;&gt;&gt; y=9\n&gt;&gt;&gt; x&lt;y\nTrue\n&gt;&gt;&gt; x&gt;y\nFalse\n&gt;&gt;&gt;\n&gt;&gt;&gt; X=range(-3,3)\n&gt;&gt;&gt; [X[i]&lt;2 for i in range(6)]\n[True, True, True, True, True, False]\n&gt;&gt;&gt; sum([X[i]&lt;2 for i in range(6)])\n5\n&gt;&gt;&gt; sum(X)\n-3\n</code></pre> <p>One of the main application of logical operator is to extract specific elements, see the following codes,</p> <pre><code>&gt;&gt;&gt; weight=[58,89,68,74,62,77,65,65]\n&gt;&gt;&gt; [weight[i]&lt;74 for i in range(len(weight))]\n[True, False, True, False, True, False, True, True]\n&gt;&gt;&gt; weight&lt;74\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nTypeError: '&lt;' not supported between instances of 'list' and 'int'\n</code></pre> <p>Obviously <code>weight&lt;74</code> does not work for the list, To run it change the data to the array provided in Numpy:  </p> <pre><code>&gt;&gt;&gt; weight=np.array(weight)\n&gt;&gt;&gt; weight&lt;74\narray([ True, False,  True, False,  True, False,  True,True], dtype=bool)\n&gt;&gt;&gt; (weight&lt;74) &amp; (weight==89)\narray([False, False, False, False, False, False, False, False], dtype=bool)\n&gt;&gt;&gt; weight[(weight&lt;74) &amp; (weight==89)]\narray([], dtype=int64)\n&gt;&gt;&gt; weight[(weight&lt;74) &amp; (weight==62)]\narray([62])\n&gt;&gt;&gt; weight[(weight&lt;74) | (weight==62)]\narray([58, 68, 62, 65, 65])\n&gt;&gt;&gt; weight[~(weight&lt;74) &amp; (weight==62)]\narray([], dtype=int64)\n&gt;&gt;&gt; weight[~((weight&lt;74) | (weight==62))]\narray([89, 74, 77])\n</code></pre>"},{"location":"concise_notes/2024/10/26/data-control-structure/#control-structure","title":"Control Structure","text":"<p>Commands with control structure often include conditional command that use comparisons operators (&gt;, &lt;, =&gt;, &lt;=, ==, !=, ~, is)</p> <pre><code>&gt;&gt;&gt; 3&lt;4\nTrue\n&gt;&gt;&gt; 3!=4\nTrue\n&gt;&gt;&gt; 3==4\nFalse\n&gt;&gt;&gt; 3 is 4\nFalse\n&gt;&gt;&gt; 'hi' == 'h' + 'i'\nTrue\n&gt;&gt;&gt; 'HI' != 'hi'\nTrue\n&gt;&gt;&gt; [1, 2] != [2, 1]\nTrue\n&gt;&gt;&gt; ~True\n-2\n&gt;&gt;&gt; ~False\n-1\n</code></pre> <p>The structure command of if is as below. <pre><code>If cond satisfies the cons.expr run otherwise alt.expr run.\nif(cond) cons.expr elif (condition) alt.expr else alt.expr\n</code></pre></p> <pre><code>x=4\ny=4\n\nif x&lt;y: \n  print('x is less than y')\nelif x&gt;y:\n print('x greater than y')\nelse: \n print(' x and y are equal')\n</code></pre> <p>To pass the value inside the quote, use the f-string format </p> <pre><code>if x&lt;y: \n  print( f'{x} is less than {y}')\nelif x&gt;y:\n print(f'{x}greater than {y}')\nelse: \n print(f'x={x} and y={y} are equal')\n</code></pre>"},{"location":"concise_notes/2024/10/26/data-control-structure/#try-except","title":"Try except","text":"<p>When there is any possibility for error, it is better to use <code>try except</code>, which tests the statement infront try, if there is an error, it goes to except, otherwise passes and goes to else.</p> <pre><code>x='Just test'\ntry:\n  print(x)\nexcept:\n  print(\"Something went wrong\")\nelse:\n  print(\"Nothing went wrong\")\n\ntry:\n  print(y)\nexcept:\n  print(\"Something went wrong\")\nelse:\n  print(\"Nothing went wrong\")\n</code></pre>"},{"location":"concise_notes/2024/10/26/data-frame/","title":"Data-frame","text":"<p>Data-frame via pandas is very useful format for working with dataset, its structure is two-dimensional size-mutable, potentially heterogeneous tabular data structure with labeled axes (rows and columns). The following codes create a data-frame from a dictionary.  </p> <pre><code>var={\"A\": [1,2,0], \"B\": [2,3,4]}\ndf= pd.DataFrame(data=var,index=['A', 'Z', 'C'])\n</code></pre> <p>The label column can be easily changed: <pre><code>raw_data = {'population': [ 1015.0, 1129.0, 333.0,  515.0],'median_income': [ 1.5, 1.8,  1.7,  3.2]}\ndf=pd.DataFrame(raw_data, columns = ['population', 'median_income'])\n</code></pre></p> <p>In some circumstances, it is better to consider the time of collecting data as index, the following script changes the data format to the time format and save it as index. <pre><code>df = df.set_index(pd.to_datetime(['2019-04-01','2019-05-04','2019-06-01','2019-07-02']))\n</code></pre></p> <p>To create an empty data-frame, run the following <pre><code>df1=pd.DataFrame(columns = ['population', 'median_income'])\ndf2=pd.DataFrame()\n</code></pre></p> <p>Dimension of data-frame is 2 which can be seen via <code>.ndim</code>, the number of rows and columns can be obtained using   <code>.shape</code>.  </p> <pre><code>df.ndim\ndf.shape\ndf.shape[0]\ndf.shape[1]\n</code></pre>"},{"location":"concise_notes/2024/10/26/data-structure/","title":"Data Structures","text":"<p>Python provides a variety of useful data structures, such as lists, sets, and dictionaries, and a new structure define by programmer which called class.</p>"},{"location":"concise_notes/2024/10/26/data-structure/#list","title":"list","text":"<p>A list is a sequence of values that is assigned to the variable. The values in a list are called elements or sometimes items. The value of list can be accessed using the square brackets.</p> <pre><code>weights=[20,15,19,21,16] \ntype(weights)\ncolors=['red','blue','green','black','white']\ncolors\n</code></pre> <p>Use the square brackets ([]) to index it.</p> <pre><code>colors[1:3]\ncolors[:3]\ncolors[3:]\ncolors[-1]\ncolors[1]\ncolors[:-1]\ncolors[::-1]\n</code></pre> <p>The following scripts show how reverse, adds new object, and sort the elements.</p> <pre><code>colors.reverse()\ncolors\n\ncolors.extend('blue')\ncolors\n\ncolors.extend(['blue'])\ncolors\n\nsorted(colors)\ncolors.sort()\ncolors.sort(key=len)\ncolors\n</code></pre> <p>Finding the index of elements and counting them are vey simple, see below.  </p> <pre><code>colors.index('blue')\ncolors.count('blue')\n</code></pre> <p>To change the element of list use <code>replace</code>:</p> <pre><code>a = 'hello, world!'\na[2]='z'\na.replace('l', 'z', 1)\na.replace('l', 'z')\n</code></pre>"},{"location":"concise_notes/2024/10/26/data-structure/#tuple","title":"Tuple","text":"<p>Tuple is a sequence of objects like list, but it is immutable. To define tuple, Python uses the parenthesis:</p> <pre><code>&gt;&gt;&gt; colors=('red','blue','green','black','white')\n&gt;&gt;&gt; type(colors)\n&lt;class 'tuple'&gt;\n&gt;&gt;&gt; colors[1:3]\n('blue', 'green')\n</code></pre> <p>To access the content in a tuple use brackets like list. Obviously the list and tuple look the same, the objects of tuple is immutable, i.e., when it is created, it can not modified.  </p> <p><pre><code>&gt;&gt;&gt; colors[1]\n'blue'\n&gt;&gt;&gt; colors[1]='yellow'\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nTypeError: 'tuple' object does not support item assignment\n</code></pre> A brief comparison of mutable and immutable and application can be found here.</p>"},{"location":"concise_notes/2024/10/26/data-structure/#set","title":"Set","text":"<p>Set is a collection of elements without order and index, the same as defined in Algebra. Duplication of elements in set does not make sense, so Python drops the duplication automatically. Use the curly bracket ({) to create the set: <pre><code>colors={'red','blue','green','black','white'}\ntype(colors)\n</code></pre></p> <p>A new object can be added using the <code>add</code>, to add more than one objects, use <code>update</code>. To drop elements use the <code>remove</code> or <code>discard</code>, both remove elements but the  <code>discard</code> does not raise any error notification, if the element does not exist in set. <pre><code>colors.add('pink')\ncolors.update(['purple','orange'])\ncolors.remove('pink')\ncolors.remove('pink')\ncolors.discard'(pink')\n</code></pre></p> <p>To delete elements and remove the set completely, use <code>clear</code> and <code>del</code>, respectively. To see whether the element exists in set, use <code>in</code>. The functions <code>len</code> and <code>sorted</code> can be applied on set: <pre><code>'blue' in colors\nlen(colors)\nsorted(colors)\n</code></pre></p> <p>The functions <code>len</code>, <code>sorted</code>, <code>intersection</code>, <code>union</code>, and <code>difference</code> can be applied on sets: <pre><code>'blue' in colors\nlen(colors)\nsorted(colors)\n{'red','blue'}.intersection({'red','white'})\n{'red','blue'}.union({'red','white'})\n{'red','blue'}.difference({'red','white'})\n</code></pre></p>"},{"location":"concise_notes/2024/10/26/data-structure/#dictionary","title":"Dictionary","text":"<p>Dictionary is a generalized form of list, unlike the list its indices can be any type of values. A dictionary maps a set of objects (keys) to another set of objects (values).</p> <p>Dictionary includes key and items, the key is actually indices and item is the values. A Python dictionary is a mapping of unique keys to values. Use the curly brackets to construct the dictionary, separate the key and value with colons (:) and with commas (,) between each pair. Keys must be quoted. We can print out the dictionary by printing the reference to it.</p> <pre><code>prices = {\n   'BMW': 50,\n   'BENZ': 55,\n   'Ford': 25,\n   'Chevy': 30,  \n   'GM': 28\n}\n\nprices.values()\nprices.keys()\nprices.items()\n</code></pre> <p>The dictionary is very simple to manipulate, <pre><code>student={'A':10, 'B':20, 'AB':100 }\nstudent.values()\nstudent.keys()\nstudent['C']=45\nstudent[45]=34\ndel student['C']\n</code></pre></p> <p>Note, dictionaries are unordered, so the order that the keys are added doesn't necessarily reflect what order they may be reported back.</p> <pre><code>dic1={\n'x1' : 1,\n'x2' : 2,\n'x3' : 3 }\n\ndic2={\n'y1' : 10,\n'x1' : 11,\n'x2' : 2 }\n\ndic1.keys() &amp; dic2.keys()\ndic1.keys() - dic2.keys()\ndic1.items() &amp; dic2.items()\n</code></pre> <p>Example: Create a list which its elements are dictionary. </p> <pre><code>team = [\n    {\n        'name': 'Saeid',\n        'city': 'Torronto',\n    },\n    {\n        'name': 'Leila',\n        'city': 'Torronto',\n    },\n    {\n        'name': 'Ryan',\n        'city': 'Montreal',\n    },\n</code></pre>"},{"location":"concise_notes/2024/10/26/data-structure/#array","title":"Array","text":"<p>Numpy's array is a generalization of list, it is more appropriate for the computation.  </p> <pre><code>import numpy as np\nweight=[58,89,68,74,62,77,65,65]\nweight\nweight_arr=np.array(weight)\nweight_arr\n</code></pre> <p>All elements should have the same type, therefore if you add a strict element, it saves all element as strict. Array also accepts multi lists. <pre><code>arr1=np.array([range(i) for i in [1, 2, 3]])\narr1[1]\narr1[1][0]\narr2=np.array([range(i, j+i) for i in [1, 2, 3] for j in [1, 2, 3]])\narr2[1]\narr2[1][0]\n</code></pre></p> <p>To generate a constant array, use <code>np.full(,)</code> <pre><code>np.full(2, 2.2)\nnp.full((2,1), 2.2)\nnp.full((2,2), 2.2)\n</code></pre></p> <pre><code>np.arange(1,14,4)\nnp.arange(21,30,3)\nnp.arange(2,1,-0.1)\n</code></pre> <p>To create an array of k values between two values <pre><code>np.linspace(0, 1, 10)\n</code></pre></p> <p>To refer elements of array should use <code>[]</code> <pre><code>weight[1]# first element\nweight[2:]# second elements to the rest\nweight[:3]# elements before the third and including the third\n</code></pre></p> <p>To refer elements of multi array should use <code>[,]</code> <pre><code>weight2=np.array([weight_arr,2.20*weight_arr,35.27*weight_arr])\nweight2[1,1]\nweight2[1:,1:]\nweight2[1:,2:]\n</code></pre></p> <p>To change the shape, use <code>reshape</code>: <pre><code>weight2.reshape((8, 3))\n</code></pre></p>"},{"location":"concise_notes/2024/10/26/data-structure/#class","title":"Class","text":"<p>Python is an object-oriented programming language, and has strong tools working with different objects. If the structure is not defined, one can create own object; the class can be used to present new structure for your data or change the existing one. It is very useful to tie a certain data and functions together.</p> <pre><code>class body(object):\n    \"\"\"Define class\"\"\"\n    \"\"\" we can use weigt and height\"\"\"\n    def __init__(bd, weight,height):\n     bd.weight=weight\n     bd.height=height\ndef bmi_body(b):\n    print (' BMI is (%g)' %((b.weight/b.height)))\n\nSAM = body(90,79)\nSAM.weight\nSAM.height\nprint (SAM)\nbmi_body(SAM)\n</code></pre> <p>Or it can be simplified to</p> <pre><code>class body(object):\n    \"\"\"Define class\"\"\"\n    \"\"\" we can use weight and height\"\"\"\ndef bmi_body(b):\n    print (' BMI is (%g)' %((b.weight/b.height)))\n\nSAM = body()\nSAM.weight = 90\nSAM.height = 79\nprint (SAM)\nbmi_body(SAM)\n</code></pre> <p>Example: American present the data as Month/Day/Year. Write a function represent it with Canadian style.</p> <pre><code>class dateg(object):\n    \"\"\"Define class\"\"\"\n    \"\"\"Month, Day, Year \"\"\"\ndef ca_date(d):\n    print (' Canadian date is (%g/%g/%g)' %((d.day,d.month,d.year)))\n\nmybirt = dateg()\nmybirt.day = 11\nmybirt.month = 11\nmybirt.year = 11\nprint (mybirt)\nca_date(mybirt)\n</code></pre>"},{"location":"concise_notes/2024/10/26/how-to-save-all-objects/","title":"How to save all objects","text":"<pre><code>import dill\n# to save session\ndill.dump_session('backup_2021_10_22.db')\n# to load \nbackup_restore = dill.load_session('backup_2021_10_22.db')\n</code></pre>"},{"location":"concise_notes/2024/11/21/eval-function/","title":"eval Function","text":"<p>The <code>eval()</code> function evaluates the specified expression (code), and runs it. The syntax is as below</p> <pre><code>eval(expression, globals, locals)\n</code></pre> Parameter Description expression A String that will be evaluated as Python expression globals (Optional) A dictionary that holds global parameters locals (Optional) A dictionary that holds local parameters <p>Let's drop the extra quote. <pre><code>&gt;&gt;&gt; x = '\"55\"'\n&gt;&gt;&gt; eval(x)\n'55'\n</code></pre></p> <p>The following performs the specified operations: <pre><code>&gt;&gt;&gt; x = 2\n&gt;&gt;&gt; eval('x * x +3')\n7\n</code></pre></p> <p>Let's transfer a dictionary of functions and simply choose from it. <pre><code>list = {'Plus': lambda x, y: x + y, 'Minus': lambda x, y: y - x}\nprint(eval('Minus(2,8)', list))\n</code></pre></p> <pre><code>&gt;&gt;&gt; list = {'Plus': lambda x, y: x + y, 'Minus': lambda x, y: y - x}\n&gt;&gt;&gt; print(eval('Minus(2,8)', list))\n6\n</code></pre>"},{"location":"concise_notes/2024/10/26/generating-frequency/","title":"Generating frequency","text":"<p>Here we demonstrate how generate frequency table from the data. </p>"},{"location":"concise_notes/2024/10/26/generating-frequency/#data-frame","title":"Data frame","text":"<p>First creates a dataframe, then use <code>value_counts</code>, <code>groupby</code>, <code>crosstab</code>, and `pivot.  <pre><code>import numpy as np\nimport pandas as pd\n\nn = 50 \ngroup = [\"High\", \"Low\"] \nsize = [\"Small\", \"Medium\", \"Large\"] \ndata = pd.DataFrame({'Size': np.random.choice(size,n), 'Group': np.random.choice(group,n)})\n</code></pre></p>"},{"location":"concise_notes/2024/10/26/generating-frequency/#value_counts","title":"value_counts","text":"<pre><code>frq_data=data.value_counts([\"Group\", \"Size\"])\nfrq_data.to_csv('frq_data.csv', sep=',', header=True,index=True, encoding='utf8')\n</code></pre>"},{"location":"concise_notes/2024/10/26/generating-frequency/#using-groupby","title":"using groupby","text":"<pre><code>data.groupby([\"Group\", \"Size\"]).size()\ndata.groupby([\"Group\", \"Size\"]).size().reset_index(name=\"Freq\")\n</code></pre>"},{"location":"concise_notes/2024/10/26/generating-frequency/#crosstab","title":"crosstab","text":"<pre><code>pd.crosstab(data.Group,data.Size,margins = True)\npd.crosstab(data.Group,data.Size,margins = False)\n</code></pre>"},{"location":"concise_notes/2024/10/26/generating-frequency/#pivot","title":"pivot","text":"<pre><code>data.pivot_table(index=['Group','Size'], aggfunc='size')\n</code></pre>"},{"location":"concise_notes/2024/10/26/generating-frequency/#plot","title":"Plot","text":""},{"location":"concise_notes/2024/10/26/generating-frequency/#mosaic-plot","title":"Mosaic plot","text":"<pre><code>import matplotlib.pyplot as plt\nfrom statsmodels.graphics.mosaicplot import mosaic\nmosaic(data, [\"Group\", \"Size\"], title='DataFrame as Source')\nplt.show()\n</code></pre>"},{"location":"concise_notes/2024/10/26/generating-frequency/#chord-diagram","title":"Chord Diagram","text":"<pre><code>from pycirclize import Circos\nmatrix_df=pd.DataFrame(pd.crosstab(data.Group,data.Size,margins = False))\ncircos = Circos.initialize_from_matrix(\n    matrix_df,\n    space=5,\n    cmap=\"tab10\",\n    label_kws=dict(size=12),\n    link_kws=dict(ec=\"black\", lw=0.5, direction=1),\n)\ncircos.savefig(\"chroddiagram.png\")\n</code></pre>"},{"location":"concise_notes/2024/10/26/generating-frequency/#list","title":"list","text":"<pre><code>lst = ['apple', 'banana', 'apple', 'orange']\n\nfrom collections import Counter\nCounter(lst)\nCounter(data['Group'])\n\ncounts = [(word, lst.count(word) / len(lst)) for word in set(lst)] \n[{word: lst.count(word) / len(lst)} for word in set(lst)] \n\ndef relative_frequency(lst, element):\n    return lst.count(element) / float(len(lst))\n</code></pre>"},{"location":"concise_notes/2024/10/26/function-in-python/","title":"Function","text":"<p>In the context of programming, a function is a sequence of statements that performs a computation. Functions has three parts; argument, script, and output. Python has two kinds of function: built-in function that is in the core of Python or are collected as package. User-defined function that is written by user.</p>"},{"location":"concise_notes/2024/10/26/function-in-python/#built-in-function","title":"Built-in function","text":"<p>Python has a number of functions in its core that are always available, see</p> <p><pre><code>x=[1,2,3]\ntype(x)\nlen(x)\nmin(x)\n</code></pre> To round the value, use the <code>round(value,size)</code> function <pre><code>round(0.12345,2)\nround(0.12345,3)\n</code></pre></p>"},{"location":"concise_notes/2024/10/26/function-in-python/#user-function","title":"User function","text":"<p>Functions has three parts; argument, script, and output. It has simple structure</p> <pre><code>def name (argument):  \n  script\n  return output\n</code></pre> <p>For instance write a function get two argument, add them together and return it.</p> <pre><code>def sum0 (x,y):  \n  s0=x+y\n  return s0\n</code></pre> <p>If you do not specify the arguments, use a * argument, <pre><code>def sum0 (x,*y):  \n  s0=x+mean(y)\n  return s0\n</code></pre></p> <p>You can define a default value for argument. <pre><code>def sum0 (x,y=1):  \n  s0=x+y\n  return s0\n</code></pre></p> <p>You can define an optional argument. <pre><code>def sum0 (x,y=None):  \n  if y is None:\n    return x\n  elif:\n     return x+y\n</code></pre></p> <pre><code>def letterGrade(score):\n    if score &gt;= 90:\n        letter = 'A'\n    elif score &gt;= 80:\n        letter = 'B'\n    elif score &gt;= 70:\n        letter = 'C'\n    elif score &gt;= 60:\n        letter = 'D'\n    else:\n        letter = 'F'\n    return letter\n</code></pre>"},{"location":"concise_notes/2024/10/26/function-in-python/#in-line-function","title":"In-line function","text":"<p>A simple function can be written in one line, <pre><code>sum0 = lambda x, y: x + y\nsum0(2,3)\n</code></pre></p> <p>Such function is more suitable for using inside the other operation, the follow get first and second name, then it sort according the last name.   ``` names = ['Sam Amiri', 'Leila Alimehr','Ryan Amiri'] sorted(names, key=lambda name: name.split()[-1].lower())</p> <p>sorted(names, key=lambda name: name.split()[-1].lower()) ['Leila Alimehr', 'Sam Amiri', 'Ryan Amiri'] sorted(names) ['Leila Alimehr', 'Ryan Amiri', 'Sam Amiri'] <pre><code>## Map and Filter\nPython access to a higher order function  which allows a function operates on other functions, either by taking a function as its argument, or by returning a function. Most popular ones are ```map``` (apply function on element) and ```filter ``` (apply function, if it is true return element)\n ```\nx=[-1,0,1]\nlist(map(abs, x))\nlist(filter(lambda x: x &lt;= 0,x))\n ```\n\nExample: Write a function to divide two number, if the denominator is zero, stop the function and give an notification. \n</code></pre> def divide(x, y):   try:     x / y   except:     print('Can not divide by zero!')   else:    return x / y</p> <p>divide(3,1) divide(3,0) <pre><code>The function is also can be rewritten using ```raise```, which raise an error and stop the function. \n\ndef divide(x, y):\n    \"\"\"Divide Function\"\"\"\n    if y == 0:\n        raise Exception('Can not divide by zero!')\n    return x / y\n\n\n## Decorators\nDecoreators in Python allows you to take a function and add additional uses without modifying its structure, the following example is from [ref](https://realpython.com/primer-on-python-decorators/#functions)\n```{Python, echo = FALSE, message = FALSE}\ndef my_decorator(func):\n   def wrapper():\n       print(\"Something is happening before the function is called.\")\n       func()\n       print(\"Something is happening after the function is called.\")\n   return wrapper\n\ndef say_whee():\n   print(\"Whee!\")\n\nsay_whee()\n\nsay_whee = my_decorator(say_whee)\nsay_whee()   \n</code></pre></p> <p>The decorator often simplify using <code>@name of decorator</code> <pre><code>def say_whee():\n   print(\"Whee!\")\n</code></pre></p>"},{"location":"concise_notes/2024/10/27/how-generate-variable-name-using-loop-item/","title":"How generate variable name using loop item","text":"<p>If you need to create the variable name using the loop object, use <code>exec</code>. </p> <p>The exec() function executes dynamically created Python code, which can be provided as either a string or a code object: <pre><code>for i in range(4):\n    exec(f'var_{i} = [range(i)]')\n</code></pre></p> <p>I personally prefer using the dictionary object instead the variable.  <pre><code>var={}\nfor i in range(4):\n    var[f'var_{i}']=range(i)\n</code></pre></p>"},{"location":"concise_notes/2024/11/21/global-variables-in-imported-module/","title":"Global variables in imported module","text":"<p>If you want to handle a global variable in an imported module, simply add it to the builtin module. Let's assume that <code>VAR</code> is a global variable in the <code>fun1</code> function within the test module:</p> <pre><code>import builtins\nimport test\nbuiltins.VAR = 3\ntest.fun1()\n</code></pre>"},{"location":"concise_notes/2024/10/26/iteration/","title":"Iteration","text":"<p>Python is equipped with strong tools for the repeat of some commands or produce sequence number.  </p>"},{"location":"concise_notes/2024/10/26/iteration/#range","title":"Range","text":"<p>The function <code>range</code> can be used to produce series of number between two numbers. <pre><code>range(3,15)\n</code></pre></p> <p>The advance function of <code>range</code> is <code>arange</code> in <code>numpy</code> which can be used to generate a series of number from a number to another number with specific increment:</p> <pre><code>&gt;&gt;&gt; np.arange(8, 20,1)\narray([ 8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n&gt;&gt;&gt; np.arange(2,1,-0.1)\narray([ 2. ,  1.9,  1.8,  1.7,  1.6,  1.5,  1.4,  1.3,  1.2,  1.1])\n</code></pre> <p>A specified element can be repeated for specific number.</p> <pre><code>&gt;&gt;&gt; [2,3]*2\n[2, 3, 2, 3]\n&gt;&gt;&gt; np.repeat([2, 3],[2,3])\narray([2, 2, 3, 3, 3])\n&gt;&gt;&gt; np.repeat([\"A\", \"B\"],[2,3])\narray(['A', 'A', 'B', 'B', 'B'],dtype='&lt;U1')\n</code></pre>"},{"location":"concise_notes/2024/10/26/iteration/#for","title":"For","text":"<p>The most useful function for the iteration is <code>for</code>  that repeats the specified commands for specified times, run the following codes to see how does it work</p> <pre><code>&gt;&gt;&gt; for r in range(1,5):\n...  print(r^3)\n...\n2\n1\n0\n7\n\n &gt;&gt;&gt; for i in [2,3,1,7]:\n...  print(i^3)\n...\n1\n0\n2\n4\n</code></pre> <pre><code>&gt;&gt;&gt; score=[10, 15, 7, 20]\n&gt;&gt;&gt; for i in (range(0,4)):\n...  if (score[i]&lt;10):\n...       print(\"fail\")\n...  else:\n...        print(\"pass\")\n...\npass\npass\nfail\npass\n</code></pre> <pre><code>&gt;&gt;&gt; for i in range(0,4):\n...   if score[i]&lt;10:\n...       print(\"fail\")\n...   elif(score[i]&gt;=10&amp;score[i]&lt;14):\n...       print(\"middle\")\n...   elif(score[i]&gt;=14&amp;score[i]&lt;17):\n...        print(\"good\")\n...   elif(score[i]&gt;=17):\n...       print(\"BEST\")\n...\nmiddle\nmiddle\nfail\nmiddle\n</code></pre>"},{"location":"concise_notes/2024/10/26/iteration/#while","title":"While","text":"<p>The command <code>while</code> runs iteration until the condition be attained,</p> <pre><code>&gt;&gt;&gt; x=8\n&gt;&gt;&gt; i=0\n&gt;&gt;&gt; while(x&lt;12):\n...   i=i+1\n...   x=x+x/8\n...   print(i,x)\n...\n1 9.0\n2 10.125\n3 11.390625\n4 12.814453125\n</code></pre> <p>Inversely, the command of repeat continue until the condition situated inside commands be attained, in the following codes, the loop continues until the condition <code>(x&gt;12)</code>  is violated.</p> <pre><code>&gt;&gt;&gt; x=8\n&gt;&gt;&gt; i=0\n&gt;&gt;&gt; while True:\n...  i=i+1\n...  x=x+x/8\n...  print(i,x)\n...  if (x&gt;12):\n...    break\n...\n1 9.0\n2 10.125\n3 11.390625\n4 12.814453125\n</code></pre>"},{"location":"concise_notes/2024/10/26/iteration/#comprehension-structure","title":"Comprehension structure","text":"<p>Comprehension structure in Python helps to combine several iteration in one line, to practice let write a simple function to select pair of unequal numbers between (1, 100).</p> <pre><code>combs=[]\nfor x in range(3):\n for y in range(3):\n  if x!= y:\n    combs.append((x,y))\n</code></pre> <p>The code can be simplify as list comprehension <pre><code>[(x,y) for x in range(3) for y in range(3) if x!=y]\n</code></pre></p> <p>Comprehension structure can be used for different Python structures, see the following script that generates numbers between (1,10) and put them in different Python structures.  </p> <pre><code># A generator expression\n\nprint ((x for x in range(10)))\n\n# A list comprehension\nprint ([x for x in range(10)])\n\n# A set comprehension\nprint ({x for x in range(10)})\n\n# A dictionary comprehension\nprint ({x: x for x in range(10)})\n</code></pre> <p>\u2b06 back to top</p>"},{"location":"concise_notes/2024/10/26/iteration/#license","title":"License","text":"<p>Copyright \u00a9 2019 Saeid Amiri</p>"},{"location":"concise_notes/2024/10/26/manipulating-data-frame/","title":"Manipulating data-frame","text":"<p>To select the data use the name of variable, or specify the indices via <code>.iloc</code> and <code>.loc</code> (link)[http://pandas.pydata.org/pandas-docs/version/0.22/indexing.html].  <code>.iloc</code> is an integer-based select and should be used with integer indies. On contrary, <code>.loc</code>   is primarily label based, and may also be used with a boolean array.</p> <pre><code>source =\"https://storage.googleapis.com/mledu-datasets/california_housing_train.csv\"\nCHT = pd.read_csv(source, sep=\",\")\nCHT.head()\nCHT.longitude\nCHT['longitude']\nCHT.iloc[:,1]\nCHT.iloc[:,[1,3]]\n</code></pre> <p>To select part of row, you can also use iloc[idenx of row,:], also rows can be selected using the logical values</p> <pre><code>CHT.iloc[2:10]\nCHT.iloc[2:10,:]\nCHT[CHT.iloc[:,1]&lt;34]\n</code></pre> <p>To retieve part of row, should pass boolean variable, <code>.iloc</code> does not work with the boolean variable, and <code>.loc</code> should be used.  Consider the median_income in our data, by using quartile divide it into three categories. <pre><code>CHT['famlev'] = ''\nC1=CHT.median_income&lt;=CHT.median_income.quantile(.3)\nC2=CHT.median_income&gt;=CHT.median_income.quantile(.7)\nCHT.loc[C1,'famlev']='L'\nCHT.loc[~C1&amp;~C2,'famlev']='M'\nCHT.loc[C2,'famlev']='H'\n</code></pre></p> <p>In this case we used <code>.loc</code>, obviously we specify column labels to retrieve columns instead of by position. Note: You can also using [][] apply different conditions on data.  </p> <pre><code>CHT['median_house_value'][CHT['famlev'] == 'M'].mean()\n</code></pre> <p>Selecting or searching can also be done using <code>np.where</code>,  which evaluates the conditions and return the data that satisfy the conditions. <pre><code>CHT_R=CHT[['total_rooms','total_bedrooms']]\nCHT_R.where(CHT.total_rooms&lt;1000)\nCHT_R.where(CHT.total_rooms&lt;1000,0)\ncon= CHT_R&lt;1000\nCHT_R.where(con, -999)\n</code></pre></p> <p>If you want to select specific elements in data-frame, use <code>.isin()</code>,  the following select element where 'famlev=M', <code>np.where(CHT.loc[:,'famlev'].isin(['M']))</code></p> <p>The <code>np.where</code> can be used to create a new column:</p> <p><pre><code>CHT['size']=np.where(CHT.total_rooms&lt;1000, 'small', 'big')\nCHT_R=CHT[['total_rooms','total_bedrooms']]\nCHT_R.where(CHT.total_rooms&lt;1000)\nCHT_R.where(CHT.total_rooms&lt;1000,0)\ncon= CHT_R&lt;1000\nCHT_R.where(con, -999)\n</code></pre> Opposite of <code>np.where</code> is <code>np.mask</code>, replace it with <code>np.where</code> and rerun the codes.  To drop row and columns use <code>.drop</code>. <pre><code>CHT.drop([0,5], axis=0)\nCHT.drop('longitude',axis=1, inplace=True)\n</code></pre></p> <p>To replace values, use <code>df.replace()</code></p> <pre><code>CHT['famlev'].replace('L','Low').replace('M','Middle').replace('H','High')\nCHT.drop('longitude',axis=1, inplace=True)\n</code></pre> <p>Note: the argument <code>inplace=True</code> apply the change on the original data.</p> <p>Simple operation using the list comprehension can be done on data-frame as well. ``` CHT['NN']=[0 for x in CHT['total_rooms'] if x&lt;100] CHT['size']=['small' if x&lt;100  else 'big'  for x in CHT['total_rooms']]</p>"},{"location":"concise_notes/2024/10/26/merging-data-frame/","title":"Merging data-frames","text":"<p>Panada is very useful for merging dataset; to merging data consider the following data sets, where 'id1' and 'id2' include the ids of data.</p> <pre><code>raw_data = {'id1': range(4),'income': [10,12,14,16]}\ndat1 =pd.DataFrame(raw_data, columns = ['id1', 'income'])\n\nraw_data = {'id2': range(6),'pay': [9,11,13,15,17,19]}\ndat2 =pd.DataFrame(raw_data, columns = ['id2', 'pay'])\n</code></pre> <p>Obviously the id variables are not the same, they can be compared using</p> <pre><code>dat1['id1'].isin(dat2['id2']).value_counts()\ndat2['id2'].isin(dat1['id1']).value_counts()\n</code></pre> <p><code>pd.merge</code> can merge different data-frames, the merging can be done based on the identities of left dataset, if there is no match in the right file, Python adds <code>NaN</code>.</p> <p><pre><code>result = pd.merge(dat1, dat2, left_on='id1', right_on='id2',how='left')\n</code></pre> On contrary, one can the right dataset as matching,</p> <pre><code>result = pd.merge(dat1, dat2, left_on='id1', right_on='id2',how='right')\n</code></pre> <p>Since the ids are not the same, one can do merging based on the intersection of the ids,</p> <pre><code>result = pd.merge(dat1, dat2, left_on='id1', right_on='id2',how='inner')\n</code></pre> <p>Merging can also be done based on the union of the ids,</p> <pre><code>result = pd.merge(dat1, dat2, left_on='id1', right_on='id2',how='outer')\n</code></pre> <p>Note: If the names of id variables are the same in the both datasets, you can use <code>on=id_name</code> instead of <code>left_on=</code> and <code>right_on=</code>.</p> <p>Note: if you want to identify where the elements in rows are from, add  argument <code>indicator=True</code>, then new column named <code>_merge</code> would be added to the merged data which shows its originate.</p> <pre><code>result = pd.merge(dat1, dat2, left_on='id1', right_on='id2',how='outer', indicator=True)\n</code></pre> <p>To combine datasets row-wisely, use <code>concat</code>, <pre><code>result = pd.concat([dat1, dat2],axis=1)\n</code></pre></p>"},{"location":"concise_notes/2024/10/26/how-find-most-most-unique-item/","title":"How find most most unique item","text":"<p>If you need to count of each unique item from an object, use module <code>collections</code> module, the following code return the 3 most common items from the given object: <pre><code>from collections import Counter\nc = Counter(l)\nc.most_common(3)\n</code></pre></p>"},{"location":"concise_notes/2024/10/26/adding-new-column-to-data-frame/","title":"Adding new column to data-frame","text":"<p>A column can easily be added to data-frame</p> <pre><code>df0=pd.DataFrame([38,40,25,33])\ndf['Ave_hour']=df0\n</code></pre> <p>Using <code>assign()</code> can also add new columns, new columns can be generated using functions, see below <pre><code>df=df.assign(Ave_hour=df0)\ndf=df.assign(PI1=lambda x: x['population']*x['median_income'],PI2=df['population']/df['median_income'] )\n</code></pre></p> <p>A new column can be added to data-frame <pre><code>df.columns=['population1','median_income','Ave_hour','PI1','PI2']\ndf=df.rename(columns={'population1': 'pop', 'median_income': 'med_income'})\n</code></pre></p>"},{"location":"concise_notes/2024/10/26/pipeline/","title":"Pipeline","text":"<p>Pipeline in Pandas allows to build a sequence of function to run in order on data-frame.</p> <pre><code>source =\"https://storage.googleapis.com/mledu-datasets/california_housing_train.csv\"\nCHT = pd.read_csv(source, sep=\",\")\n\ndef categ(x,col):\n  x[col].quantile(.3)\n  x['lev'] = ''\n  C1=x[col]&lt;=x[col].quantile(.3)\n  C2=x[col]&gt;=x[col].quantile(.7)\n  x.loc[C1,'famlev']=0\n  x.loc[~C1&amp;~C2,'famlev']=1\n  x.loc[C2,'famlev']=2\n  return x\n\ndef cv(x):\n return (np.mean(x)/np.var(x))\n\nCHT.pipe(cv)\nCHT.pipe(categ, col='median_income').pipe(cv)\n</code></pre>"},{"location":"concise_notes/2024/10/26/introductory-notes-on-plot/","title":"Introductory Notes on plot","text":""},{"location":"concise_notes/2024/10/26/introductory-notes-on-plot/#matplotlib","title":"Matplotlib","text":"<p>Python has very advanced tools for plotting, the plot (pyplot) can be done in two different ways; 1) Pythonic: in this approach an empty object oriented is created and plots are built using programs and assigned to the empty object, and 2) non-pythonic: it relies on non-python machines like the package  <code>matplotlib</code>,  it is very easy to use and good tools for interactive use. A standard shorthands for this module is <code>import matplotlib.pyplot as plt</code>. </p>"},{"location":"concise_notes/2024/10/26/introductory-notes-on-plot/#scatter-plot","title":"Scatter plot","text":"<p>The most commonly used plot is the scatter plot, see the following scripts that generate random number and plot</p> <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nn = 100\nx = 2 * np.random.rand(n)\ny=2*x+np.random.rand(n)\nplt.scatter(x, y)\nplt.show(block=False)\n</code></pre> <p></p> <p>The scatter plot can be presented using different arguments, the size of point, colour, marker different character for points. <pre><code>colors = np.random.rand(n)\nplt.scatter(x, y, s=20 /(x+.4)**2 , c=colors, marker=\"s\")\nplt.show(block=False)\n</code></pre> Now highlight points that  <pre><code>xy=x**2+y**2\nselect=xy&lt;1\nplt.scatter(x, y, alpha=0.3)\nplt.scatter(x[select], y[select],facecolor='none',edgecolors='r')\nplt.show()\n</code></pre> </p>"},{"location":"concise_notes/2024/10/26/introductory-notes-on-plot/#line","title":"line","text":"<p>Using <code>plt.plot</code> can plot the line, to explain let consider timesries:  <pre><code>import pandas as pd \nx=pd.period_range('2019-11-06', periods=12*10,freq='M').to_timestamp()\ny = np.random.randn(len(x)).cumsum()\ny=abs(min(y))+y\nplt.plot(x, y, label='ED')\nplt.title('Example Data') \nplt.xlabel('Date') \nplt.ylabel('Y')\nplt.grid(True)\nplt.figtext(1,0, 'note',ha='right', va='bottom')\nplt.legend(loc='best', framealpha=0.5,prop={'size':'small'})\nplt.tight_layout(pad=1)\nplt.gcf().set_size_inches(10, 5)\nplt.show(block=False)\nplt.close()\n</code></pre></p> <p>&lt; img src=\"https://raw.githubusercontent.com/saeidamiri1/myblog/master/public/image/Figure-2019-12-30-plot-3.png\" width=\"350\" height=\"300\" &gt;</p> <p>Example: Write a function to plot the following function $$ f(x) =   \\begin{cases}     sin(x),       &amp; x\\leq \\pi/2,\\     cos(x)  &amp; x&gt; \\pi/2.\\   \\end{cases} $$</p> <p><pre><code>x=np.arange(0,np.pi,np.pi/100)\ny=np.where(x&lt;np.pi/2,np.cos(x),np.sin(x))\nplt.plot(x,y)\n</code></pre> </p> <p>The other approach is to use two function instead one, it can be done using the following script,   </p> <p><pre><code>x=np.arange(0,np.pi,np.pi/100)\ny=np.where(x&lt;np.pi/2,np.cos(x),np.sin(x))\nx0=x[x&lt;np.pi/2]\nplt.plot(x0,np.cos(x0), linestyle='--',label='cos(x)')\nplt.axis([0,np.pi,0,1])\nx1=x[(x&gt;=np.pi/2)]\nplt.plot(x1,np.sin(x1), linestyle='--',label='sin(x)')\nplt.legend()\n# it can be done using\n# plt.plot(x0,np.cos(x0), '--',x1,np.sin(x1), '--')\n</code></pre> </p> <p>The argument <code>plt.axis()</code> defines axes limits, it can also be done using  <code>plt.xlim(,)</code>, <code>plt.ylim(,)</code>.  The style of line is define in <code>'--'</code>, other styles are</p> <p>Type|   Description --- | --- | '-' or 'solid'| solid line '--' or 'dashed'|   dashed line '-.' or 'dashdot'|  dash-dotted line ':' or 'dotted'|    dotted line 'None' or ' '   |   draw nothing</p> <p>There are more options for axis, for instance <code>plt.axis('equal')</code>  and  <code>plt.axis('tight')</code>.</p> <p>The labels and title can be added to plot using <code>plt.axes()</code>,  <pre><code>plt.axes(xlim=(0, 10), ylim=(-2, 2),xlabel='x', ylabel='sin(x)', title='A Simple Plot')\nplt.plot(x, np.sin(x), '-')\nplt.show(block=False)\n</code></pre></p> <p>The following plot lines with different markers</p> <p><pre><code>n = 15\nlinestyles = ['-', '--', '-.', ':']\nmarkers = list('ov^&lt;&gt;8sp*hHDdPX')\nx = np.linspace(0, 100, 10)\nfor i in range(n): \n  y = x + x/5*i + i\n  st = linestyles[i % len(linestyles)]\n  ma = markers[i % len(markers)] \n  plt.plot(x, y,label='Line '+str(i+1)+' '+st+ma, marker=ma,linestyle=st)\n\nplt.grid(True)\nplt.axis('tight')\nplt.legend(loc='best', prop={'size':'small'}) \nplt.show(block=False)\n</code></pre> </p> <p>The legend can be moved to different positions. <pre><code>plt.legend(bbox_to_anchor=(1, 0.5), loc='center left', prop={'size':'small'}) \nplt.legend(bbox_to_anchor=(0.5, -0.05),loc='upper center', ncol=8, prop={'size':'small'})\n</code></pre> </p> <p></p> <p>Note: if you want to save the figure to a file, put the script between <pre><code>fig = plt.figure()\nfig.savefig('name.png')\n</code></pre></p>"},{"location":"concise_notes/2024/10/26/introductory-notes-on-plot/#subplot","title":"subplot","text":"<p>Figures can be plotted in one figure using <code>.subplot(#row,#col,position)</code>, </p> <p><pre><code>x = np.linspace(0, 16, 800)\nplt.subplot(2, 2, 1)\nplt.plot(x, np.sin(x))\nplt.title(\"Fig1\")\nplt.xlim(0,1.5*np.pi)\nplt.xlabel(\"X-axis\")\nplt.ylabel(\"sin(x)\")\nplt.subplot(2, 2, 2)\nplt.plot(x, np.cos(x))\nplt.subplot(2, 2, 3)\nplt.plot(x, np.sin(x)*np.cos(x))\nplt.subplot(2, 2, 4)\nplt.plot(x, np.sin(x)+np.cos(x))\nplt.show(block=False)\n</code></pre> </p> <p>You can not use <code>plt.axes()</code> for subplot. </p> <p>Example: Fit a linear model to a sample data. <pre><code>x = np.random.randn(100)\ny = x + np.random.randn(100)\nfig, ax = plt.subplots() \nax.scatter(x, y, alpha=0.5, color='orchid') \nfig.suptitle('Scatter Plot') \nfig.tight_layout(pad=2);\nax.grid(True)\nfit = np.polyfit(x, y, deg=1) \nax.plot(x, fit[0]*x + fit[1], '-',color='red', linewidth=2)\n</code></pre> </p>"},{"location":"concise_notes/2024/10/26/introductory-notes-on-plot/#pythonic-approach","title":"Pythonic approach","text":"<p>The following codes show how pythonic approach can be applied to generate several plots; first generate an empty figure from the global Figure factory, then generate your plots and assign to figure. </p> <pre><code>fig = plt.figure()\nfor i in range(1,10):\n  x=pd.period_range('2019-11-06', periods=12*10,freq='M').to_timestamp()\n  y = np.random.randn(len(x)).cumsum()\n  y=abs(min(y))+y\n  plt.plot(x, y, label='ED%s'%i)\n  plt.title('Example Data') \n  plt.xlabel('Date') \n  plt.ylabel('Y')\n  plt.grid(True)\n  plt.legend(loc='best', framealpha=0.5,prop={'size':'small'})\n  fig = plt.figure(i) # get the figure\nplt.show(block=False)\n</code></pre> <p>you can close figures according the number <code>plt.close(fig.number)</code>,  all figures <code>plt.close(all)</code>,  ro the current one <code>plt.close()</code></p>"},{"location":"concise_notes/2024/10/26/introductory-notes-on-plot/#plotnine","title":"Plotnine","text":"<p><code>Plotnine</code> is actually a implemetation of R's <code>ggplot2</code> which has strong tool. The following codes  show the scatter plot using qqplot2</p> <pre><code>import plotnine as p9\nscat_plot = (p9.ggplot(mapping=p9.aes(x=x, y=y,color=colors))\n+ p9.geom_point()\n+ p9.geom_jitter(alpha=0.1, color=\"green\")\n+ p9.xlab(\"X-axis\") + p9.ylab(\"Y-axis\")\n)\nscat_plot\nscat_plot.save(\"scatterplot.png\", width=10, height=10, dpi=400)\n</code></pre>"},{"location":"concise_notes/2024/10/26/summarizing-data-frame/","title":"Summarizing data-frame","text":"<p>To see the type, the information and summary of variables in the data-frame, use <code>.dtypes</code>,  <code>.describe()</code>, and   <code>.info()</code>. </p> <pre><code>source =\"https://storage.googleapis.com/mledu-datasets/california_housing_train.csv\"\nCHT = pd.read_csv(source, sep=\",\")\n# show the type of variables\nCHT.dtypes\n# generate summary\nCHT.describe()\nCHT.info()\n</code></pre> <p>Beside the function print, pandas can show the first and the last part of data, using <code>.head()</code> and <code>.tail()</code>. By passing a number in the parenthesis, one can specify the output.</p> <pre><code>CHT.head(10)\nCHT.tail(10)\nCHT.sort_values(by='housing_median_age', ascending=False).head(3)\nCHT.columns\n</code></pre> <p>It is easy to find the duplicates in data-frame  and  drop them, see below. <pre><code>CHT.duplicated()\nCHT.drop_duplicates()\n</code></pre> To check the duplication in variables, specify their names as well,  <pre><code>CHT.duplicated(['longitude'])\nCHT.drop_duplicates(['longitude'], keep='last')\nCHT.index.duplicated()\n</code></pre></p> <p>Although <code>.describe</code> can give a summary of variables,  more specific summery of variables (columns) can be extracted, see below.</p> <pre><code>CHT.count()\nCHT[CHT.iloc[:,1]&lt;34].nunique()\n</code></pre> <p>The following table includes the useful functions.</p> Function Description <code>count</code> Number of non-null observations <code>sum</code> Sum of values <code>mean</code> Mean of value <code>mad</code> Mean absolute deviation <code>median</code> median of values <code>min</code> Minimum <code>max</code> Maximum <code>mode</code> Mode <code>abs</code> Absolute Value <code>prod</code> Product of values <code>std</code> Unbiased standard deviation <code>var</code> Unbiased variance <code>sem</code> Unbiased standard error of the mean <code>skew</code> Unbiased skewness (3<sup>rd</sup> moment) <code>kurt</code> Unbiased kurtosis (4<sup>th</sup> moment) <code>quantile</code> Sample quantile (value at %) <code>cumsum</code> Cumulative sum <code>cumprod</code> Cumulative product <code>cummax</code> Cumulative maximum <code>cummin</code> Cumulative minimum <code>nunique</code> number of unique elements <code>value_counts</code> Counts of unique values <code>cov</code> Calculate the covariance between columns <code>corr</code> Calculate the correlation between columns <p>The summaries can be obtained using any grouping variables in the data set:</p> <pre><code>CHT.groupby(['famlev']).groups.keys()\nCHT.groupby(['famlev']).groups['H']\nCHT.groupby(['famlev']).first()\n\nCHT.groupby(['famlev']).sum()\n\nCHT.groupby(['famlev'])['median_house_value'].sum()\n# better output\nCHT.groupby(['famlev'])[['median_house_value']].sum()\n</code></pre> <p>The grouped variables would be assigned as indices, to bring them back as variables use <code>df.reset_index()</code> <pre><code>CHT.reset_index()\n</code></pre></p> <p>It is possible to apply even complex function, the following scripts calculate the coefficient of data.</p> <pre><code>def cv(x):\n return (np.mean(x)/np.var(x))\n\naggr = {\n    'total_rooms':'sum',\n    'population': lambda x: cv(x)\n}\nCHT.groupby('famlev').agg(aggr)\n</code></pre> <p>The output can be tidied up,</p> <pre><code>aggr = {\n    'total_rooms':['mean','std']\n}\ngrouped = CHT.groupby('famlev').agg(aggr)\ngrouped.columns = grouped.columns.droplevel(level=0)\ngrouped.rename(columns={\"mean\": \"total_rooms\", \"std\": \"total_rooms\"})\ngrouped.head()\n</code></pre> <p>The summarizations can be done using pivot table,  <pre><code>pd.pivot_table(CHT, index=['famlev'], aggfunc=['mean'])\n</code></pre></p>"},{"location":"python_projects/overview/","title":"Overview","text":"<p>Python projects </p>"},{"location":"python_projects/posts/crime-mtl-pattern/","title":"A Dive into Montreal Crime Pattern","text":"<p>Last year, someone broke our car's window parked inside the parking and took some stuff, I though, it is good idea to look at the rubbing data in Montreal where we have been living. </p> <p>Montreal is one of the AI hub city, and provides open data open data to accessible for every one. Amazingly Montreal police has also been releasing detailed data, which can be used to explore this multicultural city. The analysis was completed using data from the website and R. The following analyses show the criminal hotspots and concentrations. </p>"},{"location":"python_projects/posts/crime-mtl-pattern/#contents","title":"Contents","text":"<ul> <li>Import data</li> <li>Pattern through years</li> <li>Spread of breaking into house</li> <li>Pattern over day</li> <li>Pattern over night</li> <li>Pattern over evenin</li> </ul>"},{"location":"python_projects/posts/crime-mtl-pattern/#import-data","title":"Import data","text":"<pre><code># Load the data Montreal and prepare \ncrime_mtl&lt;- read.csv(\"https://data.montreal.ca/dataset/5829b5b0-ea6f-476f-be94-bc2b8797769a/resource/c6f482bf-bf0f-4960-8b2f-9982c211addd/download/interventionscitoyendo.csv\", header = TRUE)\n\ncrime_mtl$CATEGORIE[crime_mtl$CATEGORIE==\"Infractions entrainant la mort\"]&lt;-\"resulting_in_death\"\ncrime_mtl$CATEGORIE[crime_mtl$CATEGORIE==\"Introduction\"]&lt;-\"breaking_into_house\"\ncrime_mtl$CATEGORIE[crime_mtl$CATEGORIE==\"M\\xe9fait\"]&lt;-\"mischief\"\ncrime_mtl$CATEGORIE[crime_mtl$CATEGORIE==\"Vol dans / sur v\\xe9hicule \\xe0 moteur\"]&lt;-\"theft_of_vehicle_part\"\ncrime_mtl$CATEGORIE[crime_mtl$CATEGORIE==\"Vol de v\\xe9hicule \\xe0 moteur\"]&lt;-\"vehicle\"\ncrime_mtl$CATEGORIE[crime_mtl$CATEGORIE==\"Vols qualifi\\xe9s\"]&lt;-\"other types of robbery\"\nknitr::kable(crime_mtl[1:5,])\n</code></pre> CATEGORIE DATE QUART PDQ X Y LONGITUDE LATITUDE vehicle 2018-09-13 jour 30 294904.2 5047549 -73.62678 45.56778 vehicle 2018-04-30 jour 30 294904.2 5047549 -73.62678 45.56778 vehicle 2018-09-01 nuit 7 290274.6 5042150 -73.68593 45.51912 mischief 2017-07-21 jour 21 0.0 0 -76.23729 0.00000 mischief 2017-07-29 jour 12 0.0 0 -76.23729 0.00000 <p>The data includes:  </p> <ul> <li>breaking_into_house(Fr: Introduction) : breaking and entering a public establishment or a private residence, theft of a firearm from a residence.</li> <li>theft_of_vehicle_part(Fr: Vol dans / sur v\u00e9hicule \u00e0 moteur) : theft of the contents of a motor vehicle (car, truck, motorcycle, etc.) or of a vehicle part (wheel, bumper, etc.).</li> <li>vehicle (Fr:Vol de v\u00e9hicule \u00e0 moteur) : car, truck, motorcycle theft, snowmobile tractor with or without trailer, construction or farm vehicle, all-terrain.</li> <li>mischie(Fr: M\u00e9fait): Graffiti and damage to religious property, vehicle or general damage and all other types of mischief. Vol qualifi\u00e9 : Robbery accompanied by commercial violence, financial institution, person, handbag, armored vehicle, vehicle, firearm, and all other types of robbery.</li> <li>resulting_in_death(Fr: Infraction entra\u00eenant la mort): First degree murder, second degree murder, manslaughter, infanticide, criminal negligence, and all other types of offenses resulting in death.</li> </ul>"},{"location":"python_projects/posts/crime-mtl-pattern/#pattern-through-years","title":"Pattern through years","text":"<p>It might also be interesting to see if the percentage changed through year, the following code provides the table of interest.  </p> <pre><code>per_year&lt;-matrix(,nrow=7,ncol=6)\ndat_cat&lt;-table(substring((crime_mtl$DATE),1,4), crime_mtl$CATEGORIE)\nfor (i in 1:6){\n per_year[,i]&lt;-t(prop.table(t(dat_cat[,i])))\n}\nrownames(per_year)&lt;-rownames(dat_cat)\ncolnames(per_year)&lt;-colnames(dat_cat)\n\nknitr::kable(per_year)\n</code></pre> breaking_into_house mischief other types of robbery resulting_in_death theft_of_vehicle_part vehicle 2015 0.1842427 0.1812778 0.1785289 0.1525424 0.1802642 0.1412043 2016 0.1842615 0.1606465 0.1680572 0.1299435 0.1686045 0.1390949 2017 0.1729767 0.1584120 0.1575856 0.1468927 0.1578200 0.1512401 2018 0.1397243 0.1395379 0.1355355 0.1751412 0.1431214 0.1354193 2019 0.1314112 0.1338757 0.1519666 0.1355932 0.1324195 0.1332779 2020 0.1139198 0.1273240 0.1191044 0.1468927 0.1222626 0.1504091 2021 0.0734639 0.0989261 0.0892219 0.1129944 0.0955078 0.1493544 <p>Here we are interested in exploring the pattern of  breaking and entering a public establishment or a private residence, so we drop unrelated crime. </p> <pre><code>crime_mtl_b &lt;- subset(crime_mtl,CATEGORIE == \"breaking_into_house\")\ncrime_mtl_b&lt;-crime_mtl_b[crime_mtl_b$LAT&gt;1,]\n</code></pre> <p>The scatter plot over year shows there has been a decline which is a very good news. </p> <pre><code>suppressMessages(library(tidyverse))\nsuppressMessages(library(xts))\nsuppressMessages(library(lubridate))\nsuppressMessages(library(dygraphs)) \n\ncrime_mtl_bj&lt;-crime_mtl_b[crime_mtl_b$QUART=='jour',]\ncrime_mtl_bj_count &lt;- crime_mtl_bj %&gt;%\n  group_by(DATE) %&gt;% \n  summarise(count = n())\n\ncrime_mtl_bn&lt;-crime_mtl_b[crime_mtl_b$QUART=='nuit',]\ncrime_mtl_bn_count &lt;- crime_mtl_bn %&gt;%\n  group_by(DATE) %&gt;% \n  summarise(count = n())\n\ncrime_mtl_bs&lt;-crime_mtl_b[crime_mtl_b$QUART=='soir',]\ncrime_mtl_bs_count &lt;- crime_mtl_bs %&gt;%\n  group_by(DATE) %&gt;% \n  summarise(count = n())\n\n\ncrime_mtl_bjn_count&lt;-merge(crime_mtl_bj_count,crime_mtl_bn_count,by.x=\"DATE\", by.y=\"DATE\",suffixes = c(\".day\",\".night\"))\ncrime_mtl_count&lt;-merge(crime_mtl_bjn_count,crime_mtl_bs_count,by.x=\"DATE\", by.y=\"DATE\")\n\nrow.names(crime_mtl_count)=crime_mtl_count$DATE\ncrime_mtl_count&lt;-crime_mtl_count[,-1]\n\ndygraph(as.xts(crime_mtl_count)) %&gt;%\n  dySeries(\"count.day\", label = \"day\") %&gt;%\n  dySeries(\"count.night\", label = \"night\") %&gt;%\n  dySeries(\"count\", label = \"evening\") \n</code></pre>"},{"location":"python_projects/posts/crime-mtl-pattern/#spread-of-breaking-into-house","title":"Spread of breaking into house","text":""},{"location":"python_projects/posts/crime-mtl-pattern/#pattern-over-day","title":"Pattern over day","text":"<pre><code>library(KernSmooth)\nLonLat&lt;-crime_mtl_bj[,7:8]\nkde &lt;- bkde2D(LonLat,bandwidth=c(0.00225, 0.00225))\nCL &lt;- contourLines(kde$x1 , kde$x2 , kde$fhat,nlevels = 8)\n\n## EXTRACT CONTOUR LINE LEVELS\nLEVS &lt;- as.factor(sapply(CL, `[[`, \"level\"))\nNLEV &lt;- length(levels(LEVS))\n\n## CONVERT CONTOUR LINES TO POLYGONS\nlibrary(sp)\npgons &lt;- lapply(1:length(CL), function(i)\n  Polygons(list(Polygon(cbind(CL[[i]]$x, CL[[i]]$y))), ID=i))\nspgons = SpatialPolygons(pgons)\n\n\n## Leaflet map with polygons\nlibrary(leaflet)\nim&lt;-leaflet(spgons) %&gt;% addTiles() %&gt;%\n  addPolygons(color = heat.colors(NLEV, NULL)[LEVS]) %&gt;%\n  addRectangles(lng1=min(LonLat[,1]), lat1=min(LonLat[,2]),\n                lng2=max(LonLat[,1]), lat2=max(LonLat[,2]),\n                fillColor = \"transparent\")\n\nim\n</code></pre>"},{"location":"python_projects/posts/crime-mtl-pattern/#pattern-over-night","title":"Pattern over night","text":"<pre><code>LonLat&lt;-crime_mtl_bn[,7:8]\nkde &lt;- bkde2D(LonLat,bandwidth=c(0.00225, 0.00225))\nCL &lt;- contourLines(kde$x1 , kde$x2 , kde$fhat,nlevels = 8)\n\nLEVS &lt;- as.factor(sapply(CL, `[[`, \"level\"))\nNLEV &lt;- length(levels(LEVS))\n\npgons &lt;- lapply(1:length(CL), function(i)\n  Polygons(list(Polygon(cbind(CL[[i]]$x, CL[[i]]$y))), ID=i))\nspgons = SpatialPolygons(pgons)\n\nim&lt;-leaflet(spgons) %&gt;% addTiles() %&gt;%\n  addPolygons(color = heat.colors(NLEV, NULL)[LEVS]) %&gt;%\n  addRectangles(lng1=min(LonLat[,1]), lat1=min(LonLat[,2]),\n                lng2=max(LonLat[,1]), lat2=max(LonLat[,2]),\n                fillColor = \"transparent\")\n\nim\n</code></pre>"},{"location":"python_projects/posts/crime-mtl-pattern/#pattern-over-evening","title":"Pattern over evening","text":"<pre><code>LonLat&lt;-crime_mtl_bs[,7:8]\nkde &lt;- bkde2D(LonLat,bandwidth=c(0.00225, 0.00225))\nCL &lt;- contourLines(kde$x1 , kde$x2 , kde$fhat,nlevels = 8)\n\nLEVS &lt;- as.factor(sapply(CL, `[[`, \"level\"))\nNLEV &lt;- length(levels(LEVS))\n\npgons &lt;- lapply(1:length(CL), function(i)\n  Polygons(list(Polygon(cbind(CL[[i]]$x, CL[[i]]$y))), ID=i))\nspgons = SpatialPolygons(pgons)\n\nim&lt;-leaflet(spgons) %&gt;% addTiles() %&gt;%\n  addPolygons(color = heat.colors(NLEV, NULL)[LEVS]) %&gt;%\n  addRectangles(lng1=min(LonLat[,1]), lat1=min(LonLat[,2]),\n                lng2=max(LonLat[,1]), lat2=max(LonLat[,2]),\n                fillColor = \"transparent\")\n\nim\n</code></pre> <p>\u2b06 back to top</p>"},{"location":"python_projects/posts/crime-mtl-pattern/#license","title":"License","text":"<p>Copyright \u00a9 2021 Saeid Amiri</p>"},{"location":"python_projects/posts/optimization/","title":"Optimization","text":"<p>When we do not have a closed form, we can use the optimization to find estimate of parameters. In order to find optimization, you need a loos function and use a procedure to minimize the value of loss function based on the parameter values. </p>"},{"location":"python_projects/posts/optimization/#contents","title":"Contents","text":"<ul> <li>Newton-Raphson</li> <li>Gradient Descent</li> </ul>"},{"location":"python_projects/posts/optimization/#newton-raphson-method","title":"Newton-Raphson method","text":"<p>The Newton-Raphson algorithm is one of the old iterative algorithm to approximately find the roots of a real-valued function (loos function); . The idea behind of it is based on the simple linear approximation. Given <code>x_0</code>, a starting point, by solving the root of function by solving , we get closer to the solution. </p> <p>The simple and plain algorithm of Newton-Raphosn is given in the below</p> <p></p> <p>Since we should run the iteration for many time; it is better to replace <code>for</code> with <code>while</code> loop. In the below, we present the algorithm in Python. </p> <p>To write the algorithm in code, we consider  that is also used in Wikipedia.</p> <p>Define the function <pre><code>def f(x):\n    return x**4 - 3 * x**3+2\n\ndef df(x):\n    return 4 * x**3 - 9 * x**2\n</code></pre></p> <p>To see the minimum of the function, plot it: </p> <pre><code>from matplotlib import pyplot as plt\nimport numpy as np \nx_ran_0 = np.linspace(-7,7,100) \nplt.plot(x_ran_0 ,f(x_ran_0))\nplt.xlabel('x')\nplt.ylabel('f(x)')\nplt.show(block=False)\n</code></pre> <p></p> <p>To see how the algorithm works, we can add the plot pf gradients along running the iterations:</p> <p><pre><code>import matplotlib as mpl\n\nx_s = -4 # Starting point\ncur_x = x_s\ndiff_cur_prev= 1\nprecision = 0.001\nmax_ite = 1000  #Maximum number of iterations\n\n#Choose different colors for each gradient\ncolors = mpl.cm.autumn(np.linspace(0,5,max_ite)) \n\nplt.plot(x_ran_0 ,f(x_ran_0)) # plot again the  f(x)\n\ni= 1\nwhile diff_cur_prev &gt; precision:\n    #Plot the points \n    plt.scatter(cur_x, f(cur_x), color='black', s=10, zorder=2);\n    plt.scatter(cur_x, f(cur_x), color='white', s=5, zorder=2)  \n    x_ran_1= np.linspace(cur_x-5,cur_x+5,10)\n    plt.plot(x_ran_1, (df(cur_x) * (x_ran_1 - cur_x)) + f(cur_x), color=colors[i], zorder=1)\n    prev_x = cur_x\n    cur_x += -f(prev_x) / df(prev_x)\n    diff_cur_prev = abs(cur_x - prev_x)\n    print(\"Run: %d, Current: %f, Previous: %f, Different: %f\" % (i, cur_x,prev_x,diff_cur_prev))\n    i+= 1\n\nplt.xlim([-10,10])\nplt.xlabel('x')\nplt.ylabel('f(x)')\nplt.show(block=False)\n</code></pre> </p>"},{"location":"python_projects/posts/optimization/#gradient-descent","title":"Gradient Descent","text":"<p>Gradient Descent is variant of Newton-Raphson that can be used to find the minimum value of a differentiable function. The local minimum can be obtained by solving </p> <p>.</p> <p>We often use theta instead of  <code>x</code>:  , where   is the derivative of loss function for the given parameters.   </p> <p>where  is called the step size or learning rate, see Wikipedia.  To not take big steps we use . We use  Obviously, the criterion function is different from the Newton-Raphson Algorithm. </p> <p>To write a simple code to find the minimum using the Gradient Descent consider  that is already used for explaining the Newton-Raphson. </p> <p>The plot of gradient can be obtained using running the following script: <pre><code>import matplotlib as mpl\n\nx_s = -4 # Starting point\ncur_x = x_s\ndiff_cur_prev= 1\ngamma = 0.001 \nprecision = 0.001\nmax_ite = 1000  #Maximum number of iterations\n\n#Choose different colors for each gradient\ncolors = mpl.cm.autumn(np.linspace(0,5,max_ite)) \n\nplt.plot(x_ran_0 ,f(x_ran_0)) # plot again the  f(x)\n\ni= 1\nwhile diff_cur_prev &gt; precision:\n    #Plot the points \n    plt.scatter(cur_x, f(cur_x), color='black', s=10, zorder=2);\n    plt.scatter(cur_x, f(cur_x), color='white', s=5, zorder=2)  \n    x_ran_1= np.linspace(cur_x-5,cur_x+5,10)\n    plt.plot(x_ran_1, (df(cur_x) * (x_ran_1 - cur_x)) + f(cur_x), color=colors[i], zorder=1)\n    prev_x = cur_x\n    cur_x += -gamma * df(prev_x)\n    diff_cur_prev = abs(cur_x - prev_x)\n    print(\"Run: %d, Current: %f, Previous: %f, Different: %f\" % (i, cur_x,prev_x,diff_cur_prev))\n    i+= 1\n\nplt.xlim([-10,10])\nplt.xlabel('x')\nplt.ylabel('f(x)')\nplt.show(block=False)\n</code></pre></p> <p></p> <p>\u2b06 back to top</p>"},{"location":"python_projects/posts/optimization/#license","title":"License","text":"<p>Copyright \u00a9 2019 Saeid Amiri</p>"},{"location":"work_shop/overview/","title":"Data Analysis using Python","text":""},{"location":"work_shop/overview/#about-this-short-workshop","title":"About this short workshop","text":"<p>This workshop provides valuable insights for individuals starting their data analysis journey with Python. We will be using IPython notebooks that are compatible with both Visual Studio Code (VSCode) and Jupyter environments. To access the workshop, click on the provided link, which will open in Google Colab.</p>"},{"location":"work_shop/overview/#contents","title":"contents","text":"<ul> <li>Part I </li> <li>Part II </li> <li>Data set </li> </ul>"},{"location":"work_shop/overview/#part-i","title":"Part I","text":"<ul> <li>Starting With Data (notebook on colab <code>01-starting-with-data.ipynb</code>)</li> <li>Exercise 1 (Exercise on colab <code>01-excercise.ipynb</code>)</li> <li>Working With Data (notebook on colab <code>02-working-with-data.ipynb</code>)</li> <li>Exercise 2 (Exercise on colab <code>02-exercise.ipynb</code>)</li> <li>Manipulating data-frame (notebook on colab <code>03-manipulating-data-frame.ipynb</code>)</li> <li>Exercise 3 (Exercise on colab <code>03-exercise.ipynb</code>)</li> </ul>"},{"location":"work_shop/overview/#part-ii","title":"Part II","text":"<ul> <li>Summarizing (notebook on colab <code>04-summarizing.ipynb</code>)</li> <li>Exercise 4 (Exercise on colab <code>04-exercise.ipynb</code>)</li> <li>Merging data-frame (notebook on colab <code>05-merging.ipynb</code>)</li> <li>Exercise 5 (Exercise on colab <code>05-exercise.ipynb</code>)</li> <li>Visualization (notebook on colab <code>06-visualization.ipynb</code>)</li> <li>Exercise 6 (Exercise on colab <code>06-exercise.ipynb</code>)</li> </ul>"},{"location":"work_shop/overview/#data-set","title":"Data set","text":""},{"location":"work_shop/overview/#california-housing-dataset","title":"California housing dataset","text":"<p>In this context, we make use of a tailored version of the California housing dataset for practice. This dataset is stored as a <code>.csv</code> file, where each row contains information about a particular strict. The columns in the dataset represent:</p> <p>| Columns        |      -----------------|  <code>longitude</code> <code>latitude</code> <code>housing_median_age</code> <code>total_rooms</code> <code>total_bedrooms</code> <code>households</code> <code>median_income</code> <code>median_house_value</code></p> <p>The first two rows of <code>data/HTC.csv</code> look line as below:</p> <pre><code>\"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\",\"median_house_value\"\n-114.310000,34.190000,15.000000,5612.000000,1283.000000,1015.000000,472.000000,1.493600,66900.000000\n-114.470000,34.400000,19.000000,7650.000000,1901.000000,1129.000000,463.000000,1.820000,80100.000000\n</code></pre>"},{"location":"work_shop/overview/#titanic-dataset","title":"Titanic dataset","text":"<p>For this exercise, we utilize the Titanic dataset, which is stored as a <code>.csv</code>  file. In this dataset, each row contains information about a specific passenger, while the columns represent:</p> Columns <code>PassengerId</code> Passenger id <code>Survived</code> 0 = No; 1 = Yes <code>Pclass</code> Passenger Class (1 = 1<sup>st</sup>; 2 = 2<sup>nd</sup>; 3 = 3<sup>rd</sup>) <code>Name</code> Passenger name <code>Sex</code> Passenger gender <code>Age</code> Passenger age <code>SibSp</code> Number of Siblings/Spouses Aboard <code>Parch</code> Number of Parents/Children Aboard <code>Ticket</code> Ticket Number <code>Fare</code> Passenger fare <code>Cabin</code> Cabin number <code>Embarked</code> Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)"},{"location":"work_shop/exercises/01-exercise/","title":"<em>1 Exercise</em>","text":"<p>1-1: Create a tuple with the four elements \"a,\" 3, 6, and [1, 2]:</p> In\u00a0[6]: Copied! <pre>my_tuple=('a',3,6,[1,2])\n</pre> my_tuple=('a',3,6,[1,2]) <p>1-2: Assign the hourly wages of Sam, Ryan, and Eli to a dictionary called wage and then get the keys, values, and items of the dictionary.</p> In\u00a0[1]: Copied! <pre># Assign hourly wages to a dictionary\nwage = {'Sam': 15, 'Ryan': 25, 'Eli': 30}\n\n# Get keys (names), values (wages), and items (key-value pairs)\nnames = wage.keys()\nwages = wage.values()\nitems = wage.items()\n\n# Print the results\nprint(\"Names:\", names)\nprint(\"Wages:\", wages)\nprint(\"Items:\", items)\n</pre> # Assign hourly wages to a dictionary wage = {'Sam': 15, 'Ryan': 25, 'Eli': 30}  # Get keys (names), values (wages), and items (key-value pairs) names = wage.keys() wages = wage.values() items = wage.items()  # Print the results print(\"Names:\", names) print(\"Wages:\", wages) print(\"Items:\", items) <pre>Names: dict_keys(['Sam', 'Ryan', 'Eli'])\nWages: dict_values([15, 25, 30])\nItems: dict_items([('Sam', 15), ('Ryan', 25), ('Eli', 30)])\n</pre> <p>1-3: Change the salary of Sam to 16, and add new person, john, 22, and delete Ryan.</p> In\u00a0[8]: Copied! <pre>wage['sam']=16\nwage['john']=22\ndel wage['Ryan']\n</pre> wage['sam']=16 wage['john']=22 del wage['Ryan'] <p>1-4: Write a loop to iterates through the numbers from 1 to 5 and prints them, but it skips the number 4</p> In\u00a0[9]: Copied! <pre>count = 1\nwhile count &lt; 6:\n    if count == 4:\n        count = count + 1\n        continue\n    print(count)\n    count = count + 1\n</pre> count = 1 while count &lt; 6:     if count == 4:         count = count + 1         continue     print(count)     count = count + 1 <pre>1\n2\n3\n5\n</pre> <p>1-5: Write a function to check if the number is even or not.</p> In\u00a0[11]: Copied! <pre>def is_even (n):\n    if n % 2 == 0:\n        return print('it is even') \n    return print('it is odd')\n</pre> def is_even (n):     if n % 2 == 0:         return print('it is even')      return print('it is odd') <pre>it is even\n</pre> In\u00a0[12]: Copied! <pre>is_even (10)\n</pre> is_even (10) <pre>it is even\n</pre> <p>1-6: Write a comprehension; get a list and drop 1st, and 3th obs.</p> In\u00a0[\u00a0]: Copied! <pre>obs=range(1,10)\n[x for (i,x) in enumerate(obs) if i not in (0,2)]\n</pre> obs=range(1,10) [x for (i,x) in enumerate(obs) if i not in (0,2)] <p>1-7: Write a comprehension that select number that are divisible by 3 and 5 between 1 and 100</p> In\u00a0[\u00a0]: Copied! <pre>obs=range(1,101)\n[x for x in obs if x%3==0 and x%5==0]\n</pre> obs=range(1,101) [x for x in obs if x%3==0 and x%5==0] <p>1-8: generate even numbers list in range 0 to 15</p> In\u00a0[\u00a0]: Copied! <pre>[i for i in range(15) if i % 2 == 0]\n</pre> [i for i in range(15) if i % 2 == 0]"},{"location":"work_shop/exercises/01-exercise/#data-analysis-using-python","title":"Data Analysis using Python\u00b6","text":""},{"location":"work_shop/exercises/01-exercise/#01-excercise","title":"01-Excercise\u00b6","text":""},{"location":"work_shop/exercises/01-exercise/#contents-next-2-exercise","title":"Contents | Next (2) Exercise\u00b6","text":"<p>01-starting with data </p>"},{"location":"work_shop/exercises/02-exercise/","title":"<em>2 Exercise</em>","text":"<p>2-1: Import the titanic data</p> In\u00a0[1]: Copied! <pre>import pandas as pd \ntitanic = pd.read_csv('../data/titanic.csv', sep=\",\")\n</pre> import pandas as pd  titanic = pd.read_csv('../data/titanic.csv', sep=\",\") <p>2-3: Determine the number of records (rows) and columns in a dataset?</p> In\u00a0[3]: Copied! <pre># Get the number of records (rows) and columns\nnum_records, num_columns = titanic.shape\n</pre> # Get the number of records (rows) and columns num_records, num_columns = titanic.shape Out[3]: <pre>(891, 12)</pre> <p>2-4: Display the top and bottom rows of the dataset.</p> In\u00a0[4]: Copied! <pre>titanic.head() # Top rows\ntitanic.tail() # Bottom rows\n</pre> titanic.head() # Top rows titanic.tail() # Bottom rows Out[4]: PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 886 887 0 2 Montvila, Rev. Juozas male 27.0 0 0 211536 13.00 NaN S 887 888 1 1 Graham, Miss. Margaret Edith female 19.0 0 0 112053 30.00 B42 S 888 889 0 3 Johnston, Miss. Catherine Helen \"Carrie\" female NaN 1 2 W./C. 6607 23.45 NaN S 889 890 1 1 Behr, Mr. Karl Howell male 26.0 0 0 111369 30.00 C148 C 890 891 0 3 Dooley, Mr. Patrick male 32.0 0 0 370376 7.75 NaN Q <p>2-5: What is the data type of the columns in the dataset?</p> In\u00a0[5]: Copied! <pre>titanic.dtypes\n</pre> titanic.dtypes Out[5]: <pre>PassengerId      int64\nSurvived         int64\nPclass           int64\nName            object\nSex             object\nAge            float64\nSibSp            int64\nParch            int64\nTicket          object\nFare           float64\nCabin           object\nEmbarked        object\ndtype: object</pre> <p>2-6: What are the column labels or names in the dataset?</p> In\u00a0[6]: Copied! <pre>titanic.columns\n</pre> titanic.columns Out[6]: <pre>Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n      dtype='object')</pre>"},{"location":"work_shop/exercises/02-exercise/#data-analysis-using-python","title":"Data Analysis using Python\u00b6","text":""},{"location":"work_shop/exercises/02-exercise/#02-excercise","title":"02-Excercise\u00b6","text":""},{"location":"work_shop/exercises/02-exercise/#consider-the-titanic-dataset","title":"Consider the Titanic dataset\u00b6","text":"<p>The available metadata of the Titanic dataset provides the following information:</p> VARIABLE DESCRIPTION <code>PassengerId</code> Passenger id <code>Survived</code> 0 = No; 1 = Yes <code>Pclass</code> Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd) <code>Name</code> Passenger name <code>Sex</code> Passenger gender <code>Age</code> Passenger age <code>SibSp</code> Number of Siblings/Spouses Aboard <code>Parch</code> Number of Parents/Children Aboard <code>Ticket</code> Ticket Number <code>Fare</code> Passenger fare <code>Cabin</code> Cabin number <code>Embarked</code> Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)"},{"location":"work_shop/exercises/02-exercise/#contents-previous-1-exercise-next-3-exercise","title":"Contents | Previous (1) Exercise | Next (3) Exercise\u00b6","text":"<p>02-Working with Data</p>"},{"location":"work_shop/exercises/03-exercise/","title":"<em>3 Exercise</em>","text":"<p>3-1: reconsider the Titanic dataset, and select the column containing the names of passengers,</p> In\u00a0[37]: Copied! <pre>import pandas as pd \nimport numpy as np \ntitanic = pd.read_csv('../data/titanic.csv', sep=\",\")\ntitanic.Name\ntitanic['Name']\ntitanic.iloc[:,3]\n</pre> import pandas as pd  import numpy as np  titanic = pd.read_csv('../data/titanic.csv', sep=\",\") titanic.Name titanic['Name'] titanic.iloc[:,3] Out[37]: <pre>0                                Braund, Mr. Owen Harris\n1      Cumings, Mrs. John Bradley (Florence Briggs Th...\n2                                 Heikkinen, Miss. Laina\n3           Futrelle, Mrs. Jacques Heath (Lily May Peel)\n4                               Allen, Mr. William Henry\n                             ...                        \n886                                Montvila, Rev. Juozas\n887                         Graham, Miss. Margaret Edith\n888             Johnston, Miss. Catherine Helen \"Carrie\"\n889                                Behr, Mr. Karl Howell\n890                                  Dooley, Mr. Patrick\nName: Name, Length: 891, dtype: object</pre> <p>3-2: Categorize the ages of passengers based on the age thresholds of 20 and 50, you can use the Pandas cut function.</p> In\u00a0[4]: Copied! <pre>C1=titanic.Age&lt;=20\nC2=titanic.Age&gt;=50\n\ntitanic.loc[C1,]\ntitanic.loc[~C1&amp;~C2,]\ntitanic.loc[C2]\n\ncategories = pd.cut(titanic['Age'], bins=[0, 20, 50, float('inf')], labels=['Under 20', '20-50', 'Over 50'])\ncategories\n</pre> C1=titanic.Age&lt;=20 C2=titanic.Age&gt;=50  titanic.loc[C1,] titanic.loc[~C1&amp;~C2,] titanic.loc[C2]  categories = pd.cut(titanic['Age'], bins=[0, 20, 50, float('inf')], labels=['Under 20', '20-50', 'Over 50']) categories  Out[4]: <pre>0         20-50\n1         20-50\n2         20-50\n3         20-50\n4         20-50\n         ...   \n886       20-50\n887    Under 20\n888         NaN\n889       20-50\n890       20-50\nName: Age, Length: 891, dtype: category\nCategories (3, object): ['Under 20' &lt; '20-50' &lt; 'Over 50']</pre> <p>3-3: Create a column to save the classifications (<code>L</code>,<code>M</code>,<code>H</code>) of age in it.</p> In\u00a0[15]: Copied! <pre>titanic['Agelev'] = pd.cut(titanic['Age'], bins=[0, 20, 50, float('inf')], labels=['L', 'M', 'H'])\ntitanic\n</pre> titanic['Agelev'] = pd.cut(titanic['Age'], bins=[0, 20, 50, float('inf')], labels=['L', 'M', 'H']) titanic Out[15]: PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked Agelav Agelev 0 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 A/5 21171 7.2500 NaN S M M 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 1 0 PC 17599 71.2833 C85 C M M 2 3 1 3 Heikkinen, Miss. Laina female 26.0 0 0 STON/O2. 3101282 7.9250 NaN S M M 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 0 113803 53.1000 C123 S M M 4 5 0 3 Allen, Mr. William Henry male 35.0 0 0 373450 8.0500 NaN S M M ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 886 887 0 2 Montvila, Rev. Juozas male 27.0 0 0 211536 13.0000 NaN S M M 887 888 1 1 Graham, Miss. Margaret Edith female 19.0 0 0 112053 30.0000 B42 S L L 888 889 0 3 Johnston, Miss. Catherine Helen \"Carrie\" female NaN 1 2 W./C. 6607 23.4500 NaN S NaN NaN 889 890 1 1 Behr, Mr. Karl Howell male 26.0 0 0 111369 30.0000 C148 C M M 890 891 0 3 Dooley, Mr. Patrick male 32.0 0 0 370376 7.7500 NaN Q M M <p>891 rows \u00d7 14 columns</p> <p>3-4: Select objects (rows) where the age is between 20 and 50,</p> In\u00a0[17]: Copied! <pre>np.where(titanic.loc[:,'Agelev'].isin(['M']))\n</pre> np.where(titanic.loc[:,'Agelev'].isin(['M'])) Out[17]: <pre>(array([  0,   1,   2,   3,   4,   8,  13,  18,  20,  21,  23,  25,  30,\n         34,  35,  37,  40,  41,  51,  52,  53,  56,  57,  60,  61,  62,\n         66,  69,  70,  72,  73,  74,  75,  79,  80,  81,  83,  85,  88,\n         89,  90,  92,  93,  97,  98,  99, 100, 102, 103, 104, 105, 106,\n        108, 110, 112, 115, 117, 118, 120, 122, 123, 127, 129, 130, 132,\n        133, 134, 135, 137, 139, 141, 142, 146, 148, 149, 151, 153, 157,\n        160, 161, 162, 167, 169, 173, 177, 178, 179, 187, 188, 189, 190,\n        194, 197, 199, 200, 202, 203, 206, 207, 209, 210, 211, 212, 213,\n        215, 216, 217, 218, 219, 221, 224, 225, 227, 230, 231, 234, 236,\n        239, 242, 243, 244, 245, 246, 247, 248, 251, 253, 254, 255, 257,\n        258, 259, 263, 265, 267, 269, 271, 272, 273, 276, 279, 281, 285,\n        286, 287, 288, 289, 290, 292, 293, 294, 296, 299, 308, 309, 310,\n        312, 313, 314, 315, 316, 318, 319, 320, 321, 322, 323, 325, 327,\n        328, 331, 332, 336, 337, 338, 339, 341, 342, 343, 344, 345, 346,\n        349, 350, 353, 355, 356, 357, 360, 361, 362, 363, 365, 369, 370,\n        373, 376, 377, 380, 382, 383, 387, 390, 391, 392, 393, 394, 395,\n        396, 397, 398, 399, 400, 401, 402, 403, 405, 408, 412, 414, 416,\n        418, 421, 422, 423, 426, 429, 430, 432, 434, 436, 437, 439, 440,\n        442, 443, 447, 450, 452, 453, 455, 458, 460, 461, 462, 463, 465,\n        471, 472, 473, 474, 476, 477, 478, 482, 484, 486, 488, 491, 494,\n        498, 499, 501, 503, 506, 508, 509, 510, 512, 514, 515, 516, 518,\n        519, 520, 521, 523, 525, 526, 528, 529, 534, 536, 537, 539, 540,\n        543, 544, 548, 551, 553, 554, 556, 558, 559, 561, 562, 565, 567,\n        569, 572, 576, 577, 579, 580, 581, 583, 586, 588, 590, 592, 594,\n        595, 597, 599, 600, 603, 604, 605, 606, 607, 608, 609, 610, 614,\n        615, 616, 617, 619, 620, 621, 623, 624, 627, 628, 632, 635, 636,\n        637, 638, 641, 645, 649, 652, 655, 657, 658, 660, 661, 662, 663,\n        665, 666, 668, 670, 671, 673, 676, 678, 679, 681, 685, 690, 693,\n        696, 698, 699, 701, 703, 704, 705, 706, 707, 708, 710, 712, 713,\n        716, 717, 719, 722, 723, 724, 726, 728, 729, 730, 733, 734, 735,\n        736, 737, 741, 742, 743, 744, 747, 749, 752, 753, 754, 756, 758,\n        759, 761, 763, 767, 769, 770, 771, 779, 782, 784, 785, 789, 794,\n        795, 796, 797, 798, 799, 800, 801, 804, 805, 806, 808, 809, 810,\n        811, 812, 814, 816, 817, 818, 821, 822, 823, 833, 835, 836, 838,\n        842, 843, 845, 847, 848, 854, 856, 858, 860, 861, 862, 864, 865,\n        866, 867, 870, 871, 872, 873, 874, 880, 881, 882, 883, 884, 885,\n        886, 889, 890]),)</pre> <p>3-5: Sort the data by the 'Age' column in ascending order.</p> In\u00a0[\u00a0]: Copied! <pre>titanic.sort_values(by='Age')\n</pre> titanic.sort_values(by='Age')"},{"location":"work_shop/exercises/03-exercise/#data-analysis-using-python","title":"Data Analysis using Python\u00b6","text":""},{"location":"work_shop/exercises/03-exercise/#03-excercise","title":"03-Excercise\u00b6","text":""},{"location":"work_shop/exercises/03-exercise/#contents-previous-2-exercise-next-4-exercise","title":"Contents | Previous (2) Exercise | Next (4) Exercise\u00b6","text":"<p>03-manipulating data frame </p>"},{"location":"work_shop/exercises/04-exercise/","title":"<em>1 Exercise</em>","text":"<p>4-1: Categorize the data in the Titanic dataset according to age quantiles at 30% and 70%, and save  the column as <code>Age_Category</code>.</p> In\u00a0[46]: Copied! <pre>import pandas as pd \nimport numpy as np \ntitanic = pd.read_csv('../data/titanic.csv', sep=\",\")\nquantiles = titanic['Age'].quantile([0.3, 0.7])\ncategories = pd.cut(titanic['Age'], bins=[0] + quantiles.tolist() + [float('inf')], labels=['0-30%', '30-70%', '70%+'])\ntitanic['Age_Category'] = categories\n</pre> import pandas as pd  import numpy as np  titanic = pd.read_csv('../data/titanic.csv', sep=\",\") quantiles = titanic['Age'].quantile([0.3, 0.7]) categories = pd.cut(titanic['Age'], bins=[0] + quantiles.tolist() + [float('inf')], labels=['0-30%', '30-70%', '70%+']) titanic['Age_Category'] = categories <p>4-2: Which rows has  age quantiles between 30% and 70%.</p> In\u00a0[33]: Copied! <pre>titanic.groupby(['Age_Category']).groups['30-70%']\n</pre> titanic.groupby(['Age_Category']).groups['30-70%'] <pre>/var/folders/wg/vccqg9g57mx470xx2txm9slr0000gn/T/ipykernel_17118/2829908899.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  titanic.groupby(['Age_Category']).groups['30-70%']\n</pre> Out[33]: <pre>Index([  2,   3,   4,   8,  18,  20,  21,  23,  34,  41,\n       ...\n       870, 872, 874, 880, 881, 883, 884, 886, 889, 890],\n      dtype='int64', length=288)</pre> <p>4-3: Display the top rows of the Titanic dataset.</p> In\u00a0[34]: Copied! <pre>titanic.head()\n</pre> titanic.head() Out[34]: PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked Age_Category 0 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 A/5 21171 7.2500 NaN S 0-30% 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 1 0 PC 17599 71.2833 C85 C 70%+ 2 3 1 3 Heikkinen, Miss. Laina female 26.0 0 0 STON/O2. 3101282 7.9250 NaN S 30-70% 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 0 113803 53.1000 C123 S 30-70% 4 5 0 3 Allen, Mr. William Henry male 35.0 0 0 373450 8.0500 NaN S 30-70% <p>4-4: To compute the coefficient of variation (CV) for the age for each level separately.</p> In\u00a0[45]: Copied! <pre>def cv(x):\n  return (np.mean(x)/np.var(x))\n\ntitanic.groupby('Age_Category')['Age'].agg(cv)\n</pre> def cv(x):   return (np.mean(x)/np.var(x))  titanic.groupby('Age_Category')['Age'].agg(cv)  <pre>/var/folders/wg/vccqg9g57mx470xx2txm9slr0000gn/T/ipykernel_17118/3335974191.py:4: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  titanic.groupby('Age_Category')['Age'].agg(cv)\n</pre> Out[45]: <pre>Age_Category\n0-30%     0.299863\n30-70%    1.827375\n70%+      0.615166\nName: Age, dtype: float64</pre> <p>4-5: Check how many null values are in the dataset?</p> In\u00a0[36]: Copied! <pre>titanic.isnull().sum()\n</pre> titanic.isnull().sum() Out[36]: <pre>PassengerId       0\nSurvived          0\nPclass            0\nName              0\nSex               0\nAge             177\nSibSp             0\nParch             0\nTicket            0\nFare              0\nCabin           687\nEmbarked          2\nAge_Category    177\ndtype: int64</pre> <p>4-6: Fill null values of column Age with linear interpolate.</p> In\u00a0[44]: Copied! <pre>titanic['Age_fill']=titanic['Age'].interpolate()\n</pre> titanic['Age_fill']=titanic['Age'].interpolate()"},{"location":"work_shop/exercises/04-exercise/#data-analysis-using-python","title":"Data Analysis using Python\u00b6","text":""},{"location":"work_shop/exercises/04-exercise/#04-excercise","title":"04-Excercise\u00b6","text":""},{"location":"work_shop/exercises/04-exercise/#contents-previous-3-exercise-next-5-exercise","title":"Contents | Previous (3) Exercise | Next (5) Exercise\u00b6","text":"<p>04 summarizing</p>"},{"location":"work_shop/exercises/05-exercise/","title":"<em>5 Exercise</em>","text":"<p>5-1: Create two data frames based on the following figures.</p> <p> </p> <p></p> In\u00a0[2]: Copied! <pre>import pandas as pd\ndata1= pd.DataFrame({\n    'id': [10, 20, 30, 40,50],\n    'name': ['John', 'Sam', 'Elizabeth', 'Ryan', 'Liam'],\n})\ndata2 = pd.DataFrame({\n    'id': [10, 20, 30, 40],\n    'age': [42, 31, 28, 53],\n    'gender': ['male', 'male', 'female', 'male']\n})\n</pre> import pandas as pd data1= pd.DataFrame({     'id': [10, 20, 30, 40,50],     'name': ['John', 'Sam', 'Elizabeth', 'Ryan', 'Liam'], }) data2 = pd.DataFrame({     'id': [10, 20, 30, 40],     'age': [42, 31, 28, 53],     'gender': ['male', 'male', 'female', 'male'] })  <p>5-2: Perform merging of the data frames using left, right, inner, and outer joins.</p> In\u00a0[3]: Copied! <pre>pd.merge(data1, data2, on='id', how='left')\n</pre> pd.merge(data1, data2, on='id', how='left') Out[3]: id name age gender 0 10 John 42.0 male 1 20 Sam 31.0 male 2 30 Elizabeth 28.0 female 3 40 Ryan 53.0 male 4 50 Liam NaN NaN In\u00a0[4]: Copied! <pre>pd.merge(data1, data2, on='id', how='right')\n</pre> pd.merge(data1, data2, on='id', how='right') Out[4]: id name age gender 0 10 John 42 male 1 20 Sam 31 male 2 30 Elizabeth 28 female 3 40 Ryan 53 male In\u00a0[5]: Copied! <pre>pd.merge(data1, data2, on='id', how='inner')\n</pre> pd.merge(data1, data2, on='id', how='inner') Out[5]: id name age gender 0 10 John 42 male 1 20 Sam 31 male 2 30 Elizabeth 28 female 3 40 Ryan 53 male In\u00a0[6]: Copied! <pre>pd.merge(data1, data2, on='id', how='outer')\n</pre> pd.merge(data1, data2, on='id', how='outer') Out[6]: id name age gender 0 10 John 42.0 male 1 20 Sam 31.0 male 2 30 Elizabeth 28.0 female 3 40 Ryan 53.0 male 4 50 Liam NaN NaN"},{"location":"work_shop/exercises/05-exercise/#data-analysis-using-python","title":"Data Analysis using Python\u00b6","text":""},{"location":"work_shop/exercises/05-exercise/#05-exercise","title":"05-Exercise\u00b6","text":""},{"location":"work_shop/exercises/05-exercise/#contents-previous-4-exercise-next-6-exercise","title":"Contents | Previous (4) Exercise | Next (6) Exercise\u00b6","text":"<p>05 Merging data frame</p>"},{"location":"work_shop/exercises/06-exercise/","title":"<em>6 Exercise</em>","text":"<p>6-1: Consider the Titanic dataset.</p> In\u00a0[1]: Copied! <pre>import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \ntitanic = pd.read_csv('../data/titanic.csv', sep=\",\")\n</pre> import pandas as pd  import numpy as np  import matplotlib.pyplot as plt  titanic = pd.read_csv('../data/titanic.csv', sep=\",\") <p>6-2: Display the scatter plot of age and fare in the Titanic dataset.</p> In\u00a0[2]: Copied! <pre>x = titanic.Age\ny = titanic.Fare\nplt.scatter(x, y)\nplt.show(block=False)\n</pre> x = titanic.Age y = titanic.Fare plt.scatter(x, y) plt.show(block=False) <p>6-3: Plot a histogram of the age variable in the Titanic dataset.</p> In\u00a0[9]: Copied! <pre>plt.hist(titanic['Age'], density=True)\n</pre> plt.hist(titanic['Age'], density=True) Out[9]: <pre>(array([0.00950368, 0.00809572, 0.03115094, 0.02974299, 0.02076729,\n        0.01231958, 0.00791973, 0.00422386, 0.00158395, 0.00035199]),\n array([ 0.42 ,  8.378, 16.336, 24.294, 32.252, 40.21 , 48.168, 56.126,\n        64.084, 72.042, 80.   ]),\n &lt;BarContainer object of 10 artists&gt;)</pre> <p>6-4: Plot a bivariate distribution of age and fare using kernel density estimation (KDE) in the Titanic dataset.</p> In\u00a0[3]: Copied! <pre>import seaborn as sns\nsns.set(color_codes=True)\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n</pre> import seaborn as sns sns.set(color_codes=True) import warnings warnings.filterwarnings(\"ignore\") In\u00a0[4]: Copied! <pre>sns.kdeplot(data=titanic, x='Age', y='Fare')\n</pre> sns.kdeplot(data=titanic, x='Age', y='Fare') Out[4]: <pre>&lt;Axes: xlabel='Age', ylabel='Fare'&gt;</pre>"},{"location":"work_shop/exercises/06-exercise/#data-analysis-using-python","title":"Data Analysis using Python\u00b6","text":""},{"location":"work_shop/exercises/06-exercise/#06-excercise","title":"06-Excercise\u00b6","text":""},{"location":"work_shop/exercises/06-exercise/#contents-previous-5-exercise","title":"Contents | Previous (5) Exercise\u00b6","text":"<p>04 Visualization</p>"},{"location":"work_shop/notebooks/01-starting-with-data/","title":"<b>1 Starting with data </b>","text":"In\u00a0[1]: Copied! <pre>2+3\n2-3\n2/3\n2*3\n2**3 # power\n</pre> 2+3 2-3 2/3 2*3 2**3 # power Out[1]: <pre>8</pre> <p>Let us start with some foundational tasks: assigning both a text and a number to variables, and then verifying their data types</p> In\u00a0[\u00a0]: Copied! <pre>pi0=3.14\npi1='approximate with two digits'\nprint(pi0)\nprint(pi1)\nprint(type(pi0))\nprint(type(pi1))\n</pre> pi0=3.14 pi1='approximate with two digits' print(pi0) print(pi1) print(type(pi0)) print(type(pi1)) <p>Python supports integer, floats, complex, and boolen.</p> In\u00a0[\u00a0]: Copied! <pre>boolen1= (3 &lt; 4) \nboolen2= (4 &lt; 3)\ncomplex = 2 + 0.5j\n</pre> boolen1= (3 &lt; 4)  boolen2= (4 &lt; 3) complex = 2 + 0.5j In\u00a0[1]: Copied! <pre>import os # import os module\nos.getcwd() # Run to see the current working directory, The Working directory is a directory that the python actively accesses to its objects, this directory is called the working directory\n</pre> import os # import os module os.getcwd() # Run to see the current working directory, The Working directory is a directory that the python actively accesses to its objects, this directory is called the working directory Out[1]: <pre>'/home/sam/GITHUBS/python/Python-for-Data-Analysis/notes'</pre> <p>Put the command in the help to get infor about the function</p> <p>To obtain information about a function, you can use the <code>help()</code> function in Python. Here's how you can use it:</p> <pre><code># Use the help() function to get information about a function\nhelp(function_name)\n</code></pre> <p>Replace function_name with the name of the function you want to get information about. When you run this command, Python will provide documentation and details about the specified function, including its parameters, purpose, and usage.</p> In\u00a0[35]: Copied! <pre>help(os.getcwd)\n</pre> help(os.getcwd) <pre>Help on built-in function getcwd in module posix:\n\ngetcwd()\n    Return a unicode string representing the current working directory.\n\n</pre> <p>The following code imports NumPy (NUMerical PYthon), which offers valuable array structures for data manipulation. It's common to use the alias \"np\" for NumPy to make it more convenient to work with:</p> In\u00a0[1]: Copied! <pre># Import NumPy with the alias \"np\"\nimport numpy as np\n</pre> # Import NumPy with the alias \"np\" import numpy as np <p>By importing NumPy this way, you can access its functions and classes using the shorter alias \"np\" throughout your code. For example, you can use np.array() to create arrays or np.mean() to calculate the mean of an array.</p> In\u00a0[1]: Copied! <pre>weights=[20,15,19,21,16] \ntype(weights)\ncolors=['red','blue','green','black','white']\ncolors\na,*b,c=[1,2,3,4]\n</pre> weights=[20,15,19,21,16]  type(weights) colors=['red','blue','green','black','white'] colors a,*b,c=[1,2,3,4] <p>You can access the values of a list by using square brackets.</p> In\u00a0[\u00a0]: Copied! <pre>colors[1:3] # Slicing\ncolors[:3] # The 0 can be left-out\ncolors[0:3:2]\ncolors[::-1] # Reversing with a negative step size\ncolors[3:]\ncolors[1]\ncolors[-1] # Indexing from the end\nweights[1]=20\nweights.append(30) # Appending\nweights.sort() # Sort list\nweights.extend([30, 31]) # Extends two ellement to list \nweights.append([30,20]) # Extends a list to list\nweights.remove(30) # Remove the occurence of an element\nweights.index(21)\ncolors + weights # Adding two list together\n</pre> colors[1:3] # Slicing colors[:3] # The 0 can be left-out colors[0:3:2] colors[::-1] # Reversing with a negative step size colors[3:] colors[1] colors[-1] # Indexing from the end weights[1]=20 weights.append(30) # Appending weights.sort() # Sort list weights.extend([30, 31]) # Extends two ellement to list  weights.append([30,20]) # Extends a list to list weights.remove(30) # Remove the occurence of an element weights.index(21) colors + weights # Adding two list together   In\u00a0[\u00a0]: Copied! <pre>my_tuple = (1,2,'red', 'blue', 'green', 'black', 'white')\ntype(my_tuple)\nmy_tuple[1:3]\n</pre> my_tuple = (1,2,'red', 'blue', 'green', 'black', 'white') type(my_tuple) my_tuple[1:3] <p>In the example above, my_tuple is defined as a tuple containing integers and a string. Once a tuple is created, you cannot modify its elements. This immutability is the key distinction between tuples and lists in Python.</p> In\u00a0[1]: Copied! <pre>my_dict = {\n    'name': 'Ryan',\n    'age': 4,\n    'sex': 'M'\n}\n\nmy_dict.values()\nmy_dict.keys()\nmy_dict.items()\nmy_dict['name']\nmy_dict['age']\n</pre> my_dict = {     'name': 'Ryan',     'age': 4,     'sex': 'M' }  my_dict.values() my_dict.keys() my_dict.items() my_dict['name'] my_dict['age']  Out[1]: <pre>4</pre> <p>In this example, `my_dict`` is a dictionary with keys \"name,\" \"age,\" and \"sex\", each associated with respective values. The values are accessed using the keys. When printed, it would display the contents of the dictionary.</p> In\u00a0[\u00a0]: Copied! <pre>a = [1., 2., 3.]\nar1=np.array(a)\nar1[0] #first array \nar1[0:2]# # first and second elements\n</pre> a = [1., 2., 3.] ar1=np.array(a) ar1[0] #first array  ar1[0:2]# # first and second elements <p>The NumPy indexing is similar the python list. The following creates a two dimensional array, consisting of two rows and four columns:</p> In\u00a0[\u00a0]: Copied! <pre>X = [[1, 2, 3, 4], [5, 6, 7, 8]]\nar2by4=np.array(X) # creates the array\nar2by4.dtype # show the type\nar2by4.astype(np.int32) # change the type\nar2by4.shape # \nar2by4.ndim #  number of dimension\n</pre> X = [[1, 2, 3, 4], [5, 6, 7, 8]] ar2by4=np.array(X) # creates the array ar2by4.dtype # show the type ar2by4.astype(np.int32) # change the type ar2by4.shape #  ar2by4.ndim #  number of dimension  <p>For indexing of arrays with more than one dimension or axis, we separate our indexing or slicing operations by commas.</p> In\u00a0[\u00a0]: Copied! <pre>ar2by4[0,1] # element on first row and second column\nar2by4[:,1] # second column\nar2by4[0,:] # first row \nar2by4[[0,1],[2,3]] # elements on first and second rows and  third and fourth columns.\n</pre> ar2by4[0,1] # element on first row and second column ar2by4[:,1] # second column ar2by4[0,:] # first row  ar2by4[[0,1],[2,3]] # elements on first and second rows and  third and fourth columns. <p>The mathematical operation  (+, -, /, *, and **)  can be applied directly on the array.</p> In\u00a0[7]: Copied! <pre>X=np.array([[1, 2, 3, 4], [5, 6, 7, 8]]) \nY=np.array( [[0, 1, 0, 1], [1, 0, 1, 0]])\nZ=np.array( [[0, 1, 0, 1]])\nX+1\nX*2\nX+Y\nX+Z\nX-Y\n</pre>  X=np.array([[1, 2, 3, 4], [5, 6, 7, 8]])  Y=np.array( [[0, 1, 0, 1], [1, 0, 1, 0]]) Z=np.array( [[0, 1, 0, 1]]) X+1 X*2 X+Y X+Z X-Y   Out[7]: <pre>array([[1, 3, 3, 5],\n       [5, 7, 7, 9]])</pre> In\u00a0[\u00a0]: Copied! <pre>print(int(True))  # Outputs: 1\nprint(int(False)) # Outputs: 0\n</pre> print(int(True))  # Outputs: 1 print(int(False)) # Outputs: 0 <p>However, the value of <code>True</code> as 1 and <code>False</code> as 0 is a convention used in some contexts, especially when performing arithmetic operations with Boolean values. Run the following codes and explains what the codes do.</p> In\u00a0[\u00a0]: Copied! <pre>8 &lt; 9\n9 &lt; 8\nx = 3\ny = 9\nx &lt; y\n</pre> 8 &lt; 9 9 &lt; 8 x = 3 y = 9 x &lt; y <p>Commands involving control structures frequently incorporate conditional statements that utilize comparison operator (&gt;, &lt;, =&gt;, &lt;=, ==, !=, ~, is)</p> In\u00a0[\u00a0]: Copied! <pre>3 &lt; 4\n3 != 4\n3 == 4\n3 is 4\n'hi' == 'h' + 'i'\n'HI' != 'hi'\n[1, 2] != [2, 1]\n</pre> 3 &lt; 4 3 != 4 3 == 4 3 is 4 'hi' == 'h' + 'i' 'HI' != 'hi' [1, 2] != [2, 1]  <p>The structure command of if is as below.</p> <pre><code>if(condition1)\n  cons.expr \nelif(condition2) \n  alt.expr1 \nelse \n  alt.expr2\n</code></pre> <p>If <code>condition1</code> satisfies then <code>cons.expr</code> run otherwise if <code>condition2</code> satisfies <code>alt.expr1</code> run, otherwise  <code>alt.expr2</code> runs.</p> In\u00a0[\u00a0]: Copied! <pre>x = 4\ny = 4\n\nif x &lt; y:\n  print('x is less than y')\nelif x &gt; y:\n print('x greater than y')\nelse:\n print(' x and y are equal')\n</pre> x = 4 y = 4  if x &lt; y:   print('x is less than y') elif x &gt; y:  print('x greater than y') else:  print(' x and y are equal')  In\u00a0[\u00a0]: Copied! <pre>x = [1, 2, 3]\ntype(x)\nlen(x)\nmin(x)\n</pre> x = [1, 2, 3] type(x) len(x) min(x) <p>To round the value, you can use the <code>round(value, size)</code> function</p> In\u00a0[\u00a0]: Copied! <pre>round(0.12345, 2)\nround(0.12345, 3)\n</pre> round(0.12345, 2) round(0.12345, 3) <p>For instance, let's write a function that takes two arguments, adds them together, and returns the result:</p> In\u00a0[\u00a0]: Copied! <pre>def add_numbers(a, b):\n    result = a + b\n    return result\n\n# Example usage of the function\nnum1 = 5\nnum2 = 7\nsum_result = add_numbers(num1, num2)\nprint(\"Sum:\", sum_result)\n</pre> def add_numbers(a, b):     result = a + b     return result  # Example usage of the function num1 = 5 num2 = 7 sum_result = add_numbers(num1, num2) print(\"Sum:\", sum_result) <p>In this example, the <code>add_numbers</code> function takes two arguments (<code>a</code> and <code>b</code>), adds them together, and returns the result. When you call the function with <code>add_numbers(num1, num2)</code>, it computes the sum of <code>num1</code> and <code>num2</code>, which is 12 in this case. The result is then printed to the console.</p> In\u00a0[\u00a0]: Copied! <pre>count = 0\nwhile count &lt; 10:\n    print(count)\n    count = count + 1\n</pre> count = 0 while count &lt; 10:     print(count)     count = count + 1 <p>You can use the <code>else</code> clause with a <code>while</code> loop in Python. The else block associated with a <code>while</code> loop is executed when the loop's condition becomes <code>Fals</code>e, and the loop naturally exits.</p> In\u00a0[\u00a0]: Copied! <pre>count = 0\nwhile count &lt; 10:\n    print(count)\n    count = count + 1\nelse: \n    print('count is greater than 10')\n</pre> count = 0 while count &lt; 10:     print(count)     count = count + 1 else:      print('count is greater than 10') <p>In this example, the <code>else</code> block will be executed when <code>count</code> becomes equal to or greater than 10, and the <code>while</code> loop terminates.</p> <p>The <code>for</code> loop in Python has the following structure:</p> <pre><code>for variable in iterable:\n    code\n</code></pre> In\u00a0[\u00a0]: Copied! <pre>iterable = (0,1,2,3,5,6)\nfor i in iterable:\n    if i == 0:\n        print('i is zero')    \n        next\n    if a % 2 == 0:\n        print('i is a even number')\n    else:\n        print('i is a odd number')\n</pre> iterable = (0,1,2,3,5,6) for i in iterable:     if i == 0:         print('i is zero')             next     if a % 2 == 0:         print('i is a even number')     else:         print('i is a odd number')    <p>Sequences are often represented using <code>range(start, end, step)</code>, making it a valuable choice.</p> In\u00a0[\u00a0]: Copied! <pre>for i in range(6):\n    print(i)\n</pre> for i in range(6):     print(i) <p>This will print numbers 0 through 5.</p> In\u00a0[2]: Copied! <pre>for i in range(6):\n    print(i) \nelse:\n    print('The loop stops at', i)\n</pre> for i in range(6):     print(i)  else:     print('The loop stops at', i)  <pre>0\n1\n2\n3\n4\n5\nThe loop stops at 5\n</pre> <p>This will print numbers 0 through 5, at the end  print <code>The loop stops at 5</code></p> <p>looping through even number from 0 to 6</p> In\u00a0[\u00a0]: Copied! <pre>for i in range(0,6,2):\n    print(i)\n</pre> for i in range(0,6,2):     print(i)  <p>Original list generation using a for loop:</p> In\u00a0[\u00a0]: Copied! <pre>x = []\nfor i in range(3):\n    for j in range(2):\n        x.append((i, j))\nprint(x)\n</pre> x = [] for i in range(3):     for j in range(2):         x.append((i, j)) print(x) <p>List comprehension equivalent:</p> In\u00a0[\u00a0]: Copied! <pre>x=[(i, j) for i in range(3) for j in range(2)]\n</pre> x=[(i, j) for i in range(3) for j in range(2)]"},{"location":"work_shop/notebooks/01-starting-with-data/#data-analysis-using-python","title":"Data Analysis using Python\u00b6","text":""},{"location":"work_shop/notebooks/01-starting-with-data/#01-starting-with-data","title":"01-Starting with Data\u00b6","text":"<p>Objectives:</p> <ul> <li>Learn about module</li> <li>Learn about data structures</li> <li>How to use conditionals</li> <li>How to write a function</li> </ul> <p>Content:</p> <ul> <li>Ipython</li> <li>Module</li> <li>Data Structures</li> <li>Conditionals</li> <li>Function</li> <li>Loops</li> <li>List Comprehension</li> </ul>"},{"location":"work_shop/notebooks/01-starting-with-data/#ipython","title":"Ipython\u00b6","text":"<p>IPython is a platform that allows you to interactively work with your code and data. To access it, simply type <code>ipython</code> in the terminal. In Python, you can perform various mathematical calculations using basic operators, such as +(addition), -(subtraction), /(division), *(multiplication), % (modulo), and exponentiation (**):</p>"},{"location":"work_shop/notebooks/01-starting-with-data/#module","title":"Module\u00b6","text":"<p>A module (or library) is a collection of data, functions, and resources bundled for execution. After installing the library, you can seamlessly access its functions within Python by importing it.</p>"},{"location":"work_shop/notebooks/01-starting-with-data/#data-structures","title":"Data Structures\u00b6","text":"<p>Python provides a versatile array of valuable data structures, including lists, sets, dictionaries, and the ability for programmers to define their own custom structures known as classes.</p>"},{"location":"work_shop/notebooks/01-starting-with-data/#list","title":"list\u00b6","text":"<p>A list is a sequence of values assigned to a variable. The individual values within a list are referred to as elements or items.</p>"},{"location":"work_shop/notebooks/01-starting-with-data/#tuple","title":"Tuple\u00b6","text":"<p>Tuple is a sequence of objects like list, but it is immutable. To define tuple, Python uses the parenthesis:</p> <p>A tuple is a sequence of objects similar to a list, but unlike a list, it is immutable, meaning its elements cannot be changed after creation. To define a tuple in Python, you use parentheses ():</p> <p>python Copy code my_tuple = (1, 2, 3, \"hello\") In the example above, my_tuple is defined as a tuple containing integers and a string. Once a tuple is created, you cannot modify its elements. This immutability is the key distinction between tuples and lists in Python.</p>"},{"location":"work_shop/notebooks/01-starting-with-data/#dictionary","title":"Dictionary\u00b6","text":"<p>Dictionary is a generalized form of list, unlike the list its indices can be any type of values. A dictionary maps a set of objects (keys) to another set of objects (values).</p> <p>Dictionary includes key and items, the key is actually indices and item is the values. A Python dictionary is a mapping of unique keys to values. Use the curly brackets to construct the dictionary, separate the key and value with colons (:) and with commas (,)between each pair. Keys must be quoted. We can print out the dictionary by printing the reference to it.</p> <p>A dictionary in Python is a generalized form of a list where the indices, known as keys, can be of any data type. A dictionary maps a set of keys to their corresponding values.</p> <p>In Python, a dictionary consists of key-value pairs enclosed in curly braces {}. Each key is separated from its associated value by a colon : and the key-value pairs are separated by commas ,. Keys are typically enclosed in quotes (either single or double), especially if they are strings. You can print a dictionary by referencing it. Here's an example:</p>"},{"location":"work_shop/notebooks/01-starting-with-data/#n-dimensional-array","title":"n-dimensional array\u00b6","text":"<p>The NumPy has a very useful array data structure that called ndarray, which is short for n-dimensional array. The following gives an one dinsion array of list.</p>"},{"location":"work_shop/notebooks/01-starting-with-data/#conditionals","title":"Conditionals\u00b6","text":"<p>The value True and False are referred to as logical values that used the same in Python, their corresponding values are 1 and 0. Run the following codes and explains what the codes do.</p> <p>The values <code>True</code> and <code>False</code> are referred to as Boolean values in Python. They are used to represent truth values, with True indicating a condition is true and False indicating a condition is false. While <code>True</code> and <code>False</code> are often used for logical comparisons, it's important to note that their corresponding integer values are not always 1 and 0.</p> <p>In Python, you can check the integer values of True and False using the int() function:</p>"},{"location":"work_shop/notebooks/01-starting-with-data/#function","title":"Function\u00b6","text":"<p>In the context of programming, a function is a sequence of statements that performs a specific computation. Functions consist of three parts: arguments, a script, and an output. Python has two types of functions: built-in functions, which are integral to Python's core or packaged within libraries, and user-defined functions, which are created by the user.</p>"},{"location":"work_shop/notebooks/01-starting-with-data/#built-in-function","title":"Built-in function\u00b6","text":"<p>Python includes a variety of functions in its core that are consistently accessible, [see](https: // docs.python.org/3/library/functions.html)</p>"},{"location":"work_shop/notebooks/01-starting-with-data/#user-function","title":"User function\u00b6","text":"<p>Functions has three parts; argument, script, and output. It has simple structure</p> <pre><code>def name (argument):  \n   script\n   return output\n</code></pre>"},{"location":"work_shop/notebooks/01-starting-with-data/#loops","title":"Loops\u00b6","text":"<p>When you have a repetitive task, you can use either a <code>for</code> loop or a <code>while</code> loop. The structure of a <code>while</code> loop is as follows:</p> <pre><code>while condition:\n    code goes here\n</code></pre> <p>In a <code>while</code> loop, the code inside the loop will be executed repeatedly as long as the specified condition remains <code>True</code>. Once the condition becomes <code>False</code>, the loop terminates, and the program continues with the next instruction after the loop.</p>"},{"location":"work_shop/notebooks/01-starting-with-data/#list-comprehension","title":"list Comprehension\u00b6","text":"<p>List comprehension in Python is a concise method for generating a list from an existing sequence. The general syntax for list comprehension is as follows:</p> <pre><code>new_list = [expression for item in iterable if condition]\n</code></pre> <p>Here's a breakdown of the components:  <code>new_list</code>: This is the new list that will be created.   <code>expression</code>: It represents an expression that defines how each item in the iterable will be transformed and added to the new list.  <code>item</code>: It is a variable that takes on each element of the iterable one at a time.  <code>iterable</code>: This is the sequence or iterable from which the elements will be taken.  <code>condition</code> (optional): It specifies an optional filter that determines whether an element from the iterable is included in the new list.</p> <p>List comprehensions are a powerful and readable way to create lists in Python, and they are often used when you want to apply a transformation or filter to elements from an existing iterable. Below is a list generated using a <code>for</code> loop; rewrite it using a list comprehension.</p>"},{"location":"work_shop/notebooks/01-starting-with-data/#contents-next-2-working-with-data","title":"Contents | Next (2) working with data\u00b6","text":"<p>Exercise Starting with Data</p>"},{"location":"work_shop/notebooks/02-working-with-data/","title":"<b>2 Working with data </b>","text":"In\u00a0[3]: Copied! <pre>import pandas as pd\n</pre> import pandas as pd In\u00a0[24]: Copied! <pre>var={\"A\": [1,2,0], \"B\": [2,3,4]}\ndf= pd.DataFrame(data=var,index=['A', 'Z', 'C'])\ndf\n</pre> var={\"A\": [1,2,0], \"B\": [2,3,4]} df= pd.DataFrame(data=var,index=['A', 'Z', 'C']) df Out[24]: A B A 1 2 Z 2 3 C 0 4 <p>Changing the label column is a straightforward task:</p> In\u00a0[25]: Copied! <pre>raw_data = {'population': [ 1015.0, 1129.0, 333.0,  515.0],'median_income': [ 1.5, 1.8,  1.7,  3.2]}\ndf=pd.DataFrame(raw_data, columns = ['population', 'median_income'])\n</pre> raw_data = {'population': [ 1015.0, 1129.0, 333.0,  515.0],'median_income': [ 1.5, 1.8,  1.7,  3.2]} df=pd.DataFrame(raw_data, columns = ['population', 'median_income']) <p>To create an empty DataFrame, execute the following code:</p> In\u00a0[26]: Copied! <pre>df1=pd.DataFrame(columns = ['population', 'median_income'])\ndf2=pd.DataFrame()\n</pre> df1=pd.DataFrame(columns = ['population', 'median_income']) df2=pd.DataFrame() In\u00a0[27]: Copied! <pre>df0=pd.DataFrame([38,40,25,33])\ndf['Ave_hour']=df0\n</pre> df0=pd.DataFrame([38,40,25,33]) df['Ave_hour']=df0 <p>You can also add new columns to a DataFrame using the <code>assign()</code> method. New columns can be generated using functions, as shown below:</p> In\u00a0[\u00a0]: Copied! <pre>df=df.assign(Ave_hour=df0)\ndf=df.assign(PI1=lambda x: x['population']*x['median_income'],PI2=df['population']/df['median_income'] )\n</pre> df=df.assign(Ave_hour=df0) df=df.assign(PI1=lambda x: x['population']*x['median_income'],PI2=df['population']/df['median_income'] ) <p>You can rename a column in a DataFrame using the <code>rename()</code> method.</p> In\u00a0[\u00a0]: Copied! <pre>df.columns = ['population1', 'median_income', 'date2', 'Ave_hour','PI1','PI2']\ndf=df.rename(columns={'population1': 'pop', 'median_income': 'med_income'},inplace=True)\ndf\n</pre> df.columns = ['population1', 'median_income', 'date2', 'Ave_hour','PI1','PI2'] df=df.rename(columns={'population1': 'pop', 'median_income': 'med_income'},inplace=True) df <p>In certain situations, it may be more appropriate to use the data collection time as the index. The script below demonstrates how to convert the data to a time format and then set it as the index.</p> In\u00a0[\u00a0]: Copied! <pre>df = df.set_index(pd.to_datetime(['2019-04-01','2019-05-04','2019-06-01','2019-07-02']))\n</pre> df = df.set_index(pd.to_datetime(['2019-04-01','2019-05-04','2019-06-01','2019-07-02'])) <p>You can utilize the <code>to_datetime</code> function to ensure that the data is stored in a time format, making it flexible for conversion into various time-related attributes such as year, weekday, and more.</p> In\u00a0[\u00a0]: Copied! <pre>df['date'] = pd.to_datetime(['2019-04-01', '2019-05-04', '2019-06-01', '2019-07-02'])\ndf['date'].dt.weekday\ndf1['date'].dt.year\n</pre> df['date'] = pd.to_datetime(['2019-04-01', '2019-05-04', '2019-06-01', '2019-07-02']) df['date'].dt.weekday df1['date'].dt.year <p>Next, we should save the data. One of the best formats for storing datasets is in CSV format. The following script saves the data as a CSV file without including row numbers and column names by setting <code>index=False</code>.</p> In\u00a0[\u00a0]: Copied! <pre>df.to_csv(\"test_df.csv\", index=False, encoding='utf8')\ndf.to_excel(\"test_df.xlsx\")\n</pre> df.to_csv(\"test_df.csv\", index=False, encoding='utf8') df.to_excel(\"test_df.xlsx\") In\u00a0[4]: Copied! <pre>source = \"../data/CHD.csv\"\nCHD = pd.read_csv(source, sep=\",\")\nCHD.head()  # Displays the first several rows of CHD\n</pre> source = \"../data/CHD.csv\" CHD = pd.read_csv(source, sep=\",\") CHD.head()  # Displays the first several rows of CHD Out[4]: longitude latitude housing_median_age total_rooms total_bedrooms population households median_income median_house_value 0 -114.31 34.19 15 5612 1283 1015 472 1.4936 66900 1 -114.47 34.40 19 7650 1901 1129 463 1.8200 80100 2 -114.56 33.69 17 720 174 333 117 1.6509 85700 3 -114.57 33.64 14 1501 337 515 226 3.1917 73400 4 -114.57 33.57 20 1454 326 624 262 1.9250 65500 <p>A DataFrame can indeed store data of different types in its columns. Here are some common data types you can specify:</p> <p>object: Represents a mix of different data types.  int64: Stores integer numbers. float64: Handles floating-point numbers. bool: Stores True/False values. datetime64: Manages date and time values. category: Represents a finite number of possible values. You can define the data type of a column in a DataFrame using various methods, including when reading in data or explicitly specifying the dtype argument.</p> <p>To check the data types of the columns in a DataFrame, you can use the dtypes attribute, as shown in the following code:</p> In\u00a0[5]: Copied! <pre>CHD.dtypes  # show the type of variables\n</pre> CHD.dtypes  # show the type of variables Out[5]: <pre>longitude             float64\nlatitude              float64\nhousing_median_age      int64\ntotal_rooms             int64\ntotal_bedrooms          int64\npopulation              int64\nhouseholds              int64\nmedian_income         float64\nmedian_house_value      int64\ndtype: object</pre> In\u00a0[\u00a0]: Copied! <pre>CHD.shape # Diplay the dimension\nCHD.columns  # Return name of columns\nCHD.describe()  # generate summary\nCHD.info() \nCHD.head() # Top rows\nCHD.tail() # Bottom rows\n</pre>  CHD.shape # Diplay the dimension CHD.columns  # Return name of columns CHD.describe()  # generate summary CHD.info()  CHD.head() # Top rows CHD.tail() # Bottom rows <p>o compute various statistics per column in a DataFrame, you can use different aggregation functions depending on your specific requirements. Here's how you can compute some common statistics using Pandas:</p> In\u00a0[\u00a0]: Copied! <pre>print(\"Count of median_house_value:    \", CHD['median_house_value'].count())\nprint(\"Mean of median_house_value:     \", CHD['median_house_value'].mean())\nprint(\"Std of median_house_value:      \", CHD['median_house_value'].std())\nprint(\"Min of median_house_value:      \", CHD['median_house_value'].min())\nprint(\"Max of median_house_value:      \", CHD['median_house_value'].max())\n</pre> print(\"Count of median_house_value:    \", CHD['median_house_value'].count()) print(\"Mean of median_house_value:     \", CHD['median_house_value'].mean()) print(\"Std of median_house_value:      \", CHD['median_house_value'].std()) print(\"Min of median_house_value:      \", CHD['median_house_value'].min()) print(\"Max of median_house_value:      \", CHD['median_house_value'].max()) <p>You can use these functions individually to compute the desired statistics for each column in your DataFrame based on your analysis needs.</p> In\u00a0[40]: Copied! <pre>xls_book = pd.ExcelFile('../data/titianic.xlsx')\nxls_book\ndfs_xls_book = {sheet: xls_book.parse(sheet) for sheet in xls_book.sheet_names}\ndfs_xls_book['Sheet1']\n</pre> xls_book = pd.ExcelFile('../data/titianic.xlsx') xls_book dfs_xls_book = {sheet: xls_book.parse(sheet) for sheet in xls_book.sheet_names} dfs_xls_book['Sheet1'] Out[40]: PassengerId Name Sex Age 0 1 Braund, Mr. Owen Harris male 22.0 1 2 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 2 3 Heikkinen, Miss. Laina female 26.0 3 4 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 4 5 Allen, Mr. William Henry male 35.0 ... ... ... ... ... 886 887 Montvila, Rev. Juozas male 27.0 887 888 Graham, Miss. Margaret Edith female 19.0 888 889 Johnston, Miss. Catherine Helen \"Carrie\" female NaN 889 890 Behr, Mr. Karl Howell male 26.0 890 891 Dooley, Mr. Patrick male 32.0 <p>891 rows \u00d7 4 columns</p> In\u00a0[41]: Copied! <pre>xls_book = pd.ExcelFile('../data/titianic.xls')\nxls_book\ndfs_xls_book = {sheet: xls_book.parse(sheet) for sheet in xls_book.sheet_names}\ndfs_xls_book['Sheet1']\n</pre> xls_book = pd.ExcelFile('../data/titianic.xls') xls_book dfs_xls_book = {sheet: xls_book.parse(sheet) for sheet in xls_book.sheet_names} dfs_xls_book['Sheet1'] Out[41]: PassengerId Name Sex Age 0 1 Braund, Mr. Owen Harris male 22.0 1 2 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 2 3 Heikkinen, Miss. Laina female 26.0 3 4 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 4 5 Allen, Mr. William Henry male 35.0 ... ... ... ... ... 886 887 Montvila, Rev. Juozas male 27.0 887 888 Graham, Miss. Margaret Edith female 19.0 888 889 Johnston, Miss. Catherine Helen \"Carrie\" female NaN 889 890 Behr, Mr. Karl Howell male 26.0 890 891 Dooley, Mr. Patrick male 32.0 <p>891 rows \u00d7 4 columns</p>"},{"location":"work_shop/notebooks/02-working-with-data/#data-analysis-using-python","title":"Data Analysis using Python\u00b6","text":""},{"location":"work_shop/notebooks/02-working-with-data/#02-working-with-data","title":"02-Working with Data\u00b6","text":"<p>Objectives:</p> <ul> <li>Creating dataframe</li> <li>loading Dataframe using  <code>read_csv</code></li> <li>Describing dataframe</li> <li>Saving dataframe</li> </ul> <p>Contents: </p> <ul> <li>Panda</li> <li>Data-frame</li> <li>Adding new column</li> <li>Loading CSV data</li> <li>Generating summary</li> <li>Loading xls</li> </ul>"},{"location":"work_shop/notebooks/02-working-with-data/#panda","title":"Panda\u00b6","text":"<p>Pandas stands out as one of the finest Python modules for working with datasets. It is built on top of the widely-used NumPy library and offers an array of highly valuable functions for efficient data manipulation. The succinct abbreviation for importing this library is:</p>"},{"location":"work_shop/notebooks/02-working-with-data/#data-frame","title":"Data-frame\u00b6","text":"<p>Pandas DataFrames are an incredibly useful format for working with datasets. They represent a two-dimensional, size-mutable, and potentially heterogeneous tabular data structure with labeled axes for both rows and columns. The following code demonstrates how to create a DataFrame from a dictionary:</p>"},{"location":"work_shop/notebooks/02-working-with-data/#adding-new-column","title":"Adding new column\u00b6","text":"<p>Adding a column to a DataFrame is a straightforward operation.</p>"},{"location":"work_shop/notebooks/02-working-with-data/#loading-csv-data","title":"Loading CSV data\u00b6","text":"<p>The <code>pd.read_csv</code> function is used to import data saved in CSV format. The following example demonstrates how to import a CSV file into Python, using California housing data as an example:</p>"},{"location":"work_shop/notebooks/02-working-with-data/#generating-summary","title":"Generating summary\u00b6","text":"<p>To examine the types, information, and summary statistics of variables in a DataFrame, you can use the following methods:</p> <p><code>df.dtypes</code>: This attribute displays the data types of each column in the DataFrame. <code>df.describe()</code>: This method provides summary statistics for numeric columns in the DataFrame, including count, mean, standard deviation, minimum, and maximum values.  <code>df.info()</code>: This method gives a concise summary of the DataFrame, including the number of non-null values in each column and the data types. It also provides information about memory usage. </p>"},{"location":"work_shop/notebooks/02-working-with-data/#loading-xls","title":"Loading xls\u00b6","text":"<p>To read Excel files (.xls format) in Python, you can use the xlrd package, which is a popular library for working with Excel files. However, newer Excel formats (.xlsx), the openpyxl library was more commonly used. You use <code>pd.ExcelFile</code>, see below:</p>"},{"location":"work_shop/notebooks/02-working-with-data/#contents-previous-1-starting-with-data-next-3-manipulating-data-frame","title":"Contents | Previous (1) starting with data | Next (3) manipulating data frame\u00b6","text":"<p>Exercise 02-Working with Data</p>"},{"location":"work_shop/notebooks/03-manipulating-data-frame/","title":"<b>3 Manipulating data frame </b>","text":"In\u00a0[\u00a0]: Copied! <pre>CHD.median_house_value\nCHD['median_house_value']\n</pre> CHD.median_house_value CHD['median_house_value'] <p>When you select a single column from a pandas DataFrame, you'll obtain a pandas Series, which is a 1-dimensional data structure. You can access the data either by using the column's variable name or by specifying the indices through <code>.iloc</code> and <code>.loc</code> link.  <code>.iloc</code> is designed for integer-based selection and should be used with integer indices. On the other hand, <code>.loc</code> is primarily label-based but can also be employed with a boolean array for selection.</p> In\u00a0[\u00a0]: Copied! <pre>CHD.longitude\nCHD['longitude']\nCHD.iloc[:, 1]\nCHD.iloc[:, [1, 3]]\n</pre> CHD.longitude CHD['longitude'] CHD.iloc[:, 1] CHD.iloc[:, [1, 3]] In\u00a0[\u00a0]: Copied! <pre>CHD.iloc[2:10]\nCHD.iloc[2:10,:]\nCHD.iloc[[2, 10], :]\nCHD[CHD.iloc[:,1]&lt;34]\n</pre> CHD.iloc[2:10] CHD.iloc[2:10,:] CHD.iloc[[2, 10], :] CHD[CHD.iloc[:,1]&lt;34] <p>To retrieve a part of a row using a boolean variable, you should use <code>.loc</code> because it works with boolean indexing. Regarding categorizing median_income into three categories based on given value of 2.7 and 4.4, you can do it as follows:</p> In\u00a0[\u00a0]: Copied! <pre>CHD['famlev'] = ''\nC1=CHD.median_income&lt;=2.7\nC2=CHD.median_income&gt;=4.4\nCHD.loc[C1,'famlev']='L'\nCHD.loc[~C1&amp;~C2,'famlev']='M'\nCHD.loc[C2,'famlev']='H'\n</pre> CHD['famlev'] = '' C1=CHD.median_income&lt;=2.7 C2=CHD.median_income&gt;=4.4 CHD.loc[C1,'famlev']='L' CHD.loc[~C1&amp;~C2,'famlev']='M' CHD.loc[C2,'famlev']='H' <p>This code can be rewritten as</p> In\u00a0[\u00a0]: Copied! <pre># Create a new column to store the categories\nCHD['famlev2'] = pd.cut(df['median_income'], bins=[0, 2.7, 4.4, np.inf], labels=['L', 'M', 'H'])\n</pre> # Create a new column to store the categories CHD['famlev2'] = pd.cut(df['median_income'], bins=[0, 2.7, 4.4, np.inf], labels=['L', 'M', 'H'])  In\u00a0[\u00a0]: Copied! <pre>CHD.count\nCHD[CHD.iloc[:, 1] &lt; 34].nunique()\n</pre> CHD.count CHD[CHD.iloc[:, 1] &lt; 34].nunique() <p>The following table includes the useful functions.</p> Function Description <p><code>count</code>|\tNumber of non-null observations <code>sum</code>\t | Sum of values <code>mean</code>\t|Mean of value <code>mad</code> |\tMean absolute deviation <code>median</code>|\tmedian of values <code>min</code>\t |Minimum <code>max</code>\t |Maximum <code>mode</code>\t|Mode <code>abs</code>\t| Absolute Value <code>prod</code>\t| Product of values <code>std</code>\t |Unbiased standard deviation <code>var</code>\t |Unbiased variance <code>sem</code>\t |Unbiased standard error of the mean <code>skew</code>\t| Unbiased skewness (3rd moment) <code>kurt</code>\t| Unbiased kurtosis (4th moment) <code>quantile</code>\t| Sample quantile (value at %) <code>cumsum</code>\t| Cumulative sum <code>cumprod</code>| \tCumulative product <code>cummax</code>\t| Cumulative maximum <code>cummin</code>\t| Cumulative minimum <code>nunique</code>| number of unique elements <code>value_counts</code>| Counts of unique values <code>cov</code>| Calculate the covariance between columns <code>corr</code>| Calculate the correlation between columns</p> <p>Regarding categorizing median_income into two categories based on quartiles, you can do it as follows:</p> In\u00a0[\u00a0]: Copied! <pre># Calculate quartile boundaries\nq30 = np.percentile(df['median_income'], 30)\nq70 = np.percentile(df['median_income'], 70)\n\ndf['famlev'] = pd.cut(df['median_income'], bins=[0, q30, q70, np.inf], labels=['L', 'M', 'H'])\n</pre> # Calculate quartile boundaries q30 = np.percentile(df['median_income'], 30) q70 = np.percentile(df['median_income'], 70)  df['famlev'] = pd.cut(df['median_income'], bins=[0, q30, q70, np.inf], labels=['L', 'M', 'H'])  <p>In this case, we utilized <code>.loc</code>, where we specify column labels to retrieve columns instead of using positional indices. Note that you can also use double square brackets <code>[[]]</code> to apply different conditions to the data.</p> In\u00a0[\u00a0]: Copied! <pre>CHD['median_house_value'][CHD['famlev'] == 'M'].mean()\n</pre> CHD['median_house_value'][CHD['famlev'] == 'M'].mean()  <p>Indeed, you can use <code>np.where</code> to select or search for data in a NumPy array based on specific conditions. It evaluates the conditions and returns the data that satisfy those conditions. This can be a valuable approach for more complex and custom data selection requirements.</p> In\u00a0[\u00a0]: Copied! <pre>CHD_R = CHD[['total_rooms', 'total_bedrooms']]\nCHD_R.where(CHD.total_rooms &lt; 1000)\nCHD_R.where(CHD.total_rooms &lt; 1000, 0)\ncon = CHD_R &lt; 1000\nCHD_R.where(con, -999)\n</pre> CHD_R = CHD[['total_rooms', 'total_bedrooms']] CHD_R.where(CHD.total_rooms &lt; 1000) CHD_R.where(CHD.total_rooms &lt; 1000, 0) con = CHD_R &lt; 1000 CHD_R.where(con, -999)  <p>If you want to select specific elements in data-frame, use <code>.isin()</code>,  the following select element where 'famlev=M'</p> <p>If you want to select specific elements in a DataFrame based on a condition like 'famlev=M', you can use the <code>.isin()</code> method. However, it's worth noting that <code>.isin()</code> is typically used to filter rows rather than individual elements. To filter rows where a specific column matches a certain value, you can do something like this:</p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np \nnp.where(CHD.loc[:,'famlev'].isin(['M']))\n</pre> import numpy as np  np.where(CHD.loc[:,'famlev'].isin(['M'])) <p>This code filters rows in the DataFrame where the 'famlev' column has the value 'M'.</p> <p>You can use np.where to create a new column in a DataFrame based on specified conditions. Here's an example of how you can do that:</p> In\u00a0[\u00a0]: Copied! <pre>CHD['size'] = np.where(CHD.total_rooms &lt; 1000, 'small', 'big')\n</pre> CHD['size'] = np.where(CHD.total_rooms &lt; 1000, 'small', 'big') <p>In this example, a new column 'size' is created where the values are determined based on the condition CHD.total_rooms &lt; 1000. If the condition is true, it assigns 'small' to the 'size' column; otherwise, it assigns 'big'. You can adjust the condition and the values as needed for your specific use case.</p> <p>You can perform simple operations on a DataFrame using list comprehension as well.</p> In\u00a0[\u00a0]: Copied! <pre>CHD['size']=['small' if x&lt;100  else 'big'  for x in CHD['total_rooms']]\n</pre> CHD['size']=['small' if x&lt;100  else 'big'  for x in CHD['total_rooms']] <p>To remove rows and columns from a DataFrame, you can use the <code>.drop</code> method.</p> In\u00a0[\u00a0]: Copied! <pre>CHD.drop([0,5], axis=0)\nCHD.drop('longitude',axis=1, inplace=True)\n</pre> CHD.drop([0,5], axis=0) CHD.drop('longitude',axis=1, inplace=True) <p>Note that using the argument <code>inplace=True</code> applies the change to the original data directly.</p> <p>To replace values in a DataFrame, you can use the <code>df.replace()</code> method.</p> In\u00a0[\u00a0]: Copied! <pre>CHD['famlev'].replace('L','Low').replace('M','Middle').replace('H','High')\n</pre> CHD['famlev'].replace('L','Low').replace('M','Middle').replace('H','High') <p>You can sort your data by a specific column using:</p> In\u00a0[\u00a0]: Copied! <pre>CHD.sort_values(by='size')\n</pre> CHD.sort_values(by='size') <p>Don't forget to save the data after making changes or sorting it:</p> In\u00a0[\u00a0]: Copied! <pre>CHD.to_csv(\"/Volumes/F/progwr/python/python_tech/analysis_data_using_python/data/CHD_test.csv\",\n           index=False, encoding='utf8')\n</pre> CHD.to_csv(\"/Volumes/F/progwr/python/python_tech/analysis_data_using_python/data/CHD_test.csv\",            index=False, encoding='utf8')"},{"location":"work_shop/notebooks/03-manipulating-data-frame/#data-analysis-using-python","title":"Data Analysis using Python\u00b6","text":""},{"location":"work_shop/notebooks/03-manipulating-data-frame/#03-manipulating-data-frame","title":"03-Manipulating data-frame\u00b6","text":"<p>Objectives</p> <ul> <li>Selecting subset of data frame</li> <li>Labeling the dataframe</li> <li>Reassigning the values</li> <li>Running condition using <code>==</code>, <code>!=</code>, <code>&gt;</code>, <code>&lt;</code>, <code>&gt;=</code>, <code>&lt;=</code></li> </ul> <p>Contens:</p> <ul> <li>Selecting Data</li> <li>Subsets of Rows and Columns</li> <li>Generating descriptive statistics</li> </ul>"},{"location":"work_shop/notebooks/03-manipulating-data-frame/#selecting-part-of-data","title":"Selecting part of Data\u00b6","text":"<p>To choose a column, employ either the column label enclosed within square brackets <code>[]</code> or with a period following the dataframe name.</p>"},{"location":"work_shop/notebooks/03-manipulating-data-frame/#subsets-of-rows-and-columns","title":"Subsets of Rows and Columns\u00b6","text":"<p>To choose a portion of a row, you can utilize <code>iloc[row_index, :]</code>, and you can also filter rows using logical values.</p>"},{"location":"work_shop/notebooks/03-manipulating-data-frame/#generating-descriptinve-statistics","title":"Generating descriptinve statistics\u00b6","text":"<p>While <code>.describe()</code> can provide a summary of variables, you can extract a more specific summary of individual columns, as shown below.</p>"},{"location":"work_shop/notebooks/03-manipulating-data-frame/#contents-previous-3-manipulating-data-frame-next-4-summarizing","title":"Contents | Previous (3) Manipulating data frame | Next (4) Summarizing\u00b6","text":"<p>Exercise 03-Manipulating data-frame</p>"},{"location":"work_shop/notebooks/04-summarizing/","title":"<b>4 Summarizing </b>","text":"In\u00a0[8]: Copied! <pre>import pandas as pd\nimport numpy as np \nsource = \"../data/CHD_test.csv\"\nCHD = pd.read_csv(source, sep=\",\")\nCHD.groupby(['famlev']).groups.keys()\nCHD.groupby(['famlev']).groups['H']\nCHD.groupby(['famlev']).first()\n\nCHD.groupby(['famlev']).sum()\n\nCHD.groupby(['famlev'])['median_house_value'].sum()\n# better output\nCHD.groupby(['famlev'])[['median_house_value']].sum()\n</pre> import pandas as pd import numpy as np  source = \"../data/CHD_test.csv\" CHD = pd.read_csv(source, sep=\",\") CHD.groupby(['famlev']).groups.keys() CHD.groupby(['famlev']).groups['H'] CHD.groupby(['famlev']).first()  CHD.groupby(['famlev']).sum()  CHD.groupby(['famlev'])['median_house_value'].sum() # better output CHD.groupby(['famlev'])[['median_house_value']].sum() Out[8]: median_house_value famlev H 705935355 L 340441311 M 617891143 <p>The grouped variables are assigned as indices, and to revert them back to regular columns, you can use <code>df.reset_index()</code>.</p> In\u00a0[4]: Copied! <pre>CHD.reset_index()\n</pre> CHD.reset_index() Out[4]: index latitude housing_median_age total_rooms total_bedrooms population households median_income median_house_value famlev 0 0 34.19 15 5612 1283 1015 472 1.4936 66900 L 1 1 34.40 19 7650 1901 1129 463 1.8200 80100 L 2 2 33.69 17 720 174 333 117 1.6509 85700 L 3 3 33.64 14 1501 337 515 226 3.1917 73400 M 4 4 33.57 20 1454 326 624 262 1.9250 65500 L ... ... ... ... ... ... ... ... ... ... ... 7995 7995 33.92 29 1436 401 674 343 3.6389 275000 M 7996 7996 33.92 22 2340 584 1141 554 4.5729 337500 H 7997 7997 33.90 39 2311 404 1044 380 8.4680 472100 H 7998 7998 33.90 39 2040 336 926 351 7.5552 500001 H 7999 7999 33.89 38 4166 828 1600 770 6.3861 500001 H <p>8000 rows \u00d7 10 columns</p> <p>It is indeed possible to apply even complex functions to your data in pandas. For instance, the following script calculates the coefficient of data:</p> In\u00a0[6]: Copied! <pre>CHD\n</pre> CHD Out[6]: latitude housing_median_age total_rooms total_bedrooms population households median_income median_house_value famlev 0 34.19 15 5612 1283 1015 472 1.4936 66900 L 1 34.40 19 7650 1901 1129 463 1.8200 80100 L 2 33.69 17 720 174 333 117 1.6509 85700 L 3 33.64 14 1501 337 515 226 3.1917 73400 M 4 33.57 20 1454 326 624 262 1.9250 65500 L ... ... ... ... ... ... ... ... ... ... 7995 33.92 29 1436 401 674 343 3.6389 275000 M 7996 33.92 22 2340 584 1141 554 4.5729 337500 H 7997 33.90 39 2311 404 1044 380 8.4680 472100 H 7998 33.90 39 2040 336 926 351 7.5552 500001 H 7999 33.89 38 4166 828 1600 770 6.3861 500001 H <p>8000 rows \u00d7 9 columns</p> In\u00a0[10]: Copied! <pre>def cv(x):\n return (np.mean(x)/np.var(x))\n\naggr = {\n    'total_rooms': 'sum',\n    'population': lambda x: cv(x)\n}\n\nCHD.groupby('famlev').agg(aggr)\n</pre> def cv(x):  return (np.mean(x)/np.var(x))  aggr = {     'total_rooms': 'sum',     'population': lambda x: cv(x) }  CHD.groupby('famlev').agg(aggr) Out[10]: total_rooms population famlev H 7732976 0.000838 L 5035074 0.001019 M 8558179 0.001310 <p>To tidy up the output and make it more presentable, you can format the result,</p> In\u00a0[11]: Copied! <pre>aggr = {\n    'total_rooms': ['mean', 'std']\n}\ngrouped = CHD.groupby('famlev').agg(aggr)\ngrouped.columns = grouped.columns.droplevel(level=0)\ngrouped.rename(columns={\"mean\": \"total_rooms\", \"std\": \"total_rooms\"})\ngrouped.head()\n</pre> aggr = {     'total_rooms': ['mean', 'std'] } grouped = CHD.groupby('famlev').agg(aggr) grouped.columns = grouped.columns.droplevel(level=0) grouped.rename(columns={\"mean\": \"total_rooms\", \"std\": \"total_rooms\"}) grouped.head() Out[11]: mean std famlev H 3222.073333 2896.512006 L 2097.947500 1636.991364 M 2674.430937 2069.132235 <p>Summarizing data using pivot tables is indeed a powerful way to organize and analyze data in pandas. Pivot tables allow you to aggregate and reshape your data, making it easier to derive insights from complex datasets. You can use the pivot_table() function in pandas to create pivot tables, and it provides flexibility in specifying rows, columns, and aggregation functions to suit your analysis needs.</p> <p>Here's a simple example of creating a pivot table:</p> In\u00a0[12]: Copied! <pre>pd.pivot_table(CHD, index=['famlev'], aggfunc=['mean'])\n</pre> pd.pivot_table(CHD, index=['famlev'], aggfunc=['mean']) Out[12]: mean households housing_median_age latitude median_house_value median_income population total_bedrooms total_rooms famlev H 503.607500 25.720417 33.738283 294139.731250 6.035106 1465.174583 531.882500 3222.073333 L 511.647500 30.937083 33.785250 141850.546250 2.085039 1591.265833 564.370833 2097.947500 M 535.627813 29.145312 33.799312 193090.982187 3.552313 1539.057188 577.704062 2674.430937 <p>In this example, a pivot table is created to summarize the whole column based on the 'famlev' column, aggregating using the mean function. Pivot tables offer great flexibility for summarizing and analyzing data in various ways, making them a valuable tool in data analysis.</p> In\u00a0[21]: Copied! <pre>raw_data = {'income': [10, np.nan, 14, 16],\n               'pay': [9, 11, 13, np.nan]}\ndat = pd.DataFrame(raw_data, columns=['income', 'pay'])\ndat2=dat.copy()\ndat.income.fillna(dat.income.mean(),inplace=True)\ndat.fillna(dat.mean(),inplace=True)\ndat\n</pre> raw_data = {'income': [10, np.nan, 14, 16],                'pay': [9, 11, 13, np.nan]} dat = pd.DataFrame(raw_data, columns=['income', 'pay']) dat2=dat.copy() dat.income.fillna(dat.income.mean(),inplace=True) dat.fillna(dat.mean(),inplace=True) dat Out[21]: income pay 0 10.000000 9.0 1 13.333333 11.0 2 14.000000 13.0 3 16.000000 11.0 <p>In this script, <code>np.nan</code> is used to represent missing values. The mean of each column is calculated using the .mean() method, and then <code>.fillna()</code> is applied to replace missing values with their respective column means. The <code>inplace=True</code> argument ensures that the changes are applied to the original DataFrame 'dat'.</p> <p>Indeed, you can use the <code>.isnull()</code> and <code>.notnull()</code> methods to identify which values in a DataFrame or Series are null (missing) or not null (non-missing). Here's how you can use these methods:</p> In\u00a0[20]: Copied! <pre>null_dat=dat.isnull()\nnon_null_dat=dat.notnull()\n</pre> null_dat=dat.isnull() non_null_dat=dat.notnull() <p>In this example, <code>null_dat</code> will be a DataFrame with True where there are null values in 'df' and False where there are non-null values. Conversely, <code>non_null_dat</code> will be True where there are non-null values and False where there are null values in 'df'. These boolean masks can be used for various purposes, such as filtering or imputing missing data.</p> <p>pandas provides various methods for filling missing values, and one of those methods is interpolation. Interpolation is useful when you want to estimate missing values based on the values of neighboring data points. Here's an example of how to interpolate NaN values in a DataFrame:</p> In\u00a0[22]: Copied! <pre>dat2.interpolate()\n</pre> dat2.interpolate()  Out[22]: income pay 0 10.0 9.0 1 12.0 11.0 2 14.0 13.0 3 16.0 13.0 <p>In this code, the <code>.interpolate()</code> method is applied to the DataFrame  with the default linear interpolation method. You can specify different interpolation methods using the method parameter, such as 'linear', 'polynomial', 'spline', etc., depending on your specific needs. Interpolation is a valuable technique for filling missing data when there is a meaningful relationship between the missing values and the surrounding data points.</p> In\u00a0[31]: Copied! <pre>categories = ['L', 'M', 'H']\n\nq30tr=CHD.total_rooms.quantile(.3)\nq70tr=CHD.total_rooms.quantile(.7)\n\nCHD['roomlev'] = pd.cut(CHD['median_income'], bins=[-np.inf, q30mi, q70mi, np.inf], labels=categories)\n\nq30hma=CHD.housing_median_age.quantile(.3)\nq70hma=CHD.housing_median_age.quantile(.7)\n\nCHD['houslev'] = pd.cut(CHD['housing_median_age'], bins=[-np.inf, q30hma, q70hma, np.inf], labels=categories)\nCHD\n</pre> categories = ['L', 'M', 'H']  q30tr=CHD.total_rooms.quantile(.3) q70tr=CHD.total_rooms.quantile(.7)  CHD['roomlev'] = pd.cut(CHD['median_income'], bins=[-np.inf, q30mi, q70mi, np.inf], labels=categories)  q30hma=CHD.housing_median_age.quantile(.3) q70hma=CHD.housing_median_age.quantile(.7)  CHD['houslev'] = pd.cut(CHD['housing_median_age'], bins=[-np.inf, q30hma, q70hma, np.inf], labels=categories) CHD Out[31]: latitude housing_median_age total_rooms total_bedrooms population households median_income median_house_value famlev houlev roomlev houslev 0 34.19 15 5612 1283 1015 472 1.4936 66900 L L L L 1 34.40 19 7650 1901 1129 463 1.8200 80100 L L L L 2 33.69 17 720 174 333 117 1.6509 85700 L L L L 3 33.64 14 1501 337 515 226 3.1917 73400 M M M L 4 33.57 20 1454 326 624 262 1.9250 65500 L L L L ... ... ... ... ... ... ... ... ... ... ... ... ... 7995 33.92 29 1436 401 674 343 3.6389 275000 M M M M 7996 33.92 22 2340 584 1141 554 4.5729 337500 H H H M 7997 33.90 39 2311 404 1044 380 8.4680 472100 H H H H 7998 33.90 39 2040 336 926 351 7.5552 500001 H H H H 7999 33.89 38 4166 828 1600 770 6.3861 500001 H H H H <p>8000 rows \u00d7 12 columns</p> In\u00a0[32]: Copied! <pre>pd.crosstab(CHD.roomlev, CHD.houlev, margins=True)\n</pre> pd.crosstab(CHD.roomlev, CHD.houlev, margins=True) Out[32]: houlev L M H All roomlev L 2400 0 0 2400 M 0 3200 0 3200 H 0 0 2400 2400 All 2400 3200 2400 8000 <p>To generate a cross-tabulation (crosstab) that includes a third variable, 'famlev', along with the previously categorized variables ('housing_median_age' and 'total_rooms'), you can use the <code>pd.crosstab</code> function with all three variables. Here's an example:</p> In\u00a0[33]: Copied! <pre>pd.crosstab([CHD.roomlev, CHD.houlev], CHD.famlev, margins=True)\n</pre> pd.crosstab([CHD.roomlev, CHD.houlev], CHD.famlev, margins=True) Out[33]: famlev H L M All roomlev houlev L L 0 2400 0 2400 M M 0 0 3200 3200 H H 2400 0 0 2400 All 2400 2400 3200 8000"},{"location":"work_shop/notebooks/04-summarizing/#data-analysis-using-python","title":"Data Analysis using Python\u00b6","text":""},{"location":"work_shop/notebooks/04-summarizing/#04-summarizing","title":"04-Summarizing\u00b6","text":"<p>Objectives:</p> <ul> <li>Employing function on dataframe</li> <li>Running grouping on dataframe</li> <li>Working with Missing Value</li> <li>Generating Crosstab</li> </ul> <p>Contents:</p> <ul> <li>Grouping</li> <li>Missing Value</li> <li>Crosstab</li> </ul>"},{"location":"work_shop/notebooks/04-summarizing/#grouping","title":"grouping\u00b6","text":"<p>Summaries can be obtained using any grouping variables present in the dataset:</p>"},{"location":"work_shop/notebooks/04-summarizing/#missing-value","title":"Missing Value\u00b6","text":"<p>Handling missing values in a dataset is a crucial part of data preprocessing. You can use the <code>.fillna(new_value)</code> method to replace missing values with a specified new value. Here's a script that generates a dataset with missing values and fills them with the mean of the other values:</p>"},{"location":"work_shop/notebooks/04-summarizing/#crosstab","title":"Crosstab\u00b6","text":"<p>To create a cross-tabulation (crosstab) between two continuous variables that have been categorized based on quantiles and labeled as 'L' (Low), 'M' (Medium), and 'H' (High), you can use the <code>pd.crosstab</code> function. Here's a step-by-step example:</p>"},{"location":"work_shop/notebooks/04-summarizing/#contents-previous3-manipulating-data-frame-next-5-merging-data-frame","title":"Contents | Previous(3) manipulating-data-frame | Next (5) Merging data frame\u00b6","text":"<p>Exercise 04-Summarizing</p>"},{"location":"work_shop/notebooks/05-merging-data-frame/","title":"<b>5 Merging data frame </b>","text":"<p>Pandas is very useful for merging datasets. To merge data, consider the following datasets where 'id1' and 'id2' include the data IDs.</p> In\u00a0[3]: Copied! <pre>import pandas as pd\nraw_data = {'id1': range(4),'income': [10,12,14,16]}\ndat1 =pd.DataFrame(raw_data, columns = ['id1', 'income'])\n\nraw_data = {'id2': range(6),'pay': [9,11,13,15,17,19]}\ndat2 =pd.DataFrame(raw_data, columns = ['id2', 'pay'])\n</pre> import pandas as pd raw_data = {'id1': range(4),'income': [10,12,14,16]} dat1 =pd.DataFrame(raw_data, columns = ['id1', 'income'])  raw_data = {'id2': range(6),'pay': [9,11,13,15,17,19]} dat2 =pd.DataFrame(raw_data, columns = ['id2', 'pay']) <p>Obviously, the ID variables may not be the same, and they can be compared using:</p> In\u00a0[\u00a0]: Copied! <pre>dat1['id1'].isin(dat2['id2']).value_counts()\ndat2['id2'].isin(dat1['id1']).value_counts()\n</pre> dat1['id1'].isin(dat2['id2']).value_counts() dat2['id2'].isin(dat1['id1']).value_counts() <p><code>pd.merge</code> can merge different dataframes, and the merging is typically done based on the identities of the left dataset. If there is no match in the right dataframe, Python adds `NaN`` values for the missing data.</p> In\u00a0[\u00a0]: Copied! <pre>result = pd.merge(dat1, dat2, left_on='id1', right_on='id2', how='left')\n</pre> result = pd.merge(dat1, dat2, left_on='id1', right_on='id2', how='left') <p>On the contrary, you can treat the right dataset as the matching one, and if there's no match in the left dataset, Python adds <code>NaN</code> values accordingly.</p> In\u00a0[\u00a0]: Copied! <pre>result = pd.merge(dat1, dat2, left_on='id1', right_on='id2', how='right')\n</pre> result = pd.merge(dat1, dat2, left_on='id1', right_on='id2', how='right') <p>Since the IDs are not the same, one can perform merging based on the intersection of the IDs.</p> In\u00a0[\u00a0]: Copied! <pre>result = pd.merge(dat1, dat2, left_on='id1', right_on='id2',how='inner')\n</pre> result = pd.merge(dat1, dat2, left_on='id1', right_on='id2',how='inner') <p>Merging can also be done based on the union of the IDs.</p> In\u00a0[\u00a0]: Copied! <pre>result = pd.merge(dat1, dat2, left_on='id1', right_on='id2',how='outer')\n</pre> result = pd.merge(dat1, dat2, left_on='id1', right_on='id2',how='outer') <p>If the names of ID variables are the same in both datasets, you can use <code>on=id_name</code> instead of <code>left_on=</code> and <code>right_on=</code>. If you want to identify where the elements in rows are from, add the argument <code>indicator=True</code>, then a new column named <code>_merge</code> will be added to the merged data, which shows its origin.</p> In\u00a0[\u00a0]: Copied! <pre>result = pd.merge(dat1, dat2, left_on='id1', right_on='id2',  how='outer', indicator=True)\n</pre> result = pd.merge(dat1, dat2, left_on='id1', right_on='id2',  how='outer', indicator=True) In\u00a0[\u00a0]: Copied! <pre>result = pd.concat([dat1, dat2],axis=1)\n</pre> result = pd.concat([dat1, dat2],axis=1)"},{"location":"work_shop/notebooks/05-merging-data-frame/#data-analysis-using-python","title":"Data Analysis using Python\u00b6","text":""},{"location":"work_shop/notebooks/05-merging-data-frame/#05-merging-data-frame","title":"05-Merging data frame\u00b6","text":"<p>Objectives</p> <ul> <li>Combine data from multiple files into a single DataFrame using <code>concat</code> and <code>merge</code>.</li> <li>Combine two DataFrames using a unique ID found in both DataFrames.</li> </ul> <p>Contents:</p> <ul> <li>Merge</li> <li>Concat</li> </ul>"},{"location":"work_shop/notebooks/05-merging-data-frame/#merging","title":"Merging\u00b6","text":"<p>To merge different datasets, various scenarios can be explored, as illustrated in the following diagram.</p> <p></p> <p>According to the figure presented, we can state  Left: Collects all data from the left dataframe and common data from both the left and right dataframes. Right: Collects all data from the right dataframe and common data from both the left and right dataframes. Inner: Collects only the common data from both the left and right dataframes, essentially performing an intersection operation.  Outer: Collects all data from both the left and right dataframes, including the common data. </p>"},{"location":"work_shop/notebooks/05-merging-data-frame/#concating","title":"Concating\u00b6","text":"<p>To concatenate datasets row-wise, use <code>concat</code>.</p>"},{"location":"work_shop/notebooks/05-merging-data-frame/#contents-previous4-summarizing-next-6-plot","title":"Contents | Previous(4) summarizing | Next (6) Plot\u00b6","text":"<p>Exercise 05-Merging data frame</p>"},{"location":"work_shop/notebooks/06-visualization/","title":"<b>6 Visualization </b>","text":"In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd \nCHD=pd.read_csv('../data/CHD_test.csv',index_col=False)\nCHD.head()\n</pre> import matplotlib.pyplot as plt import numpy as np import pandas as pd  CHD=pd.read_csv('../data/CHD_test.csv',index_col=False) CHD.head() Out[1]: latitude housing_median_age total_rooms total_bedrooms population households median_income median_house_value famlev 0 34.19 15 5612 1283 1015 472 1.4936 66900 L 1 34.40 19 7650 1901 1129 463 1.8200 80100 L 2 33.69 17 720 174 333 117 1.6509 85700 L 3 33.64 14 1501 337 515 226 3.1917 73400 M 4 33.57 20 1454 326 624 262 1.9250 65500 L In\u00a0[2]: Copied! <pre>x = CHD.median_house_value\ny = CHD.median_income\nplt.scatter(x, y)\nplt.xlabel('median_house_value')\nplt.ylabel('median_income')\nplt.title('Scatter Plot')\nplt.show(block=False)\n</pre> x = CHD.median_house_value y = CHD.median_income plt.scatter(x, y) plt.xlabel('median_house_value') plt.ylabel('median_income') plt.title('Scatter Plot') plt.show(block=False) <p>Indeed, you can customize the appearance of a scatter plot using various arguments:</p> <ul> <li>Size of point (<code>s</code>): you can adjust the size of the points, for example,  <code>s=10</code> make the point smaller,</li> <li>colour (<code>c</code>): You can specify the color of pointy. For example, <code>c=red</code> will make the points red.</li> <li><code>marker</code>: you can choose different marker styles for points. For example <code>marker=s</code> w ill use squares for presenting points.</li> </ul> In\u00a0[7]: Copied! <pre>plt.scatter(x, y,s=40, c='red', marker='s')\nplt.xlabel('median_house_value')\nplt.ylabel('median_income')\nplt.title('Scatter Plot')\nplt.show(block=False)\n</pre> plt.scatter(x, y,s=40, c='red', marker='s') plt.xlabel('median_house_value') plt.ylabel('median_income') plt.title('Scatter Plot') plt.show(block=False) <p>In this example, we've customized the scatter plot to use red square for data points with a larger size (s=40) to label the points. You can further explore the links provided for more marker styles and line properties in matplotlib. The following figure displays a more sophisticated plot.</p> In\u00a0[8]: Copied! <pre>select = (CHD.famlev == 'L')\nplt.scatter(x, y, alpha=0.3)\nplt.xlabel('median_house_value')\nplt.ylabel('median_income')\nplt.title('Scatter Plot')\nplt.scatter(x[select], y[select], facecolor='none', edgecolors='r')\nplt.show(block=False)\n</pre> select = (CHD.famlev == 'L') plt.scatter(x, y, alpha=0.3) plt.xlabel('median_house_value') plt.ylabel('median_income') plt.title('Scatter Plot') plt.scatter(x[select], y[select], facecolor='none', edgecolors='r') plt.show(block=False)  <p>Fit a linear model to a sample dataset.</p> In\u00a0[9]: Copied! <pre>fig, ax = plt.subplots() \nax.scatter(x, y, alpha=0.5, color='orchid') \nfig.suptitle('Scatter Plot') \nfig.tight_layout(pad=2);\nax.grid(True)\nfit = np.polyfit(x, y, deg=1) \nax.plot(x, fit[0]*x + fit[1], '-',color='red', linewidth=2)\n</pre>  fig, ax = plt.subplots()  ax.scatter(x, y, alpha=0.5, color='orchid')  fig.suptitle('Scatter Plot')  fig.tight_layout(pad=2); ax.grid(True) fit = np.polyfit(x, y, deg=1)  ax.plot(x, fit[0]*x + fit[1], '-',color='red', linewidth=2) Out[9]: <pre>[&lt;matplotlib.lines.Line2D at 0x14052de10&gt;]</pre> In\u00a0[10]: Copied! <pre>plt.subplot(2, 1, 1)\nplt.scatter(x, y)\nplt.title(\"Fig1\")\nplt.xlabel(\"median house value\")\nplt.ylabel(\"median income\")\nplt.subplot(2, 1, 2)\nplt.scatter(x, CHD.population)\nplt.title(\"Fig2\")\nplt.xlabel(\"median house value\")\nplt.ylabel(\"population\")\nplt.show(block=False)\n</pre> plt.subplot(2, 1, 1) plt.scatter(x, y) plt.title(\"Fig1\") plt.xlabel(\"median house value\") plt.ylabel(\"median income\") plt.subplot(2, 1, 2) plt.scatter(x, CHD.population) plt.title(\"Fig2\") plt.xlabel(\"median house value\") plt.ylabel(\"population\") plt.show(block=False) In\u00a0[8]: Copied! <pre>import seaborn as sns\nsns.set(color_codes=True)\n\nCHD['median_income'] = (CHD['median_income'] -CHD['median_income'].mean()) / CHD['median_income'].std()\nCHD['median_house_value'] = (CHD['median_house_value'] -CHD['median_house_value'].mean()) / CHD['median_house_value'].std()\n</pre> import seaborn as sns sns.set(color_codes=True)  CHD['median_income'] = (CHD['median_income'] -CHD['median_income'].mean()) / CHD['median_income'].std() CHD['median_house_value'] = (CHD['median_house_value'] -CHD['median_house_value'].mean()) / CHD['median_house_value'].std()  In\u00a0[6]: Copied! <pre>for col in ['median_income','median_house_value']:\n    plt.hist(CHD[col], density=True)\n</pre> for col in ['median_income','median_house_value']:     plt.hist(CHD[col], density=True) <p>We can get a smooth estimate of the distribution using a kernel density estimation (KDE):</p> In\u00a0[9]: Copied! <pre>import warnings\nwarnings.filterwarnings(\"ignore\")\nsns.kdeplot(data=CHD, x='median_income', y='median_house_value')\n</pre> import warnings warnings.filterwarnings(\"ignore\") sns.kdeplot(data=CHD, x='median_income', y='median_house_value') Out[9]: <pre>&lt;Axes: xlabel='median_income', ylabel='median_house_value'&gt;</pre> <p>You can create a hexagonally-based histogram using <code>jointplot</code>:</p> In\u00a0[10]: Copied! <pre>sns.jointplot(data=CHD, x='median_income', y='median_house_value',kind=\"hex\")\n</pre> sns.jointplot(data=CHD, x='median_income', y='median_house_value',kind=\"hex\") Out[10]: <pre>&lt;seaborn.axisgrid.JointGrid at 0x168785bd0&gt;</pre> In\u00a0[11]: Copied! <pre>sns.jointplot(data=CHD, x='median_income', y='median_house_value',kind=\"kde\", hue='famlev')\n</pre> sns.jointplot(data=CHD, x='median_income', y='median_house_value',kind=\"kde\", hue='famlev') Out[11]: <pre>&lt;seaborn.axisgrid.JointGrid at 0x168f77e10&gt;</pre> <p>The following illustrates how to draw a box plot for different family levels.</p> In\u00a0[14]: Copied! <pre>g=sns.catplot(data=CHD, x='median_income', y='famlev', kind=\"box\")\ng.set_axis_labels(\"Income\", \"Family level\");\n</pre> g=sns.catplot(data=CHD, x='median_income', y='famlev', kind=\"box\") g.set_axis_labels(\"Income\", \"Family level\"); In\u00a0[11]: Copied! <pre>sns.pairplot(CHD, hue='famlev');\n</pre> sns.pairplot(CHD, hue='famlev'); <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\n/Users/samamiri/Library/CloudStorage/GoogleDrive-saeid.amiri1@gmail.com/My Drive/python/Python-for-Data-Analysis/notebooks/06-visualization.ipynb Cell 25 line 1\n----&gt; &lt;a href='vscode-notebook-cell:/Users/samamiri/Library/CloudStorage/GoogleDrive-saeid.amiri1%40gmail.com/My%20Drive/python/Python-for-Data-Analysis/notebooks/06-visualization.ipynb#X31sZmlsZQ%3D%3D?line=0'&gt;1&lt;/a&gt; sns.pairplot(CHD, hue='famlev');\n\nNameError: name 'sns' is not defined</pre> <ul> <li>initialize it</li> </ul> In\u00a0[14]: Copied! <pre>import plotnine as p9\np9.ggplot(data=CHD)\n</pre> import plotnine as p9 p9.ggplot(data=CHD) Out[14]: <pre>&lt;Figure Size: (640 x 480)&gt;</pre> <ul> <li>Define aesthetics using <code>aes</code> and specify your arguments. The most important aesthetics include: <code>x</code>, <code>y</code>, <code>alpha</code>, <code>color</code>, <code>colour</code>, <code>fill</code>, <code>linetype</code>, <code>shape</code>, <code>size</code>, and <code>stroke</code>. To create variations of the plot with different parameters, you can assign it to a variable.</li> </ul> In\u00a0[15]: Copied! <pre>CHD_plot=p9.ggplot(data=CHD,mapping=p9.aes(x='median_income', y='median_house_value'))\n</pre> CHD_plot=p9.ggplot(data=CHD,mapping=p9.aes(x='median_income', y='median_house_value')) <ul> <li>Specify what you want to display and use the <code>+</code> operator to add layers and customize your plot.</li> </ul> In\u00a0[16]: Copied! <pre>CHD_plot+p9.geom_point()\n</pre> CHD_plot+p9.geom_point() Out[16]: <pre>&lt;Figure Size: (640 x 480)&gt;</pre> <p>You can easily add scale and define label:</p> In\u00a0[35]: Copied! <pre>CHD_plot+ p9.geom_point(alpha=0.15)+ p9.xlab(\"median_income\") + p9.ylab(\"median_house_value\")+ p9.scale_x_log10()+ p9.theme_bw()+ p9.theme(text=p9.element_text(size=10))\n</pre> CHD_plot+ p9.geom_point(alpha=0.15)+ p9.xlab(\"median_income\") + p9.ylab(\"median_house_value\")+ p9.scale_x_log10()+ p9.theme_bw()+ p9.theme(text=p9.element_text(size=10)) Out[35]: <pre>&lt;Figure Size: (640 x 480)&gt;</pre> <ul> <li>After creating your plot, you can save it to a file in your favourite format</li> </ul> In\u00a0[36]: Copied! <pre>CHD_plot2 = CHD_plot+p9.geom_point()\nCHD_plot2.save(\"CHD_plot.png\", dpi=300)\n</pre> CHD_plot2 = CHD_plot+p9.geom_point() CHD_plot2.save(\"CHD_plot.png\", dpi=300) <pre>/home/sam/venv/lib/python3.10/site-packages/plotnine/ggplot.py:587: PlotnineWarning: Saving 6.4 x 4.8 in image.\n/home/sam/venv/lib/python3.10/site-packages/plotnine/ggplot.py:588: PlotnineWarning: Filename: CHD_plot.png\n</pre> In\u00a0[37]: Copied! <pre>(p9.ggplot(data=CHD,mapping=p9.aes(x='famlev'))+ p9.geom_bar())\n</pre> (p9.ggplot(data=CHD,mapping=p9.aes(x='famlev'))+ p9.geom_bar()) Out[37]: <pre>&lt;Figure Size: (640 x 480)&gt;</pre> In\u00a0[38]: Copied! <pre>(p9.ggplot(data=CHD,\n           mapping=p9.aes(x='famlev',\n                          y='median_income'))\n    + p9.geom_boxplot()\n    + p9.scale_y_log10()\n )\n</pre> (p9.ggplot(data=CHD,            mapping=p9.aes(x='famlev',                           y='median_income'))     + p9.geom_boxplot()     + p9.scale_y_log10()  ) Out[38]: <pre>&lt;Figure Size: (640 x 480)&gt;</pre> <ul> <li>To add points behind the boxplot, you can use geom_jitter() to plot the points with some random noise to avoid overlapping points. This will create a visual representation of the data points behind the boxplot. Here's an example:</li> </ul> In\u00a0[39]: Copied! <pre>(p9.ggplot(data=CHD,\n           mapping=p9.aes(x='famlev',\n                          y='median_income'))\n    + p9.geom_boxplot()\n    + p9.geom_jitter(alpha=0.1, color=\"green\")\n    + p9.scale_y_log10()\n )\n</pre> (p9.ggplot(data=CHD,            mapping=p9.aes(x='famlev',                           y='median_income'))     + p9.geom_boxplot()     + p9.geom_jitter(alpha=0.1, color=\"green\")     + p9.scale_y_log10()  ) Out[39]: <pre>&lt;Figure Size: (640 x 480)&gt;</pre>"},{"location":"work_shop/notebooks/06-visualization/#data-analysis-using-python","title":"Data Analysis using Python\u00b6","text":""},{"location":"work_shop/notebooks/06-visualization/#06-visualization","title":"06-Visualization\u00b6","text":"<p>Objectives</p> <ul> <li>Learn about <code>matplotlib</code></li> <li>Learn about <code>seaborn</code></li> <li>How to use <code>Plotnine</code> to plot</li> </ul> <p>Contents:</p> <ul> <li>Matplotlib</li> <li>Seaborn</li> </ul>"},{"location":"work_shop/notebooks/06-visualization/#matplotlib","title":"Matplotlib\u00b6","text":"<p>Python offers sophisticated plotting capabilities. Plotting can be approached in two ways:</p> <ul> <li>Pythonic Approach: In this method, an empty object is created, and plots are constructed programmatically, then assigned to the empty object using code.</li> <li>Non-Pythonic Approach: This approach relies on external libraries like <code>matplotlib</code>, which provides user-friendly tools for interactive plotting. A common shorthand for importing this module is <code>import matplotlib.pyplot as plt</code>.</li> </ul>"},{"location":"work_shop/notebooks/06-visualization/#scatter-plot","title":"Scatter plot\u00b6","text":"<p>The most commonly used plot is the scatter plot. Here are the following scripts that generate random numbers and create a scatter plot:</p>"},{"location":"work_shop/notebooks/06-visualization/#subplot","title":"subplot\u00b6","text":"<p>You can create multiple subplots in a single figure using the <code>.subplot(#row,#col,position)</code> method.</p>"},{"location":"work_shop/notebooks/06-visualization/#seaborn","title":"Seaborn\u00b6","text":"<p>Seaborn provides advanced graphical capabilities for creating sophisticated statistical visualizations with ease. It simplifies the process of generating complex plots from pandas DataFrames using simple commands.</p>"},{"location":"work_shop/notebooks/06-visualization/#pairplots","title":"Pairplots\u00b6","text":"<p>We can generalize joint plots for multidimensional data, which is very useful for exploring correlations between multiple dimensions of data.</p>"},{"location":"work_shop/notebooks/06-visualization/#ggplot2","title":"GGPLOT2\u00b6","text":"<p><code>ggplot2</code> is a very useful package in R for creating advanced plots. In Python, the <code>plotnine</code> library is used to create <code>ggplot2</code>-like plots. You can import the module using <code>import plotnine as p9</code>. Generating plots in <code>ggplot2</code> (plotnine) follows a structured series of steps, which can be accomplished via:</p>"},{"location":"work_shop/notebooks/06-visualization/#bar-chart","title":"bar chart\u00b6","text":"<p>To generate a bar chart, you can use <code>geom_bar()</code></p>"},{"location":"work_shop/notebooks/06-visualization/#plotting-distributions","title":"Plotting distributions\u00b6","text":"<ul> <li>A boxplot can be created using <code>geom_boxplot()</code>:</li> </ul>"},{"location":"work_shop/notebooks/06-visualization/#contents-previous-5-merging-data-frame","title":"Contents | Previous (5) Merging data frame\u00b6","text":"<p>Excercise 06-Visualization</p>"},{"location":"concise_notes/archive/2024/","title":"2024","text":""},{"location":"concise_notes/category/notes/","title":"Notes","text":""},{"location":"concise_notes/category/python-core/","title":"Python core","text":""},{"location":"concise_notes/category/numpy/","title":"Numpy","text":""},{"location":"concise_notes/category/dataframe/","title":"Dataframe","text":""},{"location":"concise_notes/category/cheat-sheet/","title":"Cheat Sheet","text":""},{"location":"concise_notes/category/panda/","title":"Panda","text":""},{"location":"concise_notes/category/plot/","title":"Plot","text":""},{"location":"concise_notes/page/2/","title":"Concise notes","text":""},{"location":"concise_notes/page/3/","title":"Concise notes","text":""},{"location":"concise_notes/archive/2024/page/2/","title":"2024","text":""},{"location":"concise_notes/archive/2024/page/3/","title":"2024","text":""},{"location":"concise_notes/category/python-core/page/2/","title":"Python core","text":""}]}